{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# GridWorld_PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ba6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "output_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"mlagents_learn_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a62e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Unity6000_Envs/3DBallHard_Darwin.app\n"
     ]
    }
   ],
   "source": [
    "# Unity Enviroment\n",
    "game = \"3DBallHard\"\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")\n",
    "env_fp = os.path.join(env_dir, env_name)\n",
    "print(env_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a25ba76",
   "metadata": {},
   "source": [
    "## Training PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "360531c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/3DBallHard_ppo.yaml\n",
      "3DBallHard_PPO\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: 3DBallHard?team=0\n",
      "[INFO] Hyperparameters for behavior name 3DBallHard: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t120\n",
      "\t  buffer_size:\t12000\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.001\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t500000\n",
      "\ttime_horizon:\t1000\n",
      "\tsummary_freq:\t12000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] 3DBallHard. Step: 12000. Time Elapsed: 15.625 s. Mean Reward: 1.143. Std of Reward: 0.699. Training.\n",
      "[INFO] 3DBallHard. Step: 24000. Time Elapsed: 26.898 s. Mean Reward: 1.192. Std of Reward: 0.667. Training.\n",
      "[INFO] 3DBallHard. Step: 36000. Time Elapsed: 38.148 s. Mean Reward: 1.385. Std of Reward: 0.786. Training.\n",
      "[INFO] 3DBallHard. Step: 48000. Time Elapsed: 49.480 s. Mean Reward: 1.660. Std of Reward: 0.937. Training.\n",
      "[INFO] 3DBallHard. Step: 60000. Time Elapsed: 60.679 s. Mean Reward: 2.262. Std of Reward: 1.473. Training.\n",
      "[INFO] 3DBallHard. Step: 72000. Time Elapsed: 72.015 s. Mean Reward: 3.163. Std of Reward: 1.874. Training.\n",
      "[INFO] 3DBallHard. Step: 84000. Time Elapsed: 83.515 s. Mean Reward: 4.583. Std of Reward: 3.499. Training.\n",
      "[INFO] 3DBallHard. Step: 96000. Time Elapsed: 95.094 s. Mean Reward: 8.077. Std of Reward: 6.625. Training.\n",
      "[INFO] 3DBallHard. Step: 108000. Time Elapsed: 108.044 s. Mean Reward: 16.151. Std of Reward: 14.656. Training.\n",
      "[INFO] 3DBallHard. Step: 120000. Time Elapsed: 120.300 s. Mean Reward: 36.391. Std of Reward: 28.050. Training.\n",
      "[INFO] 3DBallHard. Step: 132000. Time Elapsed: 132.878 s. Mean Reward: 58.105. Std of Reward: 41.213. Training.\n",
      "[INFO] 3DBallHard. Step: 144000. Time Elapsed: 144.410 s. Mean Reward: 91.769. Std of Reward: 22.855. Training.\n",
      "[INFO] 3DBallHard. Step: 156000. Time Elapsed: 155.961 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 168000. Time Elapsed: 167.528 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 180000. Time Elapsed: 179.095 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 192000. Time Elapsed: 190.646 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 204000. Time Elapsed: 202.245 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 216000. Time Elapsed: 213.829 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 228000. Time Elapsed: 225.362 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 240000. Time Elapsed: 236.930 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 252000. Time Elapsed: 248.495 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 264000. Time Elapsed: 259.997 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 276000. Time Elapsed: 270.396 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 288000. Time Elapsed: 281.981 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 300000. Time Elapsed: 293.563 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 312000. Time Elapsed: 305.097 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 324000. Time Elapsed: 316.663 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 336000. Time Elapsed: 328.147 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 348000. Time Elapsed: 339.749 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 360000. Time Elapsed: 351.307 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 372000. Time Elapsed: 362.847 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 384000. Time Elapsed: 374.431 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 396000. Time Elapsed: 385.980 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 408000. Time Elapsed: 397.481 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 420000. Time Elapsed: 409.032 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 432000. Time Elapsed: 419.448 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 444000. Time Elapsed: 430.998 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 456000. Time Elapsed: 442.565 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 468000. Time Elapsed: 454.115 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 480000. Time Elapsed: 465.682 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 492000. Time Elapsed: 477.199 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_PPO/3DBallHard/3DBallHard-499562.onnx\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_PPO/3DBallHard/3DBallHard-500562.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_PPO/3DBallHard/3DBallHard-500562.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_PPO/3DBallHard.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_ppo_fp = os.path.join(cur_dir, \"config\", \"3DBallHard_ppo.yaml\")\n",
    "run_ppo_id = \"3DBallHard_PPO\"\n",
    "print(config_ppo_fp)\n",
    "print(run_ppo_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_ppo_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8c3c8",
   "metadata": {},
   "source": [
    "## Training SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590578c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/3DBallHard_ppo.yaml\n",
      "3DBallHard_SAC\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: 3DBallHard?team=0\n",
      "[INFO] Hyperparameters for behavior name 3DBallHard: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t120\n",
      "\t  buffer_size:\t12000\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.001\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t500000\n",
      "\ttime_horizon:\t1000\n",
      "\tsummary_freq:\t12000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] 3DBallHard. Step: 12000. Time Elapsed: 14.676 s. Mean Reward: 1.193. Std of Reward: 0.669. Training.\n",
      "[INFO] 3DBallHard. Step: 24000. Time Elapsed: 25.990 s. Mean Reward: 1.269. Std of Reward: 0.749. Training.\n",
      "[INFO] 3DBallHard. Step: 36000. Time Elapsed: 37.285 s. Mean Reward: 1.404. Std of Reward: 0.822. Training.\n",
      "[INFO] 3DBallHard. Step: 48000. Time Elapsed: 48.552 s. Mean Reward: 1.769. Std of Reward: 1.057. Training.\n",
      "[INFO] 3DBallHard. Step: 60000. Time Elapsed: 59.953 s. Mean Reward: 2.605. Std of Reward: 1.633. Training.\n",
      "[INFO] 3DBallHard. Step: 72000. Time Elapsed: 71.388 s. Mean Reward: 3.265. Std of Reward: 2.491. Training.\n",
      "[INFO] 3DBallHard. Step: 84000. Time Elapsed: 82.920 s. Mean Reward: 4.979. Std of Reward: 3.438. Training.\n",
      "[INFO] 3DBallHard. Step: 96000. Time Elapsed: 94.143 s. Mean Reward: 7.951. Std of Reward: 7.172. Training.\n",
      "[INFO] 3DBallHard. Step: 108000. Time Elapsed: 106.721 s. Mean Reward: 16.642. Std of Reward: 16.345. Training.\n",
      "[INFO] 3DBallHard. Step: 120000. Time Elapsed: 119.917 s. Mean Reward: 41.021. Std of Reward: 30.927. Training.\n",
      "[INFO] 3DBallHard. Step: 132000. Time Elapsed: 132.766 s. Mean Reward: 75.556. Std of Reward: 35.883. Training.\n",
      "[INFO] 3DBallHard. Step: 144000. Time Elapsed: 144.299 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 156000. Time Elapsed: 155.867 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 168000. Time Elapsed: 167.400 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 180000. Time Elapsed: 178.984 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 192000. Time Elapsed: 190.500 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 204000. Time Elapsed: 202.067 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 216000. Time Elapsed: 213.650 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 228000. Time Elapsed: 225.226 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 240000. Time Elapsed: 236.826 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 252000. Time Elapsed: 248.409 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 264000. Time Elapsed: 259.893 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 276000. Time Elapsed: 270.326 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 288000. Time Elapsed: 281.893 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 300000. Time Elapsed: 293.426 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 312000. Time Elapsed: 305.042 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 324000. Time Elapsed: 316.560 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 336000. Time Elapsed: 328.143 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 348000. Time Elapsed: 339.711 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 360000. Time Elapsed: 351.277 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 372000. Time Elapsed: 362.777 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 384000. Time Elapsed: 374.327 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 396000. Time Elapsed: 385.877 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 408000. Time Elapsed: 397.428 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 420000. Time Elapsed: 409.028 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 432000. Time Elapsed: 419.378 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 444000. Time Elapsed: 430.995 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 456000. Time Elapsed: 442.562 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 468000. Time Elapsed: 454.062 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 480000. Time Elapsed: 465.662 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 492000. Time Elapsed: 477.279 s. Mean Reward: 100.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_SAC/3DBallHard/3DBallHard-499744.onnx\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_SAC/3DBallHard/3DBallHard-500744.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_SAC/3DBallHard/3DBallHard-500744.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_SAC/3DBallHard.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_sac_fp = os.path.join(cur_dir, \"config\", \"3DBallHard_sac.yaml\")\n",
    "run_sac_id = \"3DBallHard_SAC\"\n",
    "print(config_ppo_fp)\n",
    "print(run_sac_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_sac_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47b032",
   "metadata": {},
   "source": [
    "## Training POCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6886efe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/3DBallHard_poca.yaml\n",
      "3DBallHard_POCA\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: 3DBallHard?team=0\n",
      "[INFO] Hyperparameters for behavior name 3DBallHard: \n",
      "\ttrainer_type:\tpoca\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t120\n",
      "\t  buffer_size:\t12000\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.001\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t500000\n",
      "\ttime_horizon:\t1000\n",
      "\tsummary_freq:\t12000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] 3DBallHard. Step: 12000. Time Elapsed: 15.196 s. Mean Reward: 1.207. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 24000. Time Elapsed: 27.893 s. Mean Reward: 1.271. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 36000. Time Elapsed: 40.319 s. Mean Reward: 1.555. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 48000. Time Elapsed: 52.649 s. Mean Reward: 2.045. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 60000. Time Elapsed: 64.919 s. Mean Reward: 2.953. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 72000. Time Elapsed: 77.191 s. Mean Reward: 4.385. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 84000. Time Elapsed: 89.785 s. Mean Reward: 7.370. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 96000. Time Elapsed: 102.901 s. Mean Reward: 15.517. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 108000. Time Elapsed: 116.853 s. Mean Reward: 48.879. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 120000. Time Elapsed: 130.614 s. Mean Reward: 61.600. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 132000. Time Elapsed: 143.542 s. Mean Reward: 86.707. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 144000. Time Elapsed: 155.874 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 156000. Time Elapsed: 168.374 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 168000. Time Elapsed: 180.773 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 180000. Time Elapsed: 193.190 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 192000. Time Elapsed: 205.690 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 204000. Time Elapsed: 218.107 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 216000. Time Elapsed: 230.607 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 228000. Time Elapsed: 243.074 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 240000. Time Elapsed: 255.508 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 252000. Time Elapsed: 267.908 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 264000. Time Elapsed: 280.341 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 276000. Time Elapsed: 292.825 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 288000. Time Elapsed: 303.191 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 300000. Time Elapsed: 315.659 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 312000. Time Elapsed: 328.142 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 324000. Time Elapsed: 340.592 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 336000. Time Elapsed: 353.059 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 348000. Time Elapsed: 365.492 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 360000. Time Elapsed: 377.959 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 372000. Time Elapsed: 389.088 s. Mean Reward: 96.092. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 384000. Time Elapsed: 401.421 s. Mean Reward: 65.283. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 396000. Time Elapsed: 415.110 s. Mean Reward: 95.608. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 408000. Time Elapsed: 427.594 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 420000. Time Elapsed: 440.061 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 432000. Time Elapsed: 452.477 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 444000. Time Elapsed: 464.960 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 456000. Time Elapsed: 475.394 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 468000. Time Elapsed: 487.810 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 480000. Time Elapsed: 500.277 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] 3DBallHard. Step: 492000. Time Elapsed: 512.744 s. Mean Reward: 100.000. Mean Group Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_POCA/3DBallHard/3DBallHard-499661.onnx\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_POCA/3DBallHard/3DBallHard-500661.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_POCA/3DBallHard/3DBallHard-500661.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/3DBallHard_POCA/3DBallHard.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_poca_fp = os.path.join(cur_dir, \"config\", \"3DBallHard_poca.yaml\")\n",
    "run_poca_id = \"3DBallHard_POCA\"\n",
    "print(config_poca_fp)\n",
    "print(run_poca_id)\n",
    "\n",
    "!mlagents-learn $config_poca_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_poca_id\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
