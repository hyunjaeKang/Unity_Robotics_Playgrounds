{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# DogeAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8ba6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "output_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"mlagents_learn_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a62e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Unity6000_Envs/Dodge_Attention_Darwin.app\n"
     ]
    }
   ],
   "source": [
    "# Unity Enviroment\n",
    "game = \"Dodge_Attention\"\n",
    "baseport = 1998\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")\n",
    "env_fp = os.path.join(env_dir, env_name)\n",
    "print(env_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a25ba76",
   "metadata": {},
   "source": [
    "## Training PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360531c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Dodge_attention_ppo.yaml\n",
      "Dodge_Att_PPO\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: My Behavior?team=0\n",
      "[INFO] Hyperparameters for behavior name My Behavior: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t512\n",
      "\t  buffer_size:\t5120\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.005\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t1000000\n",
      "\ttime_horizon:\t100\n",
      "\tsummary_freq:\t10000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] My Behavior. Step: 10000. Time Elapsed: 24.555 s. Mean Reward: 4.082. Std of Reward: 4.957. Training.\n",
      "[INFO] My Behavior. Step: 20000. Time Elapsed: 50.070 s. Mean Reward: 4.686. Std of Reward: 5.043. Training.\n",
      "[INFO] My Behavior. Step: 30000. Time Elapsed: 75.568 s. Mean Reward: 5.598. Std of Reward: 5.656. Training.\n",
      "[INFO] My Behavior. Step: 40000. Time Elapsed: 101.337 s. Mean Reward: 4.380. Std of Reward: 4.260. Training.\n",
      "[INFO] My Behavior. Step: 50000. Time Elapsed: 126.971 s. Mean Reward: 5.568. Std of Reward: 4.189. Training.\n",
      "[INFO] My Behavior. Step: 60000. Time Elapsed: 152.104 s. Mean Reward: 7.124. Std of Reward: 4.797. Training.\n",
      "[INFO] My Behavior. Step: 70000. Time Elapsed: 177.944 s. Mean Reward: 6.896. Std of Reward: 4.394. Training.\n",
      "[INFO] My Behavior. Step: 80000. Time Elapsed: 203.445 s. Mean Reward: 8.429. Std of Reward: 5.466. Training.\n",
      "[INFO] My Behavior. Step: 90000. Time Elapsed: 229.133 s. Mean Reward: 7.530. Std of Reward: 4.949. Training.\n",
      "[INFO] My Behavior. Step: 100000. Time Elapsed: 254.846 s. Mean Reward: 8.069. Std of Reward: 5.599. Training.\n",
      "[INFO] My Behavior. Step: 110000. Time Elapsed: 280.264 s. Mean Reward: 7.338. Std of Reward: 4.995. Training.\n",
      "[INFO] My Behavior. Step: 120000. Time Elapsed: 305.852 s. Mean Reward: 8.500. Std of Reward: 5.499. Training.\n",
      "[INFO] My Behavior. Step: 130000. Time Elapsed: 331.445 s. Mean Reward: 7.258. Std of Reward: 4.637. Training.\n",
      "[INFO] My Behavior. Step: 140000. Time Elapsed: 357.046 s. Mean Reward: 7.317. Std of Reward: 4.638. Training.\n",
      "[INFO] My Behavior. Step: 150000. Time Elapsed: 382.696 s. Mean Reward: 7.758. Std of Reward: 5.083. Training.\n",
      "[INFO] My Behavior. Step: 160000. Time Elapsed: 408.055 s. Mean Reward: 8.829. Std of Reward: 5.326. Training.\n",
      "[INFO] My Behavior. Step: 170000. Time Elapsed: 427.450 s. Mean Reward: 7.228. Std of Reward: 4.798. Training.\n",
      "[INFO] My Behavior. Step: 180000. Time Elapsed: 452.979 s. Mean Reward: 7.960. Std of Reward: 4.956. Training.\n",
      "[INFO] My Behavior. Step: 190000. Time Elapsed: 478.650 s. Mean Reward: 7.372. Std of Reward: 4.632. Training.\n",
      "[INFO] My Behavior. Step: 200000. Time Elapsed: 504.035 s. Mean Reward: 9.137. Std of Reward: 5.223. Training.\n",
      "[INFO] My Behavior. Step: 210000. Time Elapsed: 529.852 s. Mean Reward: 7.865. Std of Reward: 5.028. Training.\n",
      "[INFO] My Behavior. Step: 220000. Time Elapsed: 555.638 s. Mean Reward: 8.057. Std of Reward: 5.321. Training.\n",
      "[INFO] My Behavior. Step: 230000. Time Elapsed: 581.041 s. Mean Reward: 8.996. Std of Reward: 5.452. Training.\n",
      "[INFO] My Behavior. Step: 240000. Time Elapsed: 606.832 s. Mean Reward: 8.615. Std of Reward: 5.289. Training.\n",
      "[INFO] My Behavior. Step: 250000. Time Elapsed: 632.285 s. Mean Reward: 8.542. Std of Reward: 5.164. Training.\n",
      "[INFO] My Behavior. Step: 260000. Time Elapsed: 658.012 s. Mean Reward: 8.510. Std of Reward: 5.553. Training.\n",
      "[INFO] My Behavior. Step: 270000. Time Elapsed: 683.604 s. Mean Reward: 8.505. Std of Reward: 5.556. Training.\n",
      "[INFO] My Behavior. Step: 280000. Time Elapsed: 709.205 s. Mean Reward: 8.990. Std of Reward: 5.719. Training.\n",
      "[INFO] My Behavior. Step: 290000. Time Elapsed: 734.829 s. Mean Reward: 7.545. Std of Reward: 4.848. Training.\n",
      "[INFO] My Behavior. Step: 300000. Time Elapsed: 760.390 s. Mean Reward: 8.349. Std of Reward: 5.367. Training.\n",
      "[INFO] My Behavior. Step: 310000. Time Elapsed: 785.972 s. Mean Reward: 9.022. Std of Reward: 5.800. Training.\n",
      "[INFO] My Behavior. Step: 320000. Time Elapsed: 811.523 s. Mean Reward: 9.232. Std of Reward: 5.515. Training.\n",
      "[INFO] My Behavior. Step: 330000. Time Elapsed: 830.734 s. Mean Reward: 8.915. Std of Reward: 5.524. Training.\n",
      "[INFO] My Behavior. Step: 340000. Time Elapsed: 856.552 s. Mean Reward: 9.614. Std of Reward: 5.683. Training.\n",
      "[INFO] My Behavior. Step: 350000. Time Elapsed: 881.947 s. Mean Reward: 9.230. Std of Reward: 5.654. Training.\n",
      "[INFO] My Behavior. Step: 360000. Time Elapsed: 907.404 s. Mean Reward: 7.786. Std of Reward: 5.142. Training.\n",
      "[INFO] My Behavior. Step: 370000. Time Elapsed: 933.292 s. Mean Reward: 10.170. Std of Reward: 5.616. Training.\n",
      "[INFO] My Behavior. Step: 380000. Time Elapsed: 958.883 s. Mean Reward: 8.963. Std of Reward: 5.354. Training.\n",
      "[INFO] My Behavior. Step: 390000. Time Elapsed: 984.652 s. Mean Reward: 10.657. Std of Reward: 5.800. Training.\n",
      "[INFO] My Behavior. Step: 400000. Time Elapsed: 1010.329 s. Mean Reward: 9.205. Std of Reward: 5.428. Training.\n",
      "[INFO] My Behavior. Step: 410000. Time Elapsed: 1035.840 s. Mean Reward: 8.827. Std of Reward: 5.903. Training.\n",
      "[INFO] My Behavior. Step: 420000. Time Elapsed: 1061.836 s. Mean Reward: 9.844. Std of Reward: 5.926. Training.\n",
      "[INFO] My Behavior. Step: 430000. Time Elapsed: 1087.325 s. Mean Reward: 9.498. Std of Reward: 5.602. Training.\n",
      "[INFO] My Behavior. Step: 440000. Time Elapsed: 1112.662 s. Mean Reward: 10.075. Std of Reward: 5.836. Training.\n",
      "[INFO] My Behavior. Step: 450000. Time Elapsed: 1138.432 s. Mean Reward: 9.785. Std of Reward: 5.510. Training.\n",
      "[INFO] My Behavior. Step: 460000. Time Elapsed: 1163.875 s. Mean Reward: 9.012. Std of Reward: 5.726. Training.\n",
      "[INFO] My Behavior. Step: 470000. Time Elapsed: 1189.366 s. Mean Reward: 10.169. Std of Reward: 5.986. Training.\n",
      "[INFO] My Behavior. Step: 480000. Time Elapsed: 1208.749 s. Mean Reward: 9.754. Std of Reward: 5.950. Training.\n",
      "[INFO] My Behavior. Step: 490000. Time Elapsed: 1234.224 s. Mean Reward: 11.386. Std of Reward: 5.449. Training.\n",
      "[INFO] My Behavior. Step: 500000. Time Elapsed: 1259.817 s. Mean Reward: 10.528. Std of Reward: 5.734. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_PPO/My Behavior/My Behavior-499968.onnx\n",
      "[INFO] My Behavior. Step: 510000. Time Elapsed: 1285.771 s. Mean Reward: 9.484. Std of Reward: 5.797. Training.\n",
      "[INFO] My Behavior. Step: 520000. Time Elapsed: 1311.653 s. Mean Reward: 8.471. Std of Reward: 5.899. Training.\n",
      "[INFO] My Behavior. Step: 530000. Time Elapsed: 1337.359 s. Mean Reward: 9.534. Std of Reward: 5.961. Training.\n",
      "[INFO] My Behavior. Step: 540000. Time Elapsed: 1362.714 s. Mean Reward: 9.892. Std of Reward: 5.708. Training.\n",
      "[INFO] My Behavior. Step: 550000. Time Elapsed: 1388.465 s. Mean Reward: 10.585. Std of Reward: 5.933. Training.\n",
      "[INFO] My Behavior. Step: 560000. Time Elapsed: 1414.255 s. Mean Reward: 8.860. Std of Reward: 5.588. Training.\n",
      "[INFO] My Behavior. Step: 570000. Time Elapsed: 1440.155 s. Mean Reward: 9.547. Std of Reward: 5.962. Training.\n",
      "[INFO] My Behavior. Step: 580000. Time Elapsed: 1465.390 s. Mean Reward: 11.093. Std of Reward: 5.856. Training.\n",
      "[INFO] My Behavior. Step: 590000. Time Elapsed: 1491.131 s. Mean Reward: 9.632. Std of Reward: 5.839. Training.\n",
      "[INFO] My Behavior. Step: 600000. Time Elapsed: 1516.948 s. Mean Reward: 11.088. Std of Reward: 6.149. Training.\n",
      "[INFO] My Behavior. Step: 610000. Time Elapsed: 1542.343 s. Mean Reward: 10.660. Std of Reward: 6.051. Training.\n",
      "[INFO] My Behavior. Step: 620000. Time Elapsed: 1567.977 s. Mean Reward: 11.897. Std of Reward: 5.484. Training.\n",
      "[INFO] My Behavior. Step: 630000. Time Elapsed: 1593.493 s. Mean Reward: 10.458. Std of Reward: 5.968. Training.\n",
      "[INFO] My Behavior. Step: 640000. Time Elapsed: 1619.119 s. Mean Reward: 9.600. Std of Reward: 5.881. Training.\n",
      "[INFO] My Behavior. Step: 650000. Time Elapsed: 1638.444 s. Mean Reward: 10.161. Std of Reward: 6.137. Training.\n",
      "[INFO] My Behavior. Step: 660000. Time Elapsed: 1664.239 s. Mean Reward: 10.574. Std of Reward: 5.911. Training.\n",
      "[INFO] My Behavior. Step: 670000. Time Elapsed: 1689.943 s. Mean Reward: 11.160. Std of Reward: 5.776. Training.\n",
      "[INFO] My Behavior. Step: 680000. Time Elapsed: 1715.315 s. Mean Reward: 12.051. Std of Reward: 5.766. Training.\n",
      "[INFO] My Behavior. Step: 690000. Time Elapsed: 1741.264 s. Mean Reward: 10.980. Std of Reward: 6.352. Training.\n",
      "[INFO] My Behavior. Step: 700000. Time Elapsed: 1766.629 s. Mean Reward: 10.054. Std of Reward: 6.329. Training.\n",
      "[INFO] My Behavior. Step: 710000. Time Elapsed: 1792.612 s. Mean Reward: 11.176. Std of Reward: 6.428. Training.\n",
      "[INFO] My Behavior. Step: 720000. Time Elapsed: 1818.064 s. Mean Reward: 11.146. Std of Reward: 5.952. Training.\n",
      "[INFO] My Behavior. Step: 730000. Time Elapsed: 1843.963 s. Mean Reward: 10.493. Std of Reward: 6.361. Training.\n",
      "[INFO] My Behavior. Step: 740000. Time Elapsed: 1869.583 s. Mean Reward: 11.301. Std of Reward: 6.115. Training.\n",
      "[INFO] My Behavior. Step: 750000. Time Elapsed: 1895.227 s. Mean Reward: 10.105. Std of Reward: 6.167. Training.\n",
      "[INFO] My Behavior. Step: 760000. Time Elapsed: 1920.687 s. Mean Reward: 11.279. Std of Reward: 6.073. Training.\n",
      "[INFO] My Behavior. Step: 770000. Time Elapsed: 1946.555 s. Mean Reward: 11.330. Std of Reward: 5.788. Training.\n",
      "[INFO] My Behavior. Step: 780000. Time Elapsed: 1972.594 s. Mean Reward: 10.063. Std of Reward: 5.870. Training.\n",
      "[INFO] My Behavior. Step: 790000. Time Elapsed: 1997.879 s. Mean Reward: 11.454. Std of Reward: 6.289. Training.\n",
      "[INFO] My Behavior. Step: 800000. Time Elapsed: 2017.416 s. Mean Reward: 11.420. Std of Reward: 6.061. Training.\n",
      "[INFO] My Behavior. Step: 810000. Time Elapsed: 2043.025 s. Mean Reward: 11.101. Std of Reward: 5.864. Training.\n",
      "[INFO] My Behavior. Step: 820000. Time Elapsed: 2068.278 s. Mean Reward: 11.541. Std of Reward: 5.933. Training.\n",
      "[INFO] My Behavior. Step: 830000. Time Elapsed: 2093.637 s. Mean Reward: 11.666. Std of Reward: 5.671. Training.\n",
      "[INFO] My Behavior. Step: 840000. Time Elapsed: 2119.326 s. Mean Reward: 10.327. Std of Reward: 5.632. Training.\n",
      "[INFO] My Behavior. Step: 850000. Time Elapsed: 2144.731 s. Mean Reward: 9.972. Std of Reward: 6.076. Training.\n",
      "[INFO] My Behavior. Step: 860000. Time Elapsed: 2170.127 s. Mean Reward: 9.639. Std of Reward: 5.910. Training.\n",
      "[INFO] My Behavior. Step: 870000. Time Elapsed: 2195.393 s. Mean Reward: 11.273. Std of Reward: 5.786. Training.\n",
      "[INFO] My Behavior. Step: 880000. Time Elapsed: 2220.964 s. Mean Reward: 10.736. Std of Reward: 6.082. Training.\n",
      "[INFO] My Behavior. Step: 890000. Time Elapsed: 2246.439 s. Mean Reward: 10.730. Std of Reward: 6.097. Training.\n",
      "[INFO] My Behavior. Step: 900000. Time Elapsed: 2271.998 s. Mean Reward: 12.187. Std of Reward: 5.587. Training.\n",
      "[INFO] My Behavior. Step: 910000. Time Elapsed: 2297.416 s. Mean Reward: 11.649. Std of Reward: 5.873. Training.\n",
      "[INFO] My Behavior. Step: 920000. Time Elapsed: 2323.054 s. Mean Reward: 11.444. Std of Reward: 6.122. Training.\n",
      "[INFO] My Behavior. Step: 930000. Time Elapsed: 2348.694 s. Mean Reward: 11.148. Std of Reward: 6.325. Training.\n",
      "[INFO] My Behavior. Step: 940000. Time Elapsed: 2374.438 s. Mean Reward: 10.879. Std of Reward: 6.197. Training.\n",
      "[INFO] My Behavior. Step: 950000. Time Elapsed: 2393.789 s. Mean Reward: 10.178. Std of Reward: 6.045. Training.\n",
      "[INFO] My Behavior. Step: 960000. Time Elapsed: 2419.291 s. Mean Reward: 11.249. Std of Reward: 6.105. Training.\n",
      "[INFO] My Behavior. Step: 970000. Time Elapsed: 2444.689 s. Mean Reward: 11.170. Std of Reward: 5.700. Training.\n",
      "[INFO] My Behavior. Step: 980000. Time Elapsed: 2469.842 s. Mean Reward: 10.792. Std of Reward: 6.006. Training.\n",
      "[INFO] My Behavior. Step: 990000. Time Elapsed: 2495.140 s. Mean Reward: 11.196. Std of Reward: 5.868. Training.\n",
      "[INFO] My Behavior. Step: 1000000. Time Elapsed: 2520.574 s. Mean Reward: 12.247. Std of Reward: 6.143. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_PPO/My Behavior/My Behavior-999981.onnx\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_PPO/My Behavior/My Behavior-1000030.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_PPO/My Behavior/My Behavior-1000030.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_PPO/My Behavior.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_ppo_fp = os.path.join(cur_dir, \"config\", \"Dodge_attention_ppo.yaml\")\n",
    "run_ppo_id = \"Dodge_Att_PPO\"\n",
    "print(config_ppo_fp)\n",
    "print(run_ppo_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_ppo_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8c3c8",
   "metadata": {},
   "source": [
    "## Training SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "590578c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Dodge_attention_ppo.yaml\n",
      "Dodge_Att_SAC\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: My Behavior?team=0\n",
      "[INFO] Hyperparameters for behavior name My Behavior: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t512\n",
      "\t  buffer_size:\t5120\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.005\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t1000000\n",
      "\ttime_horizon:\t100\n",
      "\tsummary_freq:\t10000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] My Behavior. Step: 10000. Time Elapsed: 24.136 s. Mean Reward: 3.357. Std of Reward: 4.401. Training.\n",
      "[INFO] My Behavior. Step: 20000. Time Elapsed: 49.507 s. Mean Reward: 4.714. Std of Reward: 5.165. Training.\n",
      "[INFO] My Behavior. Step: 30000. Time Elapsed: 75.180 s. Mean Reward: 5.149. Std of Reward: 4.844. Training.\n",
      "[INFO] My Behavior. Step: 40000. Time Elapsed: 100.971 s. Mean Reward: 6.064. Std of Reward: 5.185. Training.\n",
      "[INFO] My Behavior. Step: 50000. Time Elapsed: 126.989 s. Mean Reward: 6.688. Std of Reward: 5.455. Training.\n",
      "[INFO] My Behavior. Step: 60000. Time Elapsed: 152.583 s. Mean Reward: 7.871. Std of Reward: 5.779. Training.\n",
      "[INFO] My Behavior. Step: 70000. Time Elapsed: 178.233 s. Mean Reward: 7.675. Std of Reward: 5.805. Training.\n",
      "[INFO] My Behavior. Step: 80000. Time Elapsed: 203.836 s. Mean Reward: 7.604. Std of Reward: 5.813. Training.\n",
      "[INFO] My Behavior. Step: 90000. Time Elapsed: 229.521 s. Mean Reward: 7.366. Std of Reward: 5.448. Training.\n",
      "[INFO] My Behavior. Step: 100000. Time Elapsed: 254.759 s. Mean Reward: 8.892. Std of Reward: 6.198. Training.\n",
      "[INFO] My Behavior. Step: 110000. Time Elapsed: 280.086 s. Mean Reward: 8.991. Std of Reward: 6.052. Training.\n",
      "[INFO] My Behavior. Step: 120000. Time Elapsed: 305.690 s. Mean Reward: 8.953. Std of Reward: 6.038. Training.\n",
      "[INFO] My Behavior. Step: 130000. Time Elapsed: 331.107 s. Mean Reward: 9.012. Std of Reward: 6.175. Training.\n",
      "[INFO] My Behavior. Step: 140000. Time Elapsed: 356.491 s. Mean Reward: 9.801. Std of Reward: 6.167. Training.\n",
      "[INFO] My Behavior. Step: 150000. Time Elapsed: 381.753 s. Mean Reward: 10.163. Std of Reward: 6.207. Training.\n",
      "[INFO] My Behavior. Step: 160000. Time Elapsed: 407.222 s. Mean Reward: 10.456. Std of Reward: 6.626. Training.\n",
      "[INFO] My Behavior. Step: 170000. Time Elapsed: 426.670 s. Mean Reward: 8.975. Std of Reward: 6.100. Training.\n",
      "[INFO] My Behavior. Step: 180000. Time Elapsed: 452.183 s. Mean Reward: 9.421. Std of Reward: 6.238. Training.\n",
      "[INFO] My Behavior. Step: 190000. Time Elapsed: 477.637 s. Mean Reward: 9.764. Std of Reward: 6.150. Training.\n",
      "[INFO] My Behavior. Step: 200000. Time Elapsed: 503.047 s. Mean Reward: 10.936. Std of Reward: 6.178. Training.\n",
      "[INFO] My Behavior. Step: 210000. Time Elapsed: 528.325 s. Mean Reward: 11.317. Std of Reward: 6.055. Training.\n",
      "[INFO] My Behavior. Step: 220000. Time Elapsed: 554.092 s. Mean Reward: 8.725. Std of Reward: 6.327. Training.\n",
      "[INFO] My Behavior. Step: 230000. Time Elapsed: 579.535 s. Mean Reward: 10.193. Std of Reward: 5.814. Training.\n",
      "[INFO] My Behavior. Step: 240000. Time Elapsed: 604.957 s. Mean Reward: 10.791. Std of Reward: 6.085. Training.\n",
      "[INFO] My Behavior. Step: 250000. Time Elapsed: 630.602 s. Mean Reward: 9.365. Std of Reward: 6.313. Training.\n",
      "[INFO] My Behavior. Step: 260000. Time Elapsed: 656.193 s. Mean Reward: 9.239. Std of Reward: 6.160. Training.\n",
      "[INFO] My Behavior. Step: 270000. Time Elapsed: 681.508 s. Mean Reward: 9.198. Std of Reward: 6.033. Training.\n",
      "[INFO] My Behavior. Step: 280000. Time Elapsed: 706.971 s. Mean Reward: 11.477. Std of Reward: 6.206. Training.\n",
      "[INFO] My Behavior. Step: 290000. Time Elapsed: 732.293 s. Mean Reward: 10.484. Std of Reward: 6.146. Training.\n",
      "[INFO] My Behavior. Step: 300000. Time Elapsed: 758.137 s. Mean Reward: 10.071. Std of Reward: 6.136. Training.\n",
      "[INFO] My Behavior. Step: 310000. Time Elapsed: 783.737 s. Mean Reward: 10.700. Std of Reward: 6.087. Training.\n",
      "[INFO] My Behavior. Step: 320000. Time Elapsed: 803.160 s. Mean Reward: 10.481. Std of Reward: 6.366. Training.\n",
      "[INFO] My Behavior. Step: 330000. Time Elapsed: 828.304 s. Mean Reward: 11.619. Std of Reward: 6.272. Training.\n",
      "[INFO] My Behavior. Step: 340000. Time Elapsed: 853.841 s. Mean Reward: 11.533. Std of Reward: 5.949. Training.\n",
      "[INFO] My Behavior. Step: 350000. Time Elapsed: 879.983 s. Mean Reward: 10.706. Std of Reward: 6.139. Training.\n",
      "[INFO] My Behavior. Step: 360000. Time Elapsed: 906.994 s. Mean Reward: 10.410. Std of Reward: 6.119. Training.\n",
      "[INFO] My Behavior. Step: 370000. Time Elapsed: 932.526 s. Mean Reward: 10.508. Std of Reward: 6.243. Training.\n",
      "[INFO] My Behavior. Step: 380000. Time Elapsed: 958.321 s. Mean Reward: 11.524. Std of Reward: 6.395. Training.\n",
      "[INFO] My Behavior. Step: 390000. Time Elapsed: 983.978 s. Mean Reward: 11.214. Std of Reward: 6.133. Training.\n",
      "[INFO] My Behavior. Step: 400000. Time Elapsed: 1009.637 s. Mean Reward: 11.762. Std of Reward: 6.701. Training.\n",
      "[INFO] My Behavior. Step: 410000. Time Elapsed: 1035.558 s. Mean Reward: 10.139. Std of Reward: 6.260. Training.\n",
      "[INFO] My Behavior. Step: 420000. Time Elapsed: 1061.195 s. Mean Reward: 11.301. Std of Reward: 6.286. Training.\n",
      "[INFO] My Behavior. Step: 430000. Time Elapsed: 1087.195 s. Mean Reward: 9.818. Std of Reward: 6.455. Training.\n",
      "[INFO] My Behavior. Step: 440000. Time Elapsed: 1113.008 s. Mean Reward: 9.514. Std of Reward: 6.260. Training.\n",
      "[INFO] My Behavior. Step: 450000. Time Elapsed: 1138.738 s. Mean Reward: 12.388. Std of Reward: 5.808. Training.\n",
      "[INFO] My Behavior. Step: 460000. Time Elapsed: 1164.433 s. Mean Reward: 11.159. Std of Reward: 6.188. Training.\n",
      "[INFO] My Behavior. Step: 470000. Time Elapsed: 1183.823 s. Mean Reward: 10.958. Std of Reward: 6.345. Training.\n",
      "[INFO] My Behavior. Step: 480000. Time Elapsed: 1209.912 s. Mean Reward: 10.849. Std of Reward: 6.223. Training.\n",
      "[INFO] My Behavior. Step: 490000. Time Elapsed: 1235.636 s. Mean Reward: 11.285. Std of Reward: 6.920. Training.\n",
      "[INFO] My Behavior. Step: 500000. Time Elapsed: 1261.431 s. Mean Reward: 12.077. Std of Reward: 5.865. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_SAC/My Behavior/My Behavior-499931.onnx\n",
      "[INFO] My Behavior. Step: 510000. Time Elapsed: 1287.834 s. Mean Reward: 11.517. Std of Reward: 5.965. Training.\n",
      "[INFO] My Behavior. Step: 520000. Time Elapsed: 1314.389 s. Mean Reward: 11.603. Std of Reward: 6.202. Training.\n",
      "[INFO] My Behavior. Step: 530000. Time Elapsed: 1340.144 s. Mean Reward: 11.392. Std of Reward: 6.177. Training.\n",
      "[INFO] My Behavior. Step: 540000. Time Elapsed: 1366.888 s. Mean Reward: 11.684. Std of Reward: 5.696. Training.\n",
      "[INFO] My Behavior. Step: 550000. Time Elapsed: 1393.618 s. Mean Reward: 12.300. Std of Reward: 6.204. Training.\n",
      "[INFO] My Behavior. Step: 560000. Time Elapsed: 1420.027 s. Mean Reward: 11.951. Std of Reward: 6.264. Training.\n",
      "[INFO] My Behavior. Step: 570000. Time Elapsed: 1446.199 s. Mean Reward: 10.741. Std of Reward: 6.598. Training.\n",
      "[INFO] My Behavior. Step: 580000. Time Elapsed: 1471.939 s. Mean Reward: 12.212. Std of Reward: 5.865. Training.\n",
      "[INFO] My Behavior. Step: 590000. Time Elapsed: 1497.726 s. Mean Reward: 10.313. Std of Reward: 6.239. Training.\n",
      "[INFO] My Behavior. Step: 600000. Time Elapsed: 1523.250 s. Mean Reward: 11.085. Std of Reward: 6.085. Training.\n",
      "[INFO] My Behavior. Step: 610000. Time Elapsed: 1549.091 s. Mean Reward: 12.205. Std of Reward: 5.977. Training.\n",
      "[INFO] My Behavior. Step: 620000. Time Elapsed: 1574.805 s. Mean Reward: 10.837. Std of Reward: 6.148. Training.\n",
      "[INFO] My Behavior. Step: 630000. Time Elapsed: 1594.186 s. Mean Reward: 11.201. Std of Reward: 6.088. Training.\n",
      "[INFO] My Behavior. Step: 640000. Time Elapsed: 1619.841 s. Mean Reward: 12.471. Std of Reward: 6.157. Training.\n",
      "[INFO] My Behavior. Step: 650000. Time Elapsed: 1645.685 s. Mean Reward: 10.999. Std of Reward: 5.912. Training.\n",
      "[INFO] My Behavior. Step: 660000. Time Elapsed: 1671.476 s. Mean Reward: 12.692. Std of Reward: 6.101. Training.\n",
      "[INFO] My Behavior. Step: 670000. Time Elapsed: 1697.357 s. Mean Reward: 10.436. Std of Reward: 6.631. Training.\n",
      "[INFO] My Behavior. Step: 680000. Time Elapsed: 1723.427 s. Mean Reward: 11.692. Std of Reward: 5.956. Training.\n",
      "[INFO] My Behavior. Step: 690000. Time Elapsed: 1750.326 s. Mean Reward: 12.022. Std of Reward: 5.765. Training.\n",
      "[INFO] My Behavior. Step: 700000. Time Elapsed: 1777.126 s. Mean Reward: 12.142. Std of Reward: 6.444. Training.\n",
      "[INFO] My Behavior. Step: 710000. Time Elapsed: 1803.611 s. Mean Reward: 12.079. Std of Reward: 5.893. Training.\n",
      "[INFO] My Behavior. Step: 720000. Time Elapsed: 1829.175 s. Mean Reward: 10.813. Std of Reward: 6.262. Training.\n",
      "[INFO] My Behavior. Step: 730000. Time Elapsed: 1855.230 s. Mean Reward: 11.850. Std of Reward: 5.871. Training.\n",
      "[INFO] My Behavior. Step: 740000. Time Elapsed: 1882.294 s. Mean Reward: 12.769. Std of Reward: 5.815. Training.\n",
      "[INFO] My Behavior. Step: 750000. Time Elapsed: 1909.107 s. Mean Reward: 12.699. Std of Reward: 5.577. Training.\n",
      "[INFO] My Behavior. Step: 760000. Time Elapsed: 1937.192 s. Mean Reward: 11.417. Std of Reward: 6.528. Training.\n",
      "[INFO] My Behavior. Step: 770000. Time Elapsed: 1966.752 s. Mean Reward: 11.733. Std of Reward: 5.930. Training.\n",
      "[INFO] My Behavior. Step: 780000. Time Elapsed: 1989.774 s. Mean Reward: 11.770. Std of Reward: 5.753. Training.\n",
      "[INFO] My Behavior. Step: 790000. Time Elapsed: 2015.897 s. Mean Reward: 11.770. Std of Reward: 6.352. Training.\n",
      "[INFO] My Behavior. Step: 800000. Time Elapsed: 2041.532 s. Mean Reward: 10.764. Std of Reward: 6.665. Training.\n",
      "[INFO] My Behavior. Step: 810000. Time Elapsed: 2067.371 s. Mean Reward: 12.651. Std of Reward: 5.804. Training.\n",
      "[INFO] My Behavior. Step: 820000. Time Elapsed: 2093.636 s. Mean Reward: 12.541. Std of Reward: 5.478. Training.\n",
      "[INFO] My Behavior. Step: 830000. Time Elapsed: 2119.785 s. Mean Reward: 10.820. Std of Reward: 6.110. Training.\n",
      "[INFO] My Behavior. Step: 840000. Time Elapsed: 2145.267 s. Mean Reward: 10.793. Std of Reward: 6.138. Training.\n",
      "[INFO] My Behavior. Step: 850000. Time Elapsed: 2170.577 s. Mean Reward: 11.300. Std of Reward: 6.236. Training.\n",
      "[INFO] My Behavior. Step: 860000. Time Elapsed: 2196.135 s. Mean Reward: 12.028. Std of Reward: 6.227. Training.\n",
      "[INFO] My Behavior. Step: 870000. Time Elapsed: 2222.229 s. Mean Reward: 11.373. Std of Reward: 5.861. Training.\n",
      "[INFO] My Behavior. Step: 880000. Time Elapsed: 2249.052 s. Mean Reward: 11.398. Std of Reward: 6.321. Training.\n",
      "[INFO] My Behavior. Step: 890000. Time Elapsed: 2274.847 s. Mean Reward: 11.144. Std of Reward: 6.265. Training.\n",
      "[INFO] My Behavior. Step: 900000. Time Elapsed: 2300.877 s. Mean Reward: 12.238. Std of Reward: 5.928. Training.\n",
      "[INFO] My Behavior. Step: 910000. Time Elapsed: 2326.875 s. Mean Reward: 11.949. Std of Reward: 6.219. Training.\n",
      "[INFO] My Behavior. Step: 920000. Time Elapsed: 2353.818 s. Mean Reward: 11.973. Std of Reward: 5.858. Training.\n",
      "[INFO] My Behavior. Step: 930000. Time Elapsed: 2381.309 s. Mean Reward: 11.211. Std of Reward: 6.091. Training.\n",
      "[INFO] My Behavior. Step: 940000. Time Elapsed: 2400.692 s. Mean Reward: 11.851. Std of Reward: 5.947. Training.\n",
      "[INFO] My Behavior. Step: 950000. Time Elapsed: 2426.575 s. Mean Reward: 11.949. Std of Reward: 5.892. Training.\n",
      "[INFO] My Behavior. Step: 960000. Time Elapsed: 2452.407 s. Mean Reward: 13.186. Std of Reward: 5.461. Training.\n",
      "[INFO] My Behavior. Step: 970000. Time Elapsed: 2478.610 s. Mean Reward: 12.544. Std of Reward: 5.995. Training.\n",
      "[INFO] My Behavior. Step: 980000. Time Elapsed: 2504.532 s. Mean Reward: 12.258. Std of Reward: 5.782. Training.\n",
      "[INFO] My Behavior. Step: 990000. Time Elapsed: 2530.564 s. Mean Reward: 11.447. Std of Reward: 6.326. Training.\n",
      "[INFO] My Behavior. Step: 1000000. Time Elapsed: 2556.487 s. Mean Reward: 11.605. Std of Reward: 6.247. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_SAC/My Behavior/My Behavior-999922.onnx\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_SAC/My Behavior/My Behavior-1000022.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_SAC/My Behavior/My Behavior-1000022.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_SAC/My Behavior.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_sac_fp = os.path.join(cur_dir, \"config\", \"Dodge_attention_sac.yaml\")\n",
    "run_sac_id = \"Dodge_Att_SAC\"\n",
    "print(config_ppo_fp)\n",
    "print(run_sac_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_sac_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47b032",
   "metadata": {},
   "source": [
    "## Training POCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6886efe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Dodge_attention_poca.yaml\n",
      "Dodge_Att_POCA\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: My Behavior?team=0\n",
      "[INFO] Hyperparameters for behavior name My Behavior: \n",
      "\ttrainer_type:\tpoca\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t512\n",
      "\t  buffer_size:\t5120\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.005\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t1000000\n",
      "\ttime_horizon:\t100\n",
      "\tsummary_freq:\t10000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] My Behavior. Step: 10000. Time Elapsed: 28.951 s. Mean Reward: 3.486. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 20000. Time Elapsed: 61.732 s. Mean Reward: 5.347. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 30000. Time Elapsed: 94.532 s. Mean Reward: 5.267. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 40000. Time Elapsed: 127.152 s. Mean Reward: 6.270. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 50000. Time Elapsed: 160.209 s. Mean Reward: 5.772. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 60000. Time Elapsed: 192.539 s. Mean Reward: 6.870. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 70000. Time Elapsed: 225.329 s. Mean Reward: 7.701. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 80000. Time Elapsed: 258.039 s. Mean Reward: 7.984. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 90000. Time Elapsed: 290.595 s. Mean Reward: 8.105. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 100000. Time Elapsed: 323.959 s. Mean Reward: 9.142. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 110000. Time Elapsed: 359.005 s. Mean Reward: 8.292. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 120000. Time Elapsed: 391.722 s. Mean Reward: 8.511. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 130000. Time Elapsed: 424.508 s. Mean Reward: 9.504. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 140000. Time Elapsed: 457.132 s. Mean Reward: 8.478. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 150000. Time Elapsed: 489.627 s. Mean Reward: 8.179. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 160000. Time Elapsed: 522.274 s. Mean Reward: 7.888. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 170000. Time Elapsed: 554.909 s. Mean Reward: 8.989. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 180000. Time Elapsed: 578.309 s. Mean Reward: 8.986. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 190000. Time Elapsed: 611.121 s. Mean Reward: 9.313. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 200000. Time Elapsed: 643.626 s. Mean Reward: 8.189. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 210000. Time Elapsed: 676.274 s. Mean Reward: 8.866. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 220000. Time Elapsed: 709.102 s. Mean Reward: 9.213. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 230000. Time Elapsed: 741.512 s. Mean Reward: 9.240. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 240000. Time Elapsed: 774.157 s. Mean Reward: 8.570. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 250000. Time Elapsed: 806.638 s. Mean Reward: 8.640. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 260000. Time Elapsed: 839.356 s. Mean Reward: 10.023. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 270000. Time Elapsed: 872.260 s. Mean Reward: 9.949. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 280000. Time Elapsed: 904.815 s. Mean Reward: 9.703. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 290000. Time Elapsed: 937.790 s. Mean Reward: 8.426. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 300000. Time Elapsed: 970.325 s. Mean Reward: 9.474. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 310000. Time Elapsed: 1002.985 s. Mean Reward: 10.005. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 320000. Time Elapsed: 1035.721 s. Mean Reward: 10.080. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 330000. Time Elapsed: 1068.461 s. Mean Reward: 10.440. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 340000. Time Elapsed: 1101.354 s. Mean Reward: 8.671. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 350000. Time Elapsed: 1124.755 s. Mean Reward: 9.317. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 360000. Time Elapsed: 1157.835 s. Mean Reward: 9.932. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 370000. Time Elapsed: 1190.829 s. Mean Reward: 9.336. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 380000. Time Elapsed: 1223.722 s. Mean Reward: 9.910. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 390000. Time Elapsed: 1256.521 s. Mean Reward: 10.374. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 400000. Time Elapsed: 1289.397 s. Mean Reward: 9.395. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 410000. Time Elapsed: 1322.022 s. Mean Reward: 11.919. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 420000. Time Elapsed: 1354.816 s. Mean Reward: 11.338. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 430000. Time Elapsed: 1387.687 s. Mean Reward: 10.442. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 440000. Time Elapsed: 1420.614 s. Mean Reward: 11.472. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 450000. Time Elapsed: 1453.108 s. Mean Reward: 10.429. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 460000. Time Elapsed: 1485.853 s. Mean Reward: 10.589. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 470000. Time Elapsed: 1518.696 s. Mean Reward: 10.963. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 480000. Time Elapsed: 1551.314 s. Mean Reward: 11.664. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 490000. Time Elapsed: 1584.200 s. Mean Reward: 10.064. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 500000. Time Elapsed: 1607.935 s. Mean Reward: 10.616. Mean Group Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_POCA/My Behavior/My Behavior-499964.onnx\n",
      "[INFO] My Behavior. Step: 510000. Time Elapsed: 1640.856 s. Mean Reward: 11.494. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 520000. Time Elapsed: 1674.096 s. Mean Reward: 11.207. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 530000. Time Elapsed: 1707.141 s. Mean Reward: 10.715. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 540000. Time Elapsed: 1739.574 s. Mean Reward: 11.286. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 550000. Time Elapsed: 1772.333 s. Mean Reward: 11.988. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 560000. Time Elapsed: 1805.330 s. Mean Reward: 10.251. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 570000. Time Elapsed: 1837.922 s. Mean Reward: 12.135. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 580000. Time Elapsed: 1870.905 s. Mean Reward: 11.178. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 590000. Time Elapsed: 1903.654 s. Mean Reward: 11.335. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 600000. Time Elapsed: 1936.287 s. Mean Reward: 10.575. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 610000. Time Elapsed: 1969.452 s. Mean Reward: 11.681. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 620000. Time Elapsed: 2002.199 s. Mean Reward: 11.949. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 630000. Time Elapsed: 2035.218 s. Mean Reward: 12.409. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 640000. Time Elapsed: 2068.368 s. Mean Reward: 10.989. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 650000. Time Elapsed: 2091.779 s. Mean Reward: 11.891. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 660000. Time Elapsed: 2124.623 s. Mean Reward: 11.083. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 670000. Time Elapsed: 2157.539 s. Mean Reward: 12.758. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 680000. Time Elapsed: 2190.406 s. Mean Reward: 11.433. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 690000. Time Elapsed: 2223.366 s. Mean Reward: 12.129. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 700000. Time Elapsed: 2256.279 s. Mean Reward: 11.666. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 710000. Time Elapsed: 2289.943 s. Mean Reward: 11.447. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 720000. Time Elapsed: 2323.079 s. Mean Reward: 11.227. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 730000. Time Elapsed: 2355.897 s. Mean Reward: 11.941. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 740000. Time Elapsed: 2388.504 s. Mean Reward: 12.162. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 750000. Time Elapsed: 2421.655 s. Mean Reward: 12.184. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 760000. Time Elapsed: 2454.620 s. Mean Reward: 10.989. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 770000. Time Elapsed: 2487.337 s. Mean Reward: 11.463. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 780000. Time Elapsed: 2520.051 s. Mean Reward: 12.120. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 790000. Time Elapsed: 2552.985 s. Mean Reward: 12.538. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 800000. Time Elapsed: 2576.709 s. Mean Reward: 13.010. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 810000. Time Elapsed: 2609.167 s. Mean Reward: 12.304. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 820000. Time Elapsed: 2642.001 s. Mean Reward: 12.005. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 830000. Time Elapsed: 2674.409 s. Mean Reward: 12.327. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 840000. Time Elapsed: 2707.561 s. Mean Reward: 11.952. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 850000. Time Elapsed: 2740.171 s. Mean Reward: 11.553. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 860000. Time Elapsed: 2773.268 s. Mean Reward: 11.764. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 870000. Time Elapsed: 2806.028 s. Mean Reward: 10.895. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 880000. Time Elapsed: 2838.753 s. Mean Reward: 12.072. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 890000. Time Elapsed: 2871.608 s. Mean Reward: 11.545. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 900000. Time Elapsed: 2904.252 s. Mean Reward: 11.187. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 910000. Time Elapsed: 2936.839 s. Mean Reward: 10.563. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 920000. Time Elapsed: 2969.571 s. Mean Reward: 12.250. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 930000. Time Elapsed: 3002.133 s. Mean Reward: 10.972. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 940000. Time Elapsed: 3034.918 s. Mean Reward: 12.234. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 950000. Time Elapsed: 3068.001 s. Mean Reward: 12.570. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 960000. Time Elapsed: 3091.782 s. Mean Reward: 12.161. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 970000. Time Elapsed: 3124.163 s. Mean Reward: 12.089. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 980000. Time Elapsed: 3156.828 s. Mean Reward: 10.973. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 990000. Time Elapsed: 3189.429 s. Mean Reward: 11.632. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1000000. Time Elapsed: 3222.115 s. Mean Reward: 11.894. Mean Group Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_POCA/My Behavior/My Behavior-999975.onnx\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_POCA/My Behavior/My Behavior-1000036.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_POCA/My Behavior/My Behavior-1000036.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Dodge_Att_POCA/My Behavior.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_poca_fp = os.path.join(cur_dir, \"config\", \"Dodge_attention_poca.yaml\")\n",
    "run_poca_id = \"Dodge_Att_POCA\"\n",
    "print(config_poca_fp)\n",
    "print(run_poca_id)\n",
    "\n",
    "!mlagents-learn $config_poca_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_poca_id --base-port=$baseport\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
