{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# Dodge_PPO_Curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d197bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import datetime\n",
    "import platform\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from mlagents_envs.environment import UnityEnvironment, ActionTuple\n",
    "from mlagents_envs.side_channel.engine_configuration_channel\\\n",
    "                             import EngineConfigurationChannel\n",
    "from mlagents_envs.side_channel.environment_parameters_channel\\\n",
    "                             import EnvironmentParametersChannel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2fb148",
   "metadata": {},
   "source": [
    "## Setting environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8093df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "test_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"pytorch_output\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d33761",
   "metadata": {},
   "source": [
    "### Pytorch Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "521fc2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Pytorch Device\n",
    "if torch.backends.mps.is_available():\n",
    "    g_device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    g_device = torch.device(\"cuda\")\n",
    "else:\n",
    "    g_device = torch.device(\"cpu\")\n",
    "\n",
    "print(g_device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485c2ea",
   "metadata": {},
   "source": [
    "### Unity Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f1e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unity Enviroment\n",
    "game = \"Dodge\"\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be65174e",
   "metadata": {},
   "source": [
    "### Seting parameters for PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ee7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seting parameters for PPO\n",
    "state_size = 122\n",
    "action_size = 5\n",
    "\n",
    "load_model = False\n",
    "train_mode = True\n",
    "\n",
    "discount_factor = 0.99\n",
    "learning_rate = 3e-4\n",
    "n_step = 128\n",
    "batch_size = 128\n",
    "n_epoch = 3\n",
    "_lambda = 0.95\n",
    "epsilon = 0.2\n",
    "\n",
    "run_step = 2000000 if train_mode else 0\n",
    "test_step = 100000\n",
    "\n",
    "print_interval = 10\n",
    "save_interval = 100\n",
    "\n",
    "# Parameters for Curriculum\n",
    "\n",
    "curriculum_level = 0\n",
    "\n",
    "curriculum_parameters = \\\n",
    "    [\n",
    "        {\"boardRadius\": 8.0, \"ballSpeed\": 2.0, \"ballNums\": 8},\n",
    "        {\"boardRadius\": 7.5, \"ballSpeed\": 2.5, \"ballNums\": 10},\n",
    "        {\"boardRadius\": 7.0, \"ballSpeed\": 3.0, \"ballNums\": 12},\n",
    "    ]\n",
    "\n",
    "curriculum_threshold = [0.2, 0.4, 1.0]\n",
    "\n",
    "# Setting parameters for Dodge Environments\n",
    "env_static_config = {\"ballSpeed\": 4, \"ballRandom\": 0.2, \"agentSpeed\": 3}\n",
    "env_dynamic_config = {\"boardRadius\": {\"min\":6, \"max\": 8, \"seed\": 77},\n",
    "                      \"ballNums\": {\"min\": 10, \"max\": 15, \"seed\": 77}}\n",
    "\n",
    "unity_base_port = 1801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce97f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN model : Save and Load\n",
    "date_time = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "save_path = os.path.join(test_dir, f\"saved_models/{game}/PPO_Curriculum/{date_time}\")\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "save_model_path = os.path.join(save_path, 'Dodge_PPO_Curriculum.ckpt')\n",
    "# print(f\"save_path :{save_path}\")\n",
    "# print(f\"save_model_path :{save_model_path}\")\n",
    "load_path = \"\" # Need to update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aded1f",
   "metadata": {},
   "source": [
    "## Model for Actor-Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa3fdab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.d1 = torch.nn.Linear(state_size, 128)\n",
    "        self.d2 = torch.nn.Linear(128, 128)\n",
    "        self.pi = torch.nn.Linear(128, action_size)\n",
    "        self.v = torch.nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.d1(x))\n",
    "        x = F.relu(self.d2(x))\n",
    "        return F.softmax(self.pi(x), dim=-1), self.v(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41c622",
   "metadata": {},
   "source": [
    "## Agent class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af439a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Class\n",
    "class PPOAgent:\n",
    "    def __init__(self):\n",
    "        self.network = ActorCritic().to(g_device)\n",
    "        self.optimizer = torch.optim.Adam(self.network.parameters(), lr = learning_rate)\n",
    "        self.memory = list()\n",
    "        self.writer = SummaryWriter(save_path)\n",
    "\n",
    "        if load_model == True:\n",
    "            print(f\"... Load Model from {load_path} ...\")\n",
    "            checkpoint = torch.load(load_path, map_location=g_device)\n",
    "            self.network.load_state_dict(checkpoint[\"network\"])\n",
    "            self.optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    def get_action(self, state, training = True):\n",
    "        self.network.train(training)\n",
    "        pi, _ = self.network(torch.FloatTensor(state).to(g_device))\n",
    "        action = torch.multinomial(pi, num_samples=1).cpu().numpy()\n",
    "        return action\n",
    "\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def train_model(self):\n",
    "        self.network.train()\n",
    "\n",
    "        state      = np.stack([m[0] for m in self.memory], axis=0)\n",
    "        action     = np.stack([m[1] for m in self.memory], axis=0)\n",
    "        reward     = np.stack([m[2] for m in self.memory], axis=0)\n",
    "        next_state = np.stack([m[3] for m in self.memory], axis=0)\n",
    "        done       = np.stack([m[4] for m in self.memory], axis=0)\n",
    "        self.memory.clear()\n",
    "\n",
    "        state, action, reward, next_state, done = map(lambda x: torch.FloatTensor(x).to(g_device),\n",
    "                                                        [state, action, reward, next_state, done])\n",
    "        # prob_old, adv, ret\n",
    "        with torch.no_grad():\n",
    "            pi_old, value = self.network(state)\n",
    "            prob_old = pi_old.gather(1, action.long())\n",
    "\n",
    "            _, next_value = self.network(next_state)\n",
    "            delta = reward + (1 - done) * discount_factor * next_value - value\n",
    "            adv = delta.clone()\n",
    "            adv, done = map(lambda x: x.view(n_step, -1).transpose(0,1).contiguous(), [adv, done])\n",
    "            for t in reversed(range(n_step-1)):\n",
    "                adv[:, t] += (1 - done[:, t]) * discount_factor * _lambda * adv[:, t+1]\n",
    "            adv = adv.transpose(0,1).contiguous().view(-1, 1)\n",
    "\n",
    "            ret = adv + value\n",
    "\n",
    "        # training\n",
    "        actor_losses, critic_losses = [], []\n",
    "        idxs = np.arange(len(reward))\n",
    "        for _ in range(n_epoch):\n",
    "            np.random.shuffle(idxs)\n",
    "            for offset in range(0, len(reward), batch_size):\n",
    "                idx = idxs[offset : offset + batch_size]\n",
    "\n",
    "                _state, _action, _ret, _adv, _prob_old =\\\n",
    "                    map(lambda x: x[idx], [state, action, ret, adv, prob_old])\n",
    "\n",
    "                pi, value = self.network(_state)\n",
    "                prob = pi.gather(1, _action.long())\n",
    "\n",
    "                # loss function for policy network\n",
    "                ratio = prob / (_prob_old + 1e-7)\n",
    "                surr1 = ratio * _adv\n",
    "                surr2 = torch.clamp(ratio, min=1-epsilon, max=1+epsilon) * _adv\n",
    "                actor_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "                # loss function for value network\n",
    "                critic_loss = F.mse_loss(value, _ret).mean()\n",
    "\n",
    "                total_loss = actor_loss + critic_loss\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                actor_losses.append(actor_loss.item())\n",
    "                critic_losses.append(critic_loss.item())\n",
    "\n",
    "        return np.mean(actor_losses), np.mean(critic_losses)\n",
    "\n",
    "\n",
    "    def save_model(self):\n",
    "        print(f\"... Save Model to {save_path}/ckpt ...\")\n",
    "        torch.save({\n",
    "            \"network\" : self.network.state_dict(),\n",
    "            \"optimizer\" : self.optimizer.state_dict(),\n",
    "        }, save_model_path)\n",
    "\n",
    "    def write_summary(self, score, actor_loss, critic_loss, step):\n",
    "        self.writer.add_scalar(\"PPO_Random_run/score\", score, step)\n",
    "        self.writer.add_scalar(\"PPO_Random_model/actor_loss\", actor_loss, step)\n",
    "        self.writer.add_scalar(\"PPO_Random_model/critic_loss\", critic_loss, step)\n",
    "        # self.writer.add_scalar(\"PPO_Random_model/total_loss\", total_loss, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b01e40",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0558bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "10 Episode / Step: 1932 / Score: 18.23 / Actor loss: -0.52 / Critic loss: 1.0564\n",
      "20 Episode / Step: 5492 / Score: 34.50 / Actor loss: -0.02 / Critic loss: 1.1241\n",
      "30 Episode / Step: 8074 / Score: 24.72 / Actor loss: -0.00 / Critic loss: 1.0359\n",
      "40 Episode / Step: 10853 / Score: 26.69 / Actor loss: 0.00 / Critic loss: 1.0584\n",
      "50 Episode / Step: 14187 / Score: 32.24 / Actor loss: -0.02 / Critic loss: 0.9381\n",
      "60 Episode / Step: 17535 / Score: 32.38 / Actor loss: -0.03 / Critic loss: 0.9168\n",
      "70 Episode / Step: 21458 / Score: 38.13 / Actor loss: 0.01 / Critic loss: 0.7902\n",
      "80 Episode / Step: 25093 / Score: 35.25 / Actor loss: -0.02 / Critic loss: 0.7851\n",
      "90 Episode / Step: 28614 / Score: 34.11 / Actor loss: -0.04 / Critic loss: 0.7917\n",
      "100 Episode / Step: 31366 / Score: 26.42 / Actor loss: 0.03 / Critic loss: 0.9218\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "110 Episode / Step: 34494 / Score: 30.18 / Actor loss: -0.02 / Critic loss: 0.9029\n",
      "120 Episode / Step: 37750 / Score: 31.46 / Actor loss: -0.06 / Critic loss: 0.7955\n",
      "130 Episode / Step: 41190 / Score: 33.30 / Actor loss: -0.02 / Critic loss: 0.8353\n",
      "140 Episode / Step: 44333 / Score: 30.33 / Actor loss: -0.00 / Critic loss: 0.7005\n",
      "150 Episode / Step: 47631 / Score: 31.88 / Actor loss: -0.03 / Critic loss: 0.7888\n",
      "160 Episode / Step: 50254 / Score: 25.13 / Actor loss: 0.00 / Critic loss: 0.8212\n",
      "170 Episode / Step: 52660 / Score: 22.96 / Actor loss: -0.02 / Critic loss: 0.8644\n",
      "180 Episode / Step: 55647 / Score: 28.77 / Actor loss: 0.01 / Critic loss: 0.9238\n",
      "190 Episode / Step: 58661 / Score: 29.04 / Actor loss: 0.01 / Critic loss: 0.9282\n",
      "200 Episode / Step: 62184 / Score: 34.13 / Actor loss: -0.04 / Critic loss: 0.7258\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "210 Episode / Step: 65032 / Score: 27.38 / Actor loss: -0.01 / Critic loss: 0.7792\n",
      "220 Episode / Step: 67492 / Score: 23.50 / Actor loss: 0.01 / Critic loss: 0.8175\n",
      "230 Episode / Step: 70837 / Score: 32.35 / Actor loss: 0.01 / Critic loss: 0.7953\n",
      "240 Episode / Step: 74015 / Score: 30.68 / Actor loss: 0.01 / Critic loss: 0.7433\n",
      "250 Episode / Step: 77452 / Score: 33.27 / Actor loss: -0.02 / Critic loss: 0.7252\n",
      "260 Episode / Step: 80853 / Score: 32.91 / Actor loss: -0.02 / Critic loss: 0.8171\n",
      "270 Episode / Step: 83588 / Score: 26.25 / Actor loss: 0.05 / Critic loss: 0.7634\n",
      "280 Episode / Step: 87244 / Score: 35.46 / Actor loss: -0.01 / Critic loss: 0.7331\n",
      "290 Episode / Step: 90521 / Score: 31.67 / Actor loss: -0.02 / Critic loss: 0.7320\n",
      "300 Episode / Step: 93304 / Score: 26.73 / Actor loss: 0.02 / Critic loss: 0.7760\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "310 Episode / Step: 96701 / Score: 32.87 / Actor loss: -0.01 / Critic loss: 0.6986\n",
      "320 Episode / Step: 99082 / Score: 22.71 / Actor loss: 0.02 / Critic loss: 0.7712\n",
      "330 Episode / Step: 101707 / Score: 25.15 / Actor loss: 0.06 / Critic loss: 0.8725\n",
      "340 Episode / Step: 105209 / Score: 33.92 / Actor loss: 0.04 / Critic loss: 0.7827\n",
      "350 Episode / Step: 108484 / Score: 31.65 / Actor loss: 0.02 / Critic loss: 0.7869\n",
      "360 Episode / Step: 110717 / Score: 21.23 / Actor loss: 0.00 / Critic loss: 0.7978\n",
      "370 Episode / Step: 114486 / Score: 36.59 / Actor loss: -0.01 / Critic loss: 0.7225\n",
      "380 Episode / Step: 117835 / Score: 32.39 / Actor loss: 0.01 / Critic loss: 0.8467\n",
      "390 Episode / Step: 121735 / Score: 37.90 / Actor loss: 0.01 / Critic loss: 0.7009\n",
      "400 Episode / Step: 124013 / Score: 21.68 / Actor loss: -0.01 / Critic loss: 0.8413\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "410 Episode / Step: 127169 / Score: 30.46 / Actor loss: 0.00 / Critic loss: 1.0930\n",
      "420 Episode / Step: 128812 / Score: 15.33 / Actor loss: 0.09 / Critic loss: 1.2797\n",
      "430 Episode / Step: 130634 / Score: 17.12 / Actor loss: 0.02 / Critic loss: 1.0147\n",
      "440 Episode / Step: 133744 / Score: 30.00 / Actor loss: 0.05 / Critic loss: 0.9362\n",
      "450 Episode / Step: 136510 / Score: 26.56 / Actor loss: 0.01 / Critic loss: 0.8222\n",
      "460 Episode / Step: 139135 / Score: 25.15 / Actor loss: -0.02 / Critic loss: 0.6825\n",
      "470 Episode / Step: 143167 / Score: 39.22 / Actor loss: 0.00 / Critic loss: 0.7319\n",
      "480 Episode / Step: 145884 / Score: 26.07 / Actor loss: 0.03 / Critic loss: 0.8338\n",
      "490 Episode / Step: 148375 / Score: 23.81 / Actor loss: -0.09 / Critic loss: 0.7862\n",
      "500 Episode / Step: 151875 / Score: 33.90 / Actor loss: -0.01 / Critic loss: 0.8629\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "510 Episode / Step: 154433 / Score: 24.48 / Actor loss: 0.00 / Critic loss: 1.0165\n",
      "520 Episode / Step: 157364 / Score: 28.21 / Actor loss: -0.03 / Critic loss: 0.8792\n",
      "530 Episode / Step: 162073 / Score: 45.99 / Actor loss: -0.04 / Critic loss: 0.9248\n",
      "540 Episode / Step: 166249 / Score: 40.66 / Actor loss: -0.03 / Critic loss: 0.8549\n",
      "550 Episode / Step: 168776 / Score: 24.17 / Actor loss: -0.03 / Critic loss: 0.9174\n",
      "560 Episode / Step: 173143 / Score: 42.57 / Actor loss: -0.00 / Critic loss: 1.0663\n",
      "570 Episode / Step: 177048 / Score: 37.95 / Actor loss: -0.05 / Critic loss: 0.8779\n",
      "580 Episode / Step: 180372 / Score: 32.14 / Actor loss: -0.02 / Critic loss: 0.9376\n",
      "590 Episode / Step: 183993 / Score: 35.11 / Actor loss: -0.01 / Critic loss: 0.7702\n",
      "600 Episode / Step: 187769 / Score: 36.66 / Actor loss: 0.02 / Critic loss: 0.8830\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "610 Episode / Step: 190382 / Score: 25.03 / Actor loss: 0.01 / Critic loss: 0.8121\n",
      "620 Episode / Step: 194070 / Score: 35.78 / Actor loss: -0.03 / Critic loss: 0.8587\n",
      "630 Episode / Step: 197975 / Score: 37.95 / Actor loss: -0.01 / Critic loss: 0.8017\n",
      "640 Episode / Step: 202405 / Score: 43.20 / Actor loss: -0.02 / Critic loss: 0.8113\n",
      "650 Episode / Step: 205943 / Score: 34.28 / Actor loss: 0.03 / Critic loss: 0.9082\n",
      "660 Episode / Step: 211276 / Score: 52.23 / Actor loss: -0.02 / Critic loss: 0.7806\n",
      "670 Episode / Step: 215839 / Score: 44.53 / Actor loss: -0.04 / Critic loss: 0.7991\n",
      "680 Episode / Step: 219688 / Score: 37.39 / Actor loss: -0.01 / Critic loss: 0.8233\n",
      "690 Episode / Step: 223527 / Score: 37.29 / Actor loss: -0.01 / Critic loss: 0.8364\n",
      "700 Episode / Step: 227758 / Score: 41.21 / Actor loss: 0.01 / Critic loss: 0.7906\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "710 Episode / Step: 232673 / Score: 48.05 / Actor loss: -0.02 / Critic loss: 0.7581\n",
      "720 Episode / Step: 236150 / Score: 33.67 / Actor loss: -0.06 / Critic loss: 0.8068\n",
      "730 Episode / Step: 240083 / Score: 38.23 / Actor loss: -0.04 / Critic loss: 0.7297\n",
      "740 Episode / Step: 244457 / Score: 42.64 / Actor loss: 0.01 / Critic loss: 0.8732\n",
      "750 Episode / Step: 248334 / Score: 37.67 / Actor loss: -0.04 / Critic loss: 0.7769\n",
      "760 Episode / Step: 252487 / Score: 40.43 / Actor loss: -0.03 / Critic loss: 0.8385\n",
      "770 Episode / Step: 256037 / Score: 34.40 / Actor loss: 0.02 / Critic loss: 0.8295\n",
      "780 Episode / Step: 258786 / Score: 26.39 / Actor loss: -0.05 / Critic loss: 0.7972\n",
      "790 Episode / Step: 262413 / Score: 35.17 / Actor loss: -0.01 / Critic loss: 0.9381\n",
      "800 Episode / Step: 266314 / Score: 37.91 / Actor loss: -0.05 / Critic loss: 0.8533\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "810 Episode / Step: 269967 / Score: 35.43 / Actor loss: -0.02 / Critic loss: 1.1155\n",
      "820 Episode / Step: 273502 / Score: 34.25 / Actor loss: 0.02 / Critic loss: 1.0230\n",
      "830 Episode / Step: 276860 / Score: 32.48 / Actor loss: -0.00 / Critic loss: 1.1859\n",
      "840 Episode / Step: 280235 / Score: 32.65 / Actor loss: -0.03 / Critic loss: 1.0380\n",
      "850 Episode / Step: 282814 / Score: 24.69 / Actor loss: 0.02 / Critic loss: 0.9929\n",
      "860 Episode / Step: 286896 / Score: 39.72 / Actor loss: -0.03 / Critic loss: 0.8203\n",
      "870 Episode / Step: 290828 / Score: 38.22 / Actor loss: -0.03 / Critic loss: 0.8763\n",
      "880 Episode / Step: 295261 / Score: 43.23 / Actor loss: 0.02 / Critic loss: 0.8805\n",
      "890 Episode / Step: 298281 / Score: 29.10 / Actor loss: -0.03 / Critic loss: 0.7758\n",
      "900 Episode / Step: 301913 / Score: 35.22 / Actor loss: -0.05 / Critic loss: 0.8107\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "910 Episode / Step: 304828 / Score: 28.05 / Actor loss: 0.03 / Critic loss: 0.9155\n",
      "920 Episode / Step: 308260 / Score: 33.22 / Actor loss: -0.04 / Critic loss: 0.8979\n",
      "930 Episode / Step: 312175 / Score: 38.05 / Actor loss: -0.03 / Critic loss: 0.8031\n",
      "940 Episode / Step: 317506 / Score: 52.21 / Actor loss: 0.01 / Critic loss: 0.7624\n",
      "950 Episode / Step: 320468 / Score: 28.52 / Actor loss: -0.04 / Critic loss: 0.7694\n",
      "960 Episode / Step: 324313 / Score: 37.35 / Actor loss: 0.00 / Critic loss: 0.8397\n",
      "970 Episode / Step: 328438 / Score: 40.15 / Actor loss: 0.02 / Critic loss: 0.7908\n",
      "980 Episode / Step: 332133 / Score: 35.85 / Actor loss: 0.02 / Critic loss: 0.9448\n",
      "990 Episode / Step: 335651 / Score: 34.08 / Actor loss: -0.02 / Critic loss: 0.8546\n",
      "1000 Episode / Step: 339987 / Score: 42.26 / Actor loss: -0.00 / Critic loss: 0.8957\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "1010 Episode / Step: 342229 / Score: 21.32 / Actor loss: -0.02 / Critic loss: 0.8172\n",
      "1020 Episode / Step: 344993 / Score: 26.54 / Actor loss: -0.02 / Critic loss: 0.9279\n",
      "1030 Episode / Step: 347908 / Score: 28.05 / Actor loss: 0.00 / Critic loss: 0.8500\n",
      "1040 Episode / Step: 350237 / Score: 22.19 / Actor loss: -0.01 / Critic loss: 0.8748\n",
      "1050 Episode / Step: 352856 / Score: 25.09 / Actor loss: -0.07 / Critic loss: 1.0104\n",
      "1060 Episode / Step: 356231 / Score: 32.65 / Actor loss: -0.01 / Critic loss: 0.9820\n",
      "1070 Episode / Step: 358787 / Score: 24.46 / Actor loss: 0.04 / Critic loss: 1.0317\n",
      "1080 Episode / Step: 361849 / Score: 29.52 / Actor loss: -0.05 / Critic loss: 0.8932\n",
      "1090 Episode / Step: 366405 / Score: 44.46 / Actor loss: -0.02 / Critic loss: 0.8942\n",
      "1100 Episode / Step: 371241 / Score: 47.26 / Actor loss: -0.02 / Critic loss: 0.8818\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "1110 Episode / Step: 374536 / Score: 31.85 / Actor loss: 0.00 / Critic loss: 0.9545\n",
      "1120 Episode / Step: 378114 / Score: 34.68 / Actor loss: -0.02 / Critic loss: 0.9167\n",
      "1130 Episode / Step: 381628 / Score: 34.04 / Actor loss: -0.04 / Critic loss: 0.8968\n",
      "1140 Episode / Step: 386387 / Score: 46.49 / Actor loss: -0.07 / Critic loss: 0.7713\n",
      "1150 Episode / Step: 390938 / Score: 44.41 / Actor loss: -0.01 / Critic loss: 0.9455\n",
      "1160 Episode / Step: 395040 / Score: 39.92 / Actor loss: -0.03 / Critic loss: 0.9159\n",
      "1170 Episode / Step: 399927 / Score: 47.77 / Actor loss: 0.03 / Critic loss: 0.9110\n",
      "the level has been increased --> 1\n",
      "1180 Episode / Step: 403803 / Score: 37.66 / Actor loss: -0.00 / Critic loss: 1.0323\n",
      "1190 Episode / Step: 406422 / Score: 25.09 / Actor loss: -0.00 / Critic loss: 1.0574\n",
      "1200 Episode / Step: 409596 / Score: 30.64 / Actor loss: -0.02 / Critic loss: 1.1056\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "1210 Episode / Step: 412221 / Score: 25.15 / Actor loss: 0.01 / Critic loss: 1.1970\n",
      "1220 Episode / Step: 414292 / Score: 19.61 / Actor loss: -0.03 / Critic loss: 1.0151\n",
      "1230 Episode / Step: 417188 / Score: 27.86 / Actor loss: -0.02 / Critic loss: 1.0584\n",
      "1240 Episode / Step: 419328 / Score: 20.30 / Actor loss: -0.02 / Critic loss: 1.0762\n",
      "1250 Episode / Step: 422966 / Score: 35.28 / Actor loss: -0.03 / Critic loss: 0.9164\n",
      "1260 Episode / Step: 426590 / Score: 35.14 / Actor loss: 0.01 / Critic loss: 1.1041\n",
      "1270 Episode / Step: 430538 / Score: 38.38 / Actor loss: 0.04 / Critic loss: 1.2805\n",
      "1280 Episode / Step: 434074 / Score: 34.26 / Actor loss: 0.01 / Critic loss: 1.2391\n",
      "1290 Episode / Step: 435992 / Score: 18.08 / Actor loss: 0.04 / Critic loss: 1.2223\n",
      "1300 Episode / Step: 438530 / Score: 24.28 / Actor loss: -0.01 / Critic loss: 1.1086\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "1310 Episode / Step: 441239 / Score: 25.99 / Actor loss: -0.05 / Critic loss: 0.9881\n",
      "1320 Episode / Step: 444124 / Score: 27.75 / Actor loss: 0.01 / Critic loss: 0.8938\n",
      "1330 Episode / Step: 446477 / Score: 22.43 / Actor loss: -0.03 / Critic loss: 0.9532\n",
      "1340 Episode / Step: 449926 / Score: 33.39 / Actor loss: -0.07 / Critic loss: 0.8663\n",
      "1350 Episode / Step: 453876 / Score: 38.40 / Actor loss: 0.00 / Critic loss: 1.0277\n",
      "1360 Episode / Step: 456853 / Score: 28.67 / Actor loss: 0.05 / Critic loss: 1.3617\n",
      "1370 Episode / Step: 460518 / Score: 35.55 / Actor loss: -0.05 / Critic loss: 1.1176\n",
      "1380 Episode / Step: 463953 / Score: 33.25 / Actor loss: 0.01 / Critic loss: 1.0336\n",
      "1390 Episode / Step: 468248 / Score: 41.85 / Actor loss: 0.01 / Critic loss: 1.0275\n",
      "1400 Episode / Step: 471306 / Score: 29.48 / Actor loss: -0.01 / Critic loss: 1.0449\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "1410 Episode / Step: 474475 / Score: 30.59 / Actor loss: -0.01 / Critic loss: 0.9973\n",
      "1420 Episode / Step: 478751 / Score: 41.66 / Actor loss: -0.00 / Critic loss: 1.0792\n",
      "1430 Episode / Step: 483521 / Score: 46.60 / Actor loss: 0.02 / Critic loss: 1.1205\n",
      "1440 Episode / Step: 486362 / Score: 27.31 / Actor loss: 0.01 / Critic loss: 1.1312\n",
      "1450 Episode / Step: 489857 / Score: 33.85 / Actor loss: -0.01 / Critic loss: 1.1634\n",
      "1460 Episode / Step: 493269 / Score: 33.02 / Actor loss: -0.02 / Critic loss: 1.0332\n",
      "1470 Episode / Step: 497887 / Score: 45.08 / Actor loss: 0.03 / Critic loss: 1.0081\n",
      "1480 Episode / Step: 501995 / Score: 39.98 / Actor loss: -0.02 / Critic loss: 1.0662\n",
      "1490 Episode / Step: 506696 / Score: 45.91 / Actor loss: 0.01 / Critic loss: 0.9909\n",
      "1500 Episode / Step: 510005 / Score: 31.99 / Actor loss: 0.02 / Critic loss: 1.1325\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "1510 Episode / Step: 514476 / Score: 43.61 / Actor loss: 0.01 / Critic loss: 1.0379\n",
      "1520 Episode / Step: 517838 / Score: 32.52 / Actor loss: 0.01 / Critic loss: 1.0749\n",
      "1530 Episode / Step: 521239 / Score: 32.91 / Actor loss: 0.01 / Critic loss: 1.0216\n",
      "1540 Episode / Step: 525465 / Score: 41.16 / Actor loss: 0.05 / Critic loss: 1.0961\n",
      "1550 Episode / Step: 530139 / Score: 45.64 / Actor loss: -0.02 / Critic loss: 0.9690\n",
      "1560 Episode / Step: 533885 / Score: 36.36 / Actor loss: 0.02 / Critic loss: 1.0292\n",
      "1570 Episode / Step: 538138 / Score: 41.43 / Actor loss: 0.02 / Critic loss: 0.9439\n",
      "1580 Episode / Step: 542874 / Score: 46.26 / Actor loss: -0.04 / Critic loss: 0.9405\n",
      "1590 Episode / Step: 547168 / Score: 41.84 / Actor loss: 0.02 / Critic loss: 1.0709\n",
      "1600 Episode / Step: 552553 / Score: 52.75 / Actor loss: -0.01 / Critic loss: 0.9024\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "1610 Episode / Step: 558985 / Score: 63.22 / Actor loss: 0.01 / Critic loss: 0.9771\n",
      "1620 Episode / Step: 563563 / Score: 44.68 / Actor loss: -0.00 / Critic loss: 0.9696\n",
      "1630 Episode / Step: 569276 / Score: 56.03 / Actor loss: 0.01 / Critic loss: 0.9996\n",
      "1640 Episode / Step: 573483 / Score: 40.97 / Actor loss: 0.03 / Critic loss: 0.9688\n",
      "1650 Episode / Step: 579938 / Score: 63.45 / Actor loss: -0.01 / Critic loss: 0.8110\n",
      "1660 Episode / Step: 585463 / Score: 54.15 / Actor loss: -0.01 / Critic loss: 1.0390\n",
      "1670 Episode / Step: 589004 / Score: 34.31 / Actor loss: 0.04 / Critic loss: 1.0624\n",
      "1680 Episode / Step: 592818 / Score: 37.04 / Actor loss: -0.02 / Critic loss: 1.1083\n",
      "1690 Episode / Step: 597500 / Score: 45.72 / Actor loss: -0.01 / Critic loss: 0.9380\n",
      "1700 Episode / Step: 602363 / Score: 47.53 / Actor loss: 0.01 / Critic loss: 0.9995\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "1710 Episode / Step: 609497 / Score: 70.24 / Actor loss: -0.01 / Critic loss: 0.8660\n",
      "1720 Episode / Step: 612106 / Score: 24.99 / Actor loss: 0.01 / Critic loss: 1.1500\n",
      "1730 Episode / Step: 615502 / Score: 32.86 / Actor loss: 0.03 / Critic loss: 1.1798\n",
      "1740 Episode / Step: 619059 / Score: 34.47 / Actor loss: 0.01 / Critic loss: 1.0799\n",
      "1750 Episode / Step: 624037 / Score: 48.68 / Actor loss: -0.01 / Critic loss: 0.9934\n",
      "1760 Episode / Step: 628890 / Score: 47.43 / Actor loss: 0.01 / Critic loss: 0.9214\n",
      "1770 Episode / Step: 633794 / Score: 47.94 / Actor loss: -0.02 / Critic loss: 0.9098\n",
      "1780 Episode / Step: 639118 / Score: 52.14 / Actor loss: 0.02 / Critic loss: 0.9037\n",
      "1790 Episode / Step: 644264 / Score: 50.36 / Actor loss: -0.00 / Critic loss: 1.0014\n",
      "1800 Episode / Step: 649577 / Score: 52.03 / Actor loss: 0.01 / Critic loss: 1.0225\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "1810 Episode / Step: 655342 / Score: 56.55 / Actor loss: -0.02 / Critic loss: 0.9931\n",
      "1820 Episode / Step: 660978 / Score: 55.26 / Actor loss: 0.01 / Critic loss: 0.9271\n",
      "1830 Episode / Step: 665477 / Score: 43.89 / Actor loss: -0.00 / Critic loss: 0.9815\n",
      "1840 Episode / Step: 671073 / Score: 54.86 / Actor loss: 0.00 / Critic loss: 0.9781\n",
      "1850 Episode / Step: 675928 / Score: 47.45 / Actor loss: -0.00 / Critic loss: 0.8960\n",
      "1860 Episode / Step: 680246 / Score: 42.08 / Actor loss: 0.01 / Critic loss: 1.0752\n",
      "1870 Episode / Step: 685033 / Score: 46.77 / Actor loss: -0.00 / Critic loss: 0.9348\n",
      "1880 Episode / Step: 689400 / Score: 42.57 / Actor loss: 0.01 / Critic loss: 1.0704\n",
      "1890 Episode / Step: 692946 / Score: 34.36 / Actor loss: 0.00 / Critic loss: 1.0460\n",
      "1900 Episode / Step: 699359 / Score: 63.03 / Actor loss: -0.02 / Critic loss: 0.9654\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "1910 Episode / Step: 704329 / Score: 48.60 / Actor loss: -0.00 / Critic loss: 0.9166\n",
      "1920 Episode / Step: 708813 / Score: 43.74 / Actor loss: 0.06 / Critic loss: 1.0487\n",
      "1930 Episode / Step: 712944 / Score: 40.21 / Actor loss: -0.00 / Critic loss: 1.0360\n",
      "1940 Episode / Step: 718324 / Score: 52.70 / Actor loss: -0.01 / Critic loss: 0.9990\n",
      "1950 Episode / Step: 721271 / Score: 28.37 / Actor loss: 0.06 / Critic loss: 1.0665\n",
      "1960 Episode / Step: 724647 / Score: 32.66 / Actor loss: -0.00 / Critic loss: 1.0256\n",
      "1970 Episode / Step: 730004 / Score: 52.47 / Actor loss: -0.02 / Critic loss: 1.0017\n",
      "1980 Episode / Step: 735206 / Score: 50.92 / Actor loss: 0.03 / Critic loss: 1.1305\n",
      "1990 Episode / Step: 739888 / Score: 45.72 / Actor loss: -0.01 / Critic loss: 1.0197\n",
      "2000 Episode / Step: 744698 / Score: 47.00 / Actor loss: -0.00 / Critic loss: 1.0406\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "2010 Episode / Step: 749913 / Score: 51.05 / Actor loss: 0.03 / Critic loss: 1.0603\n",
      "2020 Episode / Step: 756541 / Score: 65.18 / Actor loss: -0.00 / Critic loss: 0.9151\n",
      "2030 Episode / Step: 761714 / Score: 50.63 / Actor loss: 0.01 / Critic loss: 0.9133\n",
      "2040 Episode / Step: 770896 / Score: 90.72 / Actor loss: 0.02 / Critic loss: 0.9252\n",
      "2050 Episode / Step: 774827 / Score: 38.21 / Actor loss: -0.02 / Critic loss: 0.9516\n",
      "2060 Episode / Step: 778555 / Score: 36.18 / Actor loss: 0.02 / Critic loss: 1.0860\n",
      "2070 Episode / Step: 783386 / Score: 47.21 / Actor loss: 0.01 / Critic loss: 0.9875\n",
      "2080 Episode / Step: 788301 / Score: 48.05 / Actor loss: 0.02 / Critic loss: 0.9573\n",
      "2090 Episode / Step: 791904 / Score: 34.93 / Actor loss: 0.02 / Critic loss: 0.9969\n",
      "2100 Episode / Step: 796048 / Score: 40.34 / Actor loss: -0.00 / Critic loss: 0.8390\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "2110 Episode / Step: 799962 / Score: 38.04 / Actor loss: 0.06 / Critic loss: 1.0833\n",
      "the level has been increased --> 2\n",
      "2120 Episode / Step: 802374 / Score: 23.02 / Actor loss: -0.00 / Critic loss: 1.2066\n",
      "2130 Episode / Step: 805788 / Score: 33.04 / Actor loss: -0.02 / Critic loss: 1.2055\n",
      "2140 Episode / Step: 809467 / Score: 35.69 / Actor loss: -0.02 / Critic loss: 1.0800\n",
      "2150 Episode / Step: 812621 / Score: 30.44 / Actor loss: -0.02 / Critic loss: 1.1342\n",
      "2160 Episode / Step: 815946 / Score: 32.15 / Actor loss: 0.01 / Critic loss: 1.1701\n",
      "2170 Episode / Step: 819850 / Score: 37.94 / Actor loss: -0.00 / Critic loss: 1.2006\n",
      "2180 Episode / Step: 823093 / Score: 31.33 / Actor loss: -0.01 / Critic loss: 1.1396\n",
      "2190 Episode / Step: 826827 / Score: 36.24 / Actor loss: -0.01 / Critic loss: 1.1060\n",
      "2200 Episode / Step: 830813 / Score: 38.76 / Actor loss: -0.00 / Critic loss: 1.2116\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "2210 Episode / Step: 834419 / Score: 34.96 / Actor loss: 0.04 / Critic loss: 1.1110\n",
      "2220 Episode / Step: 837933 / Score: 34.04 / Actor loss: -0.01 / Critic loss: 1.0901\n",
      "2230 Episode / Step: 841961 / Score: 39.18 / Actor loss: 0.01 / Critic loss: 0.9078\n",
      "2240 Episode / Step: 846466 / Score: 43.95 / Actor loss: 0.01 / Critic loss: 1.0048\n",
      "2250 Episode / Step: 849183 / Score: 26.07 / Actor loss: 0.03 / Critic loss: 1.3099\n",
      "2260 Episode / Step: 853764 / Score: 44.71 / Actor loss: -0.02 / Critic loss: 1.1500\n",
      "2270 Episode / Step: 858413 / Score: 45.39 / Actor loss: -0.00 / Critic loss: 1.1925\n",
      "2280 Episode / Step: 862155 / Score: 36.32 / Actor loss: -0.00 / Critic loss: 1.2066\n",
      "2290 Episode / Step: 865926 / Score: 36.61 / Actor loss: 0.03 / Critic loss: 1.1987\n",
      "2300 Episode / Step: 870567 / Score: 45.31 / Actor loss: -0.01 / Critic loss: 0.9923\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "2310 Episode / Step: 875511 / Score: 48.34 / Actor loss: 0.03 / Critic loss: 1.1344\n",
      "2320 Episode / Step: 879469 / Score: 38.48 / Actor loss: -0.01 / Critic loss: 1.0532\n",
      "2330 Episode / Step: 883539 / Score: 39.60 / Actor loss: 0.00 / Critic loss: 1.0768\n",
      "2340 Episode / Step: 888066 / Score: 44.17 / Actor loss: -0.02 / Critic loss: 1.0133\n",
      "2350 Episode / Step: 893992 / Score: 58.16 / Actor loss: 0.01 / Critic loss: 1.0447\n",
      "2360 Episode / Step: 899635 / Score: 55.33 / Actor loss: -0.01 / Critic loss: 1.0450\n",
      "2370 Episode / Step: 904259 / Score: 45.14 / Actor loss: 0.00 / Critic loss: 0.9457\n",
      "2380 Episode / Step: 908670 / Score: 43.01 / Actor loss: 0.02 / Critic loss: 1.1664\n",
      "2390 Episode / Step: 912693 / Score: 39.13 / Actor loss: 0.01 / Critic loss: 1.0316\n",
      "2400 Episode / Step: 916006 / Score: 32.03 / Actor loss: -0.00 / Critic loss: 1.0007\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "2410 Episode / Step: 918033 / Score: 19.17 / Actor loss: 0.03 / Critic loss: 1.2562\n",
      "2420 Episode / Step: 923161 / Score: 50.18 / Actor loss: -0.03 / Critic loss: 1.0726\n",
      "2430 Episode / Step: 926587 / Score: 33.16 / Actor loss: 0.03 / Critic loss: 1.0181\n",
      "2440 Episode / Step: 930451 / Score: 37.54 / Actor loss: 0.01 / Critic loss: 1.0624\n",
      "2450 Episode / Step: 934644 / Score: 40.83 / Actor loss: 0.00 / Critic loss: 1.1226\n",
      "2460 Episode / Step: 938751 / Score: 39.97 / Actor loss: 0.02 / Critic loss: 0.9526\n",
      "2470 Episode / Step: 942555 / Score: 36.94 / Actor loss: 0.01 / Critic loss: 1.1046\n",
      "2480 Episode / Step: 945572 / Score: 29.07 / Actor loss: -0.03 / Critic loss: 1.1064\n",
      "2490 Episode / Step: 949796 / Score: 41.14 / Actor loss: -0.02 / Critic loss: 1.1206\n",
      "2500 Episode / Step: 953095 / Score: 31.89 / Actor loss: 0.01 / Critic loss: 1.0799\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "2510 Episode / Step: 956865 / Score: 36.60 / Actor loss: 0.03 / Critic loss: 1.1961\n",
      "2520 Episode / Step: 960096 / Score: 31.21 / Actor loss: -0.01 / Critic loss: 1.0623\n",
      "2530 Episode / Step: 964587 / Score: 43.81 / Actor loss: -0.03 / Critic loss: 0.9987\n",
      "2540 Episode / Step: 967911 / Score: 32.14 / Actor loss: 0.01 / Critic loss: 1.1738\n",
      "2550 Episode / Step: 970505 / Score: 24.84 / Actor loss: 0.03 / Critic loss: 1.0648\n",
      "2560 Episode / Step: 974850 / Score: 42.35 / Actor loss: 0.00 / Critic loss: 1.1125\n",
      "2570 Episode / Step: 980243 / Score: 52.83 / Actor loss: -0.00 / Critic loss: 1.1093\n",
      "2580 Episode / Step: 984054 / Score: 37.01 / Actor loss: 0.03 / Critic loss: 1.2267\n",
      "2590 Episode / Step: 987949 / Score: 37.85 / Actor loss: -0.02 / Critic loss: 1.1703\n",
      "2600 Episode / Step: 993983 / Score: 59.24 / Actor loss: -0.03 / Critic loss: 0.9683\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "2610 Episode / Step: 998970 / Score: 48.77 / Actor loss: 0.01 / Critic loss: 0.9902\n",
      "2620 Episode / Step: 1005616 / Score: 65.36 / Actor loss: 0.01 / Critic loss: 0.9464\n",
      "2630 Episode / Step: 1009786 / Score: 40.60 / Actor loss: 0.01 / Critic loss: 0.9276\n",
      "2640 Episode / Step: 1014609 / Score: 47.13 / Actor loss: 0.01 / Critic loss: 1.0956\n",
      "2650 Episode / Step: 1019469 / Score: 47.50 / Actor loss: -0.01 / Critic loss: 0.9873\n",
      "2660 Episode / Step: 1024539 / Score: 49.60 / Actor loss: 0.01 / Critic loss: 0.9349\n",
      "2670 Episode / Step: 1028704 / Score: 40.55 / Actor loss: 0.00 / Critic loss: 0.9382\n",
      "2680 Episode / Step: 1035514 / Score: 67.00 / Actor loss: -0.01 / Critic loss: 0.8802\n",
      "2690 Episode / Step: 1037830 / Score: 22.06 / Actor loss: 0.03 / Critic loss: 1.0996\n",
      "2700 Episode / Step: 1044176 / Score: 62.36 / Actor loss: -0.02 / Critic loss: 1.0749\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "2710 Episode / Step: 1047225 / Score: 29.39 / Actor loss: 0.02 / Critic loss: 1.0970\n",
      "2720 Episode / Step: 1053238 / Score: 59.03 / Actor loss: 0.00 / Critic loss: 1.0015\n",
      "2730 Episode / Step: 1060365 / Score: 70.17 / Actor loss: 0.01 / Critic loss: 0.8916\n",
      "2740 Episode / Step: 1065127 / Score: 46.52 / Actor loss: 0.01 / Critic loss: 1.0839\n",
      "2750 Episode / Step: 1072575 / Score: 73.38 / Actor loss: -0.00 / Critic loss: 1.0145\n",
      "2760 Episode / Step: 1078888 / Score: 62.03 / Actor loss: -0.01 / Critic loss: 0.9225\n",
      "2770 Episode / Step: 1083640 / Score: 46.42 / Actor loss: -0.00 / Critic loss: 0.9396\n",
      "2780 Episode / Step: 1087159 / Score: 34.09 / Actor loss: 0.02 / Critic loss: 1.0869\n",
      "2790 Episode / Step: 1094991 / Score: 77.22 / Actor loss: -0.01 / Critic loss: 0.8705\n",
      "2800 Episode / Step: 1101700 / Score: 65.99 / Actor loss: 0.01 / Critic loss: 0.9805\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "2810 Episode / Step: 1107185 / Score: 53.75 / Actor loss: -0.00 / Critic loss: 1.0160\n",
      "2820 Episode / Step: 1114750 / Score: 74.55 / Actor loss: -0.01 / Critic loss: 0.8887\n",
      "2830 Episode / Step: 1121881 / Score: 70.21 / Actor loss: 0.01 / Critic loss: 0.9877\n",
      "2840 Episode / Step: 1127825 / Score: 58.34 / Actor loss: -0.02 / Critic loss: 0.8874\n",
      "2850 Episode / Step: 1133028 / Score: 50.93 / Actor loss: 0.00 / Critic loss: 0.9406\n",
      "2860 Episode / Step: 1137680 / Score: 45.42 / Actor loss: 0.01 / Critic loss: 0.9470\n",
      "2870 Episode / Step: 1143825 / Score: 60.35 / Actor loss: 0.00 / Critic loss: 1.0634\n",
      "2880 Episode / Step: 1150702 / Score: 67.67 / Actor loss: 0.00 / Critic loss: 0.9445\n",
      "2890 Episode / Step: 1154974 / Score: 41.62 / Actor loss: -0.02 / Critic loss: 0.9828\n",
      "2900 Episode / Step: 1161047 / Score: 59.63 / Actor loss: -0.00 / Critic loss: 0.8917\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "2910 Episode / Step: 1165819 / Score: 46.62 / Actor loss: 0.01 / Critic loss: 0.9214\n",
      "2920 Episode / Step: 1170207 / Score: 42.78 / Actor loss: -0.00 / Critic loss: 0.9917\n",
      "2930 Episode / Step: 1176095 / Score: 57.78 / Actor loss: 0.00 / Critic loss: 1.0631\n",
      "2940 Episode / Step: 1181604 / Score: 53.99 / Actor loss: 0.01 / Critic loss: 1.0440\n",
      "2950 Episode / Step: 1187715 / Score: 60.01 / Actor loss: -0.02 / Critic loss: 0.8824\n",
      "2960 Episode / Step: 1193644 / Score: 58.19 / Actor loss: 0.00 / Critic loss: 1.0013\n",
      "2970 Episode / Step: 1197976 / Score: 42.22 / Actor loss: -0.03 / Critic loss: 1.0208\n",
      "2980 Episode / Step: 1202348 / Score: 42.62 / Actor loss: -0.01 / Critic loss: 1.2549\n",
      "2990 Episode / Step: 1209258 / Score: 68.00 / Actor loss: -0.01 / Critic loss: 1.0228\n",
      "3000 Episode / Step: 1214334 / Score: 49.66 / Actor loss: 0.02 / Critic loss: 1.0758\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "3010 Episode / Step: 1220315 / Score: 58.71 / Actor loss: 0.00 / Critic loss: 0.9685\n",
      "3020 Episode / Step: 1224813 / Score: 43.88 / Actor loss: -0.00 / Critic loss: 0.9909\n",
      "3030 Episode / Step: 1229309 / Score: 43.86 / Actor loss: -0.02 / Critic loss: 0.9711\n",
      "3040 Episode / Step: 1233368 / Score: 39.49 / Actor loss: 0.00 / Critic loss: 1.1413\n",
      "3050 Episode / Step: 1238599 / Score: 51.21 / Actor loss: -0.03 / Critic loss: 0.9266\n",
      "3060 Episode / Step: 1244891 / Score: 61.82 / Actor loss: 0.02 / Critic loss: 0.9763\n",
      "3070 Episode / Step: 1249927 / Score: 49.26 / Actor loss: -0.01 / Critic loss: 0.9951\n",
      "3080 Episode / Step: 1255907 / Score: 58.70 / Actor loss: -0.00 / Critic loss: 1.0166\n",
      "3090 Episode / Step: 1263439 / Score: 74.22 / Actor loss: -0.00 / Critic loss: 1.0349\n",
      "3100 Episode / Step: 1269083 / Score: 55.34 / Actor loss: -0.01 / Critic loss: 0.8815\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "3110 Episode / Step: 1279239 / Score: 100.46 / Actor loss: 0.00 / Critic loss: 0.9099\n",
      "3120 Episode / Step: 1283781 / Score: 44.32 / Actor loss: 0.02 / Critic loss: 0.9249\n",
      "3130 Episode / Step: 1290822 / Score: 69.31 / Actor loss: -0.01 / Critic loss: 0.8035\n",
      "3140 Episode / Step: 1296691 / Score: 57.59 / Actor loss: 0.00 / Critic loss: 0.9520\n",
      "3150 Episode / Step: 1301334 / Score: 45.33 / Actor loss: 0.00 / Critic loss: 0.9613\n",
      "3160 Episode / Step: 1305222 / Score: 37.78 / Actor loss: 0.02 / Critic loss: 1.2198\n",
      "3170 Episode / Step: 1313190 / Score: 78.58 / Actor loss: 0.00 / Critic loss: 0.9829\n",
      "3180 Episode / Step: 1317702 / Score: 44.02 / Actor loss: -0.00 / Critic loss: 1.0018\n",
      "3190 Episode / Step: 1323917 / Score: 61.05 / Actor loss: -0.00 / Critic loss: 1.0022\n",
      "3200 Episode / Step: 1329151 / Score: 51.24 / Actor loss: 0.00 / Critic loss: 1.0654\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "3210 Episode / Step: 1336251 / Score: 69.90 / Actor loss: 0.01 / Critic loss: 1.0122\n",
      "3220 Episode / Step: 1344266 / Score: 79.05 / Actor loss: 0.01 / Critic loss: 0.8925\n",
      "3230 Episode / Step: 1349199 / Score: 48.23 / Actor loss: -0.01 / Critic loss: 0.8389\n",
      "3240 Episode / Step: 1354442 / Score: 51.33 / Actor loss: 0.00 / Critic loss: 0.8727\n",
      "3250 Episode / Step: 1359923 / Score: 53.71 / Actor loss: -0.00 / Critic loss: 0.9519\n",
      "3260 Episode / Step: 1367187 / Score: 71.54 / Actor loss: 0.00 / Critic loss: 1.0233\n",
      "3270 Episode / Step: 1370985 / Score: 36.88 / Actor loss: -0.00 / Critic loss: 1.0675\n",
      "3280 Episode / Step: 1374858 / Score: 37.63 / Actor loss: 0.01 / Critic loss: 1.1864\n",
      "3290 Episode / Step: 1377826 / Score: 28.58 / Actor loss: -0.03 / Critic loss: 1.0930\n",
      "3300 Episode / Step: 1382880 / Score: 49.44 / Actor loss: -0.01 / Critic loss: 1.0725\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "3310 Episode / Step: 1387554 / Score: 45.64 / Actor loss: -0.01 / Critic loss: 0.9388\n",
      "3320 Episode / Step: 1394337 / Score: 66.73 / Actor loss: -0.00 / Critic loss: 0.8792\n",
      "3330 Episode / Step: 1401692 / Score: 72.45 / Actor loss: 0.00 / Critic loss: 0.8400\n",
      "3340 Episode / Step: 1407353 / Score: 55.51 / Actor loss: 0.01 / Critic loss: 0.8376\n",
      "3350 Episode / Step: 1414133 / Score: 66.70 / Actor loss: 0.02 / Critic loss: 1.0082\n",
      "3360 Episode / Step: 1422173 / Score: 79.30 / Actor loss: -0.01 / Critic loss: 0.8939\n",
      "3370 Episode / Step: 1427836 / Score: 55.53 / Actor loss: 0.04 / Critic loss: 1.0546\n",
      "3380 Episode / Step: 1431415 / Score: 34.69 / Actor loss: -0.01 / Critic loss: 0.9308\n",
      "3390 Episode / Step: 1434400 / Score: 28.75 / Actor loss: -0.01 / Critic loss: 1.0998\n",
      "3400 Episode / Step: 1441257 / Score: 67.47 / Actor loss: -0.00 / Critic loss: 0.9360\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "3410 Episode / Step: 1447338 / Score: 59.71 / Actor loss: -0.01 / Critic loss: 1.0419\n",
      "3420 Episode / Step: 1453463 / Score: 60.15 / Actor loss: -0.00 / Critic loss: 0.9043\n",
      "3430 Episode / Step: 1459727 / Score: 61.54 / Actor loss: 0.02 / Critic loss: 0.9519\n",
      "3440 Episode / Step: 1466788 / Score: 69.51 / Actor loss: 0.00 / Critic loss: 0.9968\n",
      "3450 Episode / Step: 1472981 / Score: 60.83 / Actor loss: -0.00 / Critic loss: 1.0375\n",
      "3460 Episode / Step: 1478833 / Score: 57.42 / Actor loss: 0.00 / Critic loss: 1.0258\n",
      "3470 Episode / Step: 1486386 / Score: 74.43 / Actor loss: -0.00 / Critic loss: 0.9582\n",
      "3480 Episode / Step: 1491675 / Score: 51.79 / Actor loss: -0.00 / Critic loss: 0.9403\n",
      "3490 Episode / Step: 1497680 / Score: 58.95 / Actor loss: -0.01 / Critic loss: 0.8725\n",
      "3500 Episode / Step: 1503631 / Score: 58.41 / Actor loss: 0.01 / Critic loss: 0.8554\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "3510 Episode / Step: 1509643 / Score: 59.02 / Actor loss: -0.01 / Critic loss: 0.8358\n",
      "3520 Episode / Step: 1516534 / Score: 67.81 / Actor loss: -0.01 / Critic loss: 0.8804\n",
      "3530 Episode / Step: 1523824 / Score: 71.80 / Actor loss: 0.01 / Critic loss: 0.9392\n",
      "3540 Episode / Step: 1531050 / Score: 71.16 / Actor loss: -0.02 / Critic loss: 0.9050\n",
      "3550 Episode / Step: 1537045 / Score: 58.85 / Actor loss: -0.01 / Critic loss: 0.8587\n",
      "3560 Episode / Step: 1544673 / Score: 75.18 / Actor loss: 0.01 / Critic loss: 0.9527\n",
      "3570 Episode / Step: 1549541 / Score: 47.58 / Actor loss: -0.02 / Critic loss: 0.9026\n",
      "3580 Episode / Step: 1552588 / Score: 29.37 / Actor loss: 0.02 / Critic loss: 1.1070\n",
      "3590 Episode / Step: 1557725 / Score: 50.27 / Actor loss: -0.02 / Critic loss: 1.0884\n",
      "3600 Episode / Step: 1565358 / Score: 75.23 / Actor loss: -0.01 / Critic loss: 0.9181\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "3610 Episode / Step: 1573085 / Score: 76.17 / Actor loss: -0.01 / Critic loss: 0.9619\n",
      "3620 Episode / Step: 1578392 / Score: 51.97 / Actor loss: -0.00 / Critic loss: 1.0143\n",
      "3630 Episode / Step: 1586152 / Score: 76.50 / Actor loss: 0.02 / Critic loss: 0.8784\n",
      "3640 Episode / Step: 1592274 / Score: 60.12 / Actor loss: -0.01 / Critic loss: 0.9144\n",
      "3650 Episode / Step: 1599532 / Score: 71.48 / Actor loss: 0.01 / Critic loss: 0.9032\n",
      "3660 Episode / Step: 1608427 / Score: 87.85 / Actor loss: -0.00 / Critic loss: 0.8548\n",
      "3670 Episode / Step: 1617027 / Score: 84.90 / Actor loss: 0.00 / Critic loss: 0.6946\n",
      "3680 Episode / Step: 1626308 / Score: 91.71 / Actor loss: 0.03 / Critic loss: 0.9914\n",
      "3690 Episode / Step: 1629411 / Score: 29.93 / Actor loss: 0.05 / Critic loss: 1.3533\n",
      "3700 Episode / Step: 1635539 / Score: 60.18 / Actor loss: -0.02 / Critic loss: 0.9442\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "3710 Episode / Step: 1640152 / Score: 45.03 / Actor loss: 0.01 / Critic loss: 0.9664\n",
      "3720 Episode / Step: 1644002 / Score: 37.40 / Actor loss: 0.01 / Critic loss: 1.0320\n",
      "3730 Episode / Step: 1648023 / Score: 39.11 / Actor loss: -0.01 / Critic loss: 1.1024\n",
      "3740 Episode / Step: 1653848 / Score: 57.15 / Actor loss: -0.01 / Critic loss: 0.8912\n",
      "3750 Episode / Step: 1657997 / Score: 40.39 / Actor loss: 0.02 / Critic loss: 1.0725\n",
      "3760 Episode / Step: 1664232 / Score: 61.25 / Actor loss: -0.02 / Critic loss: 1.0732\n",
      "3770 Episode / Step: 1669420 / Score: 50.78 / Actor loss: 0.00 / Critic loss: 0.9683\n",
      "3780 Episode / Step: 1672746 / Score: 32.16 / Actor loss: 0.02 / Critic loss: 0.9518\n",
      "3790 Episode / Step: 1679932 / Score: 70.76 / Actor loss: -0.01 / Critic loss: 0.8578\n",
      "3800 Episode / Step: 1684378 / Score: 43.36 / Actor loss: -0.01 / Critic loss: 0.8557\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "3810 Episode / Step: 1689066 / Score: 45.78 / Actor loss: 0.01 / Critic loss: 0.9399\n",
      "3820 Episode / Step: 1696228 / Score: 70.52 / Actor loss: 0.00 / Critic loss: 0.9104\n",
      "3830 Episode / Step: 1702872 / Score: 65.34 / Actor loss: -0.01 / Critic loss: 0.9103\n",
      "3840 Episode / Step: 1709967 / Score: 69.85 / Actor loss: -0.01 / Critic loss: 0.8212\n",
      "3850 Episode / Step: 1717621 / Score: 75.44 / Actor loss: -0.00 / Critic loss: 0.8599\n",
      "3860 Episode / Step: 1724908 / Score: 71.77 / Actor loss: 0.01 / Critic loss: 0.9582\n",
      "3870 Episode / Step: 1730759 / Score: 57.41 / Actor loss: -0.02 / Critic loss: 0.9216\n",
      "3880 Episode / Step: 1741065 / Score: 101.96 / Actor loss: -0.01 / Critic loss: 0.8248\n",
      "3890 Episode / Step: 1747548 / Score: 63.73 / Actor loss: 0.01 / Critic loss: 0.9329\n",
      "3900 Episode / Step: 1754684 / Score: 70.26 / Actor loss: 0.00 / Critic loss: 0.9551\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "3910 Episode / Step: 1758657 / Score: 38.63 / Actor loss: -0.05 / Critic loss: 0.9081\n",
      "3920 Episode / Step: 1763872 / Score: 51.05 / Actor loss: -0.00 / Critic loss: 0.9522\n",
      "3930 Episode / Step: 1771038 / Score: 70.56 / Actor loss: 0.01 / Critic loss: 1.0292\n",
      "3940 Episode / Step: 1776470 / Score: 53.22 / Actor loss: -0.01 / Critic loss: 1.0662\n",
      "3950 Episode / Step: 1784760 / Score: 81.80 / Actor loss: -0.02 / Critic loss: 0.7761\n",
      "3960 Episode / Step: 1793003 / Score: 81.33 / Actor loss: -0.00 / Critic loss: 0.8271\n",
      "3970 Episode / Step: 1799010 / Score: 58.97 / Actor loss: 0.02 / Critic loss: 0.8984\n",
      "3980 Episode / Step: 1806071 / Score: 69.51 / Actor loss: -0.01 / Critic loss: 0.9267\n",
      "3990 Episode / Step: 1813991 / Score: 78.10 / Actor loss: -0.02 / Critic loss: 0.8515\n",
      "4000 Episode / Step: 1821462 / Score: 73.61 / Actor loss: 0.02 / Critic loss: 0.9833\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "4010 Episode / Step: 1829418 / Score: 78.46 / Actor loss: -0.02 / Critic loss: 0.9050\n",
      "4020 Episode / Step: 1833297 / Score: 37.69 / Actor loss: -0.00 / Critic loss: 1.1183\n",
      "4030 Episode / Step: 1836412 / Score: 30.05 / Actor loss: -0.00 / Critic loss: 1.0693\n",
      "4040 Episode / Step: 1843052 / Score: 65.30 / Actor loss: -0.00 / Critic loss: 0.8999\n",
      "4050 Episode / Step: 1851735 / Score: 85.73 / Actor loss: -0.00 / Critic loss: 0.8530\n",
      "4060 Episode / Step: 1861512 / Score: 96.67 / Actor loss: -0.00 / Critic loss: 0.8395\n",
      "4070 Episode / Step: 1872105 / Score: 104.83 / Actor loss: -0.00 / Critic loss: 0.8401\n",
      "4080 Episode / Step: 1879694 / Score: 74.79 / Actor loss: -0.02 / Critic loss: 0.7728\n",
      "4090 Episode / Step: 1887671 / Score: 78.67 / Actor loss: -0.01 / Critic loss: 0.8559\n",
      "4100 Episode / Step: 1897264 / Score: 94.83 / Actor loss: 0.01 / Critic loss: 0.8359\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "4110 Episode / Step: 1903254 / Score: 58.80 / Actor loss: 0.02 / Critic loss: 0.9871\n",
      "4120 Episode / Step: 1912622 / Score: 92.58 / Actor loss: -0.01 / Critic loss: 0.8203\n",
      "4130 Episode / Step: 1919732 / Score: 70.00 / Actor loss: 0.01 / Critic loss: 0.8688\n",
      "4140 Episode / Step: 1927755 / Score: 79.13 / Actor loss: -0.01 / Critic loss: 0.9776\n",
      "4150 Episode / Step: 1936787 / Score: 89.22 / Actor loss: -0.01 / Critic loss: 0.9472\n",
      "4160 Episode / Step: 1941141 / Score: 42.44 / Actor loss: 0.01 / Critic loss: 0.9790\n",
      "4170 Episode / Step: 1945257 / Score: 40.06 / Actor loss: 0.00 / Critic loss: 1.0786\n",
      "4180 Episode / Step: 1949388 / Score: 40.21 / Actor loss: 0.02 / Critic loss: 1.0293\n",
      "4190 Episode / Step: 1954506 / Score: 50.08 / Actor loss: 0.00 / Critic loss: 1.0533\n",
      "4200 Episode / Step: 1960325 / Score: 57.09 / Actor loss: -0.00 / Critic loss: 0.9374\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "4210 Episode / Step: 1965724 / Score: 52.89 / Actor loss: 0.01 / Critic loss: 0.9393\n",
      "4220 Episode / Step: 1973129 / Score: 72.95 / Actor loss: 0.01 / Critic loss: 0.8963\n",
      "4230 Episode / Step: 1977717 / Score: 44.78 / Actor loss: 0.01 / Critic loss: 1.0723\n",
      "4240 Episode / Step: 1983034 / Score: 52.07 / Actor loss: -0.01 / Critic loss: 0.9758\n",
      "4250 Episode / Step: 1988982 / Score: 58.38 / Actor loss: 0.00 / Critic loss: 0.8663\n",
      "4260 Episode / Step: 1993670 / Score: 45.78 / Actor loss: -0.02 / Critic loss: 0.8442\n",
      "4270 Episode / Step: 1999144 / Score: 53.64 / Actor loss: 0.02 / Critic loss: 0.9539\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/ckpt ...\n",
      "TEST START\n",
      "4280 Episode / Step: 2005162 / Score: 59.08 / Actor loss: -0.03 / Critic loss: 0.9562\n",
      "4290 Episode / Step: 2009078 / Score: 38.06 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4300 Episode / Step: 2016753 / Score: 75.65 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4310 Episode / Step: 2023199 / Score: 63.36 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4320 Episode / Step: 2029518 / Score: 62.09 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4330 Episode / Step: 2035902 / Score: 62.74 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4340 Episode / Step: 2042503 / Score: 64.91 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4350 Episode / Step: 2048719 / Score: 61.06 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4360 Episode / Step: 2053947 / Score: 51.18 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4370 Episode / Step: 2058989 / Score: 49.32 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4380 Episode / Step: 2065946 / Score: 68.47 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4390 Episode / Step: 2070807 / Score: 47.51 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4400 Episode / Step: 2074712 / Score: 37.95 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4410 Episode / Step: 2079228 / Score: 44.06 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4420 Episode / Step: 2083743 / Score: 44.05 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4430 Episode / Step: 2090300 / Score: 64.47 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4440 Episode / Step: 2094051 / Score: 36.41 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4450 Episode / Step: 2098925 / Score: 47.64 / Actor loss: 0.00 / Critic loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "engine_configuration_channel = EngineConfigurationChannel()\n",
    "environment_parameters_channel = EnvironmentParametersChannel()\n",
    "env = UnityEnvironment(file_name=env_name,\n",
    "                       side_channels=[engine_configuration_channel,\n",
    "                                      environment_parameters_channel],\n",
    "                                      base_port=unity_base_port)\n",
    "env.reset()\n",
    "\n",
    "# Setup Unitu MLAgent\n",
    "behavior_name = list(env.behavior_specs.keys())[0]\n",
    "spec = env.behavior_specs[behavior_name]\n",
    "engine_configuration_channel.set_configuration_parameters(time_scale=12.0)\n",
    "# for key, value in env_static_config.items():\n",
    "#     environment_parameters_channel.set_float_parameter(key, value)\n",
    "# for key, value in env_dynamic_config.items():\n",
    "#     environment_parameters_channel.set_uniform_sampler_parameters(\n",
    "#                             key, value[\"min\"], value[\"max\"], value[\"seed\"])\n",
    "\n",
    "# reset curriculum\n",
    "for key, value in curriculum_parameters[curriculum_level].items():\n",
    "    environment_parameters_channel.set_float_parameter(key, value)\n",
    "dec, term = env.get_steps(behavior_name)\n",
    "num_worker = len(dec)\n",
    "\n",
    "# PPO agent\n",
    "agent = PPOAgent()\n",
    "actor_losses, critic_losses, scores, episode, score = [], [], [], 0, 0\n",
    "for step in range(run_step + test_step):\n",
    "    if step == run_step:\n",
    "        if train_mode:\n",
    "            agent.save_model()\n",
    "        print(\"TEST START\")\n",
    "        train_mode = False\n",
    "        engine_configuration_channel.set_configuration_parameters(time_scale=1.0)\n",
    "\n",
    "    state = dec.obs[0]\n",
    "    action = agent.get_action(state, train_mode)\n",
    "    action_tuple = ActionTuple()\n",
    "    action_tuple.add_discrete(action)\n",
    "    env.set_actions(behavior_name, action_tuple)\n",
    "    env.step()\n",
    "\n",
    "    # information from enviroment\n",
    "    dec, term = env.get_steps(behavior_name)\n",
    "    done = [False] * num_worker\n",
    "    next_state = dec.obs[0]\n",
    "    reward = dec.reward\n",
    "    for id in term.agent_id:\n",
    "        _id = list(term.agent_id).index(id)\n",
    "        done[id] = True\n",
    "        next_state[id] = term.obs[0][_id]\n",
    "        reward[id] = term.reward[_id]\n",
    "    score += reward[0]\n",
    "\n",
    "    if train_mode:\n",
    "        for id in range(num_worker):\n",
    "            agent.append_sample(state[id], action[id], [reward[id]], next_state[id], [done[id]])\n",
    "        # training\n",
    "        if (step+1) % n_step == 0:\n",
    "            actor_loss, critic_loss = agent.train_model()\n",
    "            actor_losses.append(actor_loss)\n",
    "            critic_losses.append(critic_loss)\n",
    "\n",
    "    if done[0]:\n",
    "        episode +=1\n",
    "        scores.append(score)\n",
    "        score = 0\n",
    "\n",
    "        # logging\n",
    "        if episode % print_interval == 0:\n",
    "            mean_score = np.mean(scores)\n",
    "            mean_actor_loss = np.mean(actor_losses) if len(actor_losses) > 0 else 0\n",
    "            mean_critic_loss = np.mean(critic_losses)  if len(critic_losses) > 0 else 0\n",
    "            agent.write_summary(mean_score, mean_actor_loss, mean_critic_loss, step)\n",
    "            actor_losses, critic_losses, scores = [], [], []\n",
    "\n",
    "            print(f\"{episode} Episode / Step: {step} / Score: {mean_score:.2f} / \" +\\\n",
    "                    f\"Actor loss: {mean_actor_loss:.2f} / Critic loss: {mean_critic_loss:.4f}\" )\n",
    "\n",
    "        # save netwrok model\n",
    "        if train_mode and episode % save_interval == 0:\n",
    "            agent.save_model()\n",
    "\n",
    "        if(train_mode and step >= run_step * curriculum_threshold[curriculum_level]):\n",
    "            curriculum_level += 1\n",
    "            print(f\"the level has been increased --> {curriculum_level}\")\n",
    "\n",
    "            for key, value in curriculum_parameters[curriculum_level].items():\n",
    "                environment_parameters_channel.set_float_parameter(key, value)\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3f52b",
   "metadata": {},
   "source": [
    "## Test the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bf21572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "... Load Model from /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Dodge/PPO_Curriculum/20250924122802/Dodge_PPO_Curriculum.ckpt ...\n",
      "4700 Episode / Step: 1253 / Score: 20.69 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4710 Episode / Step: 4954 / Score: 35.91 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4720 Episode / Step: 10046 / Score: 49.82 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4730 Episode / Step: 13694 / Score: 35.38 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4740 Episode / Step: 16970 / Score: 31.66 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4750 Episode / Step: 21075 / Score: 39.95 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4760 Episode / Step: 27005 / Score: 58.20 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4770 Episode / Step: 30080 / Score: 29.65 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4780 Episode / Step: 34968 / Score: 47.78 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4790 Episode / Step: 38614 / Score: 35.36 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4800 Episode / Step: 43174 / Score: 44.50 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4810 Episode / Step: 47009 / Score: 37.25 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4820 Episode / Step: 50943 / Score: 38.24 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4830 Episode / Step: 54267 / Score: 32.14 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4840 Episode / Step: 57958 / Score: 35.81 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4850 Episode / Step: 61587 / Score: 35.19 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4860 Episode / Step: 65663 / Score: 39.66 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4870 Episode / Step: 69554 / Score: 37.81 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4880 Episode / Step: 73685 / Score: 40.21 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4890 Episode / Step: 79332 / Score: 55.37 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4900 Episode / Step: 82073 / Score: 26.31 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4910 Episode / Step: 86396 / Score: 42.13 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4920 Episode / Step: 90739 / Score: 42.33 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4930 Episode / Step: 95716 / Score: 48.67 / Actor loss: 0.00 / Critic loss: 0.0000\n",
      "4940 Episode / Step: 99431 / Score: 36.05 / Actor loss: 0.00 / Critic loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "load_model = True\n",
    "train_mode = False\n",
    "\n",
    "load_path = save_model_path\n",
    "\n",
    "engine_configuration_channel = EngineConfigurationChannel()\n",
    "environment_parameters_channel = EnvironmentParametersChannel()\n",
    "env = UnityEnvironment(file_name=env_name,\n",
    "                       side_channels=[engine_configuration_channel,\n",
    "                                      environment_parameters_channel],\n",
    "                                      base_port=unity_base_port)\n",
    "env.reset()\n",
    "\n",
    "# Setup Unitu MLAgent\n",
    "behavior_name = list(env.behavior_specs.keys())[0]\n",
    "spec = env.behavior_specs[behavior_name]\n",
    "engine_configuration_channel.set_configuration_parameters(time_scale=1.0)\n",
    "for key, value in env_static_config.items():\n",
    "    environment_parameters_channel.set_float_parameter(key, value)\n",
    "for key, value in env_dynamic_config.items():\n",
    "    environment_parameters_channel.set_uniform_sampler_parameters(\n",
    "                            key, value[\"min\"], value[\"max\"], value[\"seed\"])\n",
    "dec, term = env.get_steps(behavior_name)\n",
    "num_worker = len(dec)\n",
    "\n",
    "# PPO agent\n",
    "agent = PPOAgent()\n",
    "# actor_losses, critic_losses, scores, episode, score = [], [], [], 0, 0\n",
    "for step in range(test_step):\n",
    "    state = dec.obs[0]\n",
    "    action = agent.get_action(state, train_mode)\n",
    "    action_tuple = ActionTuple()\n",
    "    action_tuple.add_discrete(action)\n",
    "    env.set_actions(behavior_name, action_tuple)\n",
    "    env.step()\n",
    "\n",
    "    # information from enviroment\n",
    "    dec, term = env.get_steps(behavior_name)\n",
    "    done = [False] * num_worker\n",
    "    next_state = dec.obs[0]\n",
    "    reward = dec.reward\n",
    "    for id in term.agent_id:\n",
    "        _id = list(term.agent_id).index(id)\n",
    "        done[id] = True\n",
    "        next_state[id] = term.obs[0][_id]\n",
    "        reward[id] = term.reward[_id]\n",
    "    score += reward[0]\n",
    "\n",
    "    if train_mode:\n",
    "        for id in range(num_worker):\n",
    "            agent.append_sample(state[id], action[id], [reward[id]], next_state[id], [done[id]])\n",
    "        # training\n",
    "        if (step+1) % n_step == 0:\n",
    "            actor_loss, critic_loss = agent.train_model()\n",
    "            actor_losses.append(actor_loss)\n",
    "            critic_losses.append(critic_loss)\n",
    "\n",
    "    if done[0]:\n",
    "        episode +=1\n",
    "        scores.append(score)\n",
    "        score = 0\n",
    "\n",
    "        # logging\n",
    "        if episode % print_interval == 0:\n",
    "            mean_score = np.mean(scores)\n",
    "            mean_actor_loss = np.mean(actor_losses) if len(actor_losses) > 0 else 0\n",
    "            mean_critic_loss = np.mean(critic_losses)  if len(critic_losses) > 0 else 0\n",
    "            agent.write_summary(mean_score, mean_actor_loss, mean_critic_loss, step)\n",
    "            actor_losses, critic_losses, scores = [], [], []\n",
    "\n",
    "            print(f\"{episode} Episode / Step: {step} / Score: {mean_score:.2f} / \" +\\\n",
    "                    f\"Actor loss: {mean_actor_loss:.2f} / Critic loss: {mean_critic_loss:.4f}\" )\n",
    "env.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
