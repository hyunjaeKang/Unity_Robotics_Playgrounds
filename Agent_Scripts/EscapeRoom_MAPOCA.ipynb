{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# EscapeRoom MAPOCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d197bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import datetime\n",
    "import platform\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from mlagents_envs.environment import UnityEnvironment, ActionTuple\n",
    "from mlagents_envs.side_channel.engine_configuration_channel\\\n",
    "                             import EngineConfigurationChannel\n",
    "from mlagents_envs.side_channel.environment_parameters_channel\\\n",
    "                             import EnvironmentParametersChannel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2fb148",
   "metadata": {},
   "source": [
    "## Setting environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8093df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "test_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"pytorch_output\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d33761",
   "metadata": {},
   "source": [
    "### Pytorch Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "521fc2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Pytorch Device\n",
    "if torch.backends.mps.is_available():\n",
    "    g_device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    g_device = torch.device(\"cuda\")\n",
    "else:\n",
    "    g_device = torch.device(\"cpu\")\n",
    "\n",
    "print(g_device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485c2ea",
   "metadata": {},
   "source": [
    "### Unity Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f1e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unity Enviroment\n",
    "game = \"EscapeRoom\"\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be65174e",
   "metadata": {},
   "source": [
    "### Seting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ee7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "state_size = 651 + 4\n",
    "action_size = 4\n",
    "num_agents = 3\n",
    "\n",
    "RAY_OBS = 0\n",
    "VEC_OBS = 1\n",
    "\n",
    "# attention parameter\n",
    "embed_size = 128\n",
    "num_heads = 4\n",
    "\n",
    "load_model = False\n",
    "train_mode = True\n",
    "\n",
    "discount_factor = 0.999\n",
    "learning_rate = 1e-4\n",
    "n_step = 8192\n",
    "batch_size = 1024\n",
    "n_epoch = 3\n",
    "_lambda = 0.95\n",
    "epsilon = 0.2\n",
    "\n",
    "run_step = 1000000 if train_mode else 0\n",
    "test_step = 100000\n",
    "\n",
    "print_interval = 10\n",
    "save_interval = 100\n",
    "\n",
    "\n",
    "unity_base_port = 1966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce97f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN model : Save and Load\n",
    "date_time = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "save_path = os.path.join(test_dir, f\"saved_models/{game}/MAPOCA/{date_time}\")\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "save_model_path = os.path.join(save_path, 'EscapeRoom_MAPOCA.ckpt')\n",
    "# print(f\"save_path :{save_path}\")\n",
    "# print(f\"save_model_path :{save_model_path}\")\n",
    "load_model_path = \"\" # Need to update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aded1f",
   "metadata": {},
   "source": [
    "## Model for Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa3fdab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Actor, self).__init__(**kwargs)\n",
    "        self.d1 = torch.nn.Linear(state_size, 128)\n",
    "        self.d2 = torch.nn.Linear(128, 128)\n",
    "        self.pi = torch.nn.Linear(128, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.d1(x))\n",
    "        x = F.relu(self.d2(x))\n",
    "        return F.softmax(self.pi(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f20d7",
   "metadata": {},
   "source": [
    "## Model for Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfef641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Critic, self).__init__(**kwargs)\n",
    "        self.g = torch.nn.ModuleList([torch.nn.Linear(state_size, embed_size)\n",
    "                                      for _ in range(num_agents)])\n",
    "        self.v_rsa = torch.nn.TransformerEncoderLayer(\n",
    "            d_model=embed_size, nhead=num_heads, batch_first=True,\n",
    "            dim_feedforward=embed_size, dropout=0)\n",
    "        self.v_d1 = torch.nn.Linear(num_agents * embed_size, 128)\n",
    "        self.v_d2 = torch.nn.Linear(128, 128)\n",
    "        self.v = torch.nn.Linear(128, 1)\n",
    "\n",
    "        self.f = torch.nn.ModuleList([torch.nn.Linear(state_size + action_size, embed_size)\n",
    "                                      for _ in range(num_agents)])\n",
    "        self.q_rsa = torch.nn.TransformerEncoderLayer(\n",
    "            d_model=2*embed_size, nhead=num_heads, batch_first=True,\n",
    "            dim_feedforward=embed_size, dropout=0)\n",
    "        self.q_d1 = torch.nn.Linear(num_agents * 2*embed_size, 128)\n",
    "        self.q_d2 = torch.nn.Linear(128, 128)\n",
    "        self.q = torch.nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, states):\n",
    "        b = states.shape[0]\n",
    "\n",
    "        states = [s.reshape(b, state_size) for s in torch.split(states, 1, dim=1)]\n",
    "        s_embed = [g(s) for g, s in zip(self.g, states)]\n",
    "        v_h = self.v_rsa(torch.stack(s_embed, dim=1))\n",
    "        v_h = F.relu(self.v_d1(v_h.reshape(b, -1)))\n",
    "        v_h = F.relu(self.v_d2(v_h))\n",
    "        v = self.v(v_h)\n",
    "\n",
    "        return v\n",
    "\n",
    "    def compute_q(self, states, actions, agent_idx):\n",
    "        b = states.shape[0]\n",
    "\n",
    "        states = [s.reshape(b, state_size) for s in torch.split(states, 1, dim=1)]\n",
    "        s_embed = [g(s) if i == agent_idx else torch.zeros((b, embed_size)).to(g_device)\n",
    "                   for i, (g, s) in enumerate(zip(self.g, states))]\n",
    "\n",
    "        active_actions = actions != -1\n",
    "        actions = torch.where(active_actions, actions, 0)\n",
    "        onehot_actions = F.one_hot(actions.long(), num_classes=action_size).reshape(b, num_agents, action_size)\n",
    "        onehot_actions *= active_actions\n",
    "        onehot_actions = torch.split(onehot_actions, 1, dim=1)\n",
    "        sa_embed = [torch.zeros((b, embed_size)).to(g_device) if i == agent_idx else \\\n",
    "                    f(torch.cat((s,a.reshape(b, action_size)), dim=1))\n",
    "                    for i, (f, s, a) in enumerate(zip(self.f, states, onehot_actions))]\n",
    "        q_h = self.q_rsa(torch.cat((torch.stack(s_embed, dim=1), torch.stack(sa_embed, dim=1)), dim=2))\n",
    "        q_h = F.relu(self.q_d1(q_h.reshape(b, -1)))\n",
    "        q_h = F.relu(self.q_d2(q_h))\n",
    "        q = self.q(q_h)\n",
    "\n",
    "        return q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41c622",
   "metadata": {},
   "source": [
    "## Agent class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af439a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAPOCAAgent:\n",
    "    def __init__(self):\n",
    "        self.actors = [Actor().to(g_device) for _ in range(num_agents)]\n",
    "        self.actor_optimizers = [torch.optim.Adam(actor.parameters(), lr=learning_rate) for actor in self.actors]\n",
    "        self.critic = Critic().to(g_device)\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=learning_rate)\n",
    "        self.memory = list()\n",
    "        self.writer = SummaryWriter(save_path)\n",
    "\n",
    "        if load_model == True:\n",
    "            print(f\"... Load Model from {load_model_path}\")\n",
    "            checkpoint = torch.load(load_model_path, map_location=g_device)\n",
    "            for i in range(num_agents):\n",
    "                self.actors[i].load_state_dict(checkpoint[f\"actor_{i}\"])\n",
    "                self.actor_optimizers[i].load_state_dict(checkpoint[f\"actor_optimizer_{i}\"])\n",
    "            self.critic.load_state_dict(checkpoint[\"critic\"])\n",
    "            self.critic_optimizer.load_state_dict(checkpoint[\"critic_optimizer\"])\n",
    "\n",
    "    # Get action from actors\n",
    "    def get_action(self, states, active_agents, training=True):\n",
    "        actions = []\n",
    "        for state, active_agent in zip(states, active_agents):\n",
    "            self.actors[active_agent].train(training)\n",
    "\n",
    "            # get action from each actor\n",
    "            pi = self.actors[active_agent](torch.FloatTensor(state).to(g_device))\n",
    "            action = torch.multinomial(pi, num_samples=1).cpu().numpy()\n",
    "            actions.append(action)\n",
    "        return np.array(actions).reshape((len(active_agents), 1))\n",
    "\n",
    "    # Add memory pool\n",
    "    def append_sample(self, states, actions, reward, next_states, done, actives):\n",
    "        self.memory.append((states, actions, reward, next_states, done, actives))\n",
    "\n",
    "    # Training\n",
    "    def train_model(self):\n",
    "        for actor in self.actors:\n",
    "            actor.train()\n",
    "        self.critic.train()\n",
    "\n",
    "        states      = np.stack([m[0] for m in self.memory], axis=0)\n",
    "        actions     = np.stack([m[1] for m in self.memory], axis=0)\n",
    "        reward      = np.stack([m[2] for m in self.memory], axis=0)\n",
    "        next_states = np.stack([m[3] for m in self.memory], axis=0)\n",
    "        done        = np.stack([m[4] for m in self.memory], axis=0)\n",
    "        actives     = np.stack([m[5] for m in self.memory], axis=0)\n",
    "        self.memory.clear()\n",
    "\n",
    "        states, actions, reward, next_states, done, actives = map(lambda x: torch.FloatTensor(x).to(g_device),\n",
    "                                                        [states, actions, reward, next_states, done, actives])\n",
    "\n",
    "       # prob_olds, ret\n",
    "        with torch.no_grad():\n",
    "            value = self.critic(states)\n",
    "            next_value = self.critic(next_states)\n",
    "            delta = reward + (1 - done) * discount_factor * next_value - value\n",
    "            adv = delta.clone()\n",
    "            adv, done = map(lambda x: x.view(n_step, -1).transpose(0,1).contiguous(), [adv, done])\n",
    "            for t in reversed(range(n_step-1)):\n",
    "                adv[:, t] += (1 - done[:, t]) * discount_factor * _lambda * adv[:, t+1]\n",
    "            adv = adv.transpose(0,1).contiguous().view(-1, 1)\n",
    "            ret = adv + value\n",
    "\n",
    "            prob_olds = torch.zeros_like(actions)\n",
    "            for i in range(num_agents):\n",
    "                state, action, active = map(lambda x: x[:,i,:], [states, actions, actives])\n",
    "                pi_old = self.actors[i](state)\n",
    "                active_action = action * active\n",
    "                prob_old = pi_old.gather(1, active_action.long())\n",
    "                prob_olds[:,i,:] = prob_old\n",
    "\n",
    "\n",
    "        # training\n",
    "        actors_losses, critic_losses = [[] for _ in range(num_agents)], []\n",
    "        idxs = np.arange(len(reward))\n",
    "        for _ in range(n_epoch):\n",
    "            np.random.shuffle(idxs)\n",
    "            for offset in range(0, len(reward), batch_size):\n",
    "                idx = idxs[offset : offset + batch_size]\n",
    "\n",
    "                _states, _actions, _actives, _ret, _prob_olds =\\\n",
    "                    map(lambda x: x[idx], [states, actions, actives, ret, prob_olds])\n",
    "\n",
    "                baselines_loss = []\n",
    "                # loss function for policy function\n",
    "                for i in range(num_agents):\n",
    "                    state, action, active, prob_old = map(lambda x: x[:,i,:], [_states, _actions, _actives, _prob_olds])\n",
    "                    pi = self.actors[i](state)\n",
    "                    active_action = action * active\n",
    "                    prob = pi.gather(1, active_action.long())\n",
    "                    ratio = prob / (prob_old + 1e-7)\n",
    "\n",
    "                    q = self.critic.compute_q(_states, _actions, i)\n",
    "                    adv = _ret - q\n",
    "\n",
    "                    surr1 = ratio * adv\n",
    "                    surr2 = torch.clamp(ratio, min=1-epsilon, max=1+epsilon) * adv\n",
    "                    actor_loss = (-torch.min(surr1, surr2) * active).mean()\n",
    "\n",
    "                    self.actor_optimizers[i].zero_grad()\n",
    "                    actor_loss.backward(retain_graph=True)\n",
    "                    self.actor_optimizers[i].step()\n",
    "\n",
    "                    actors_losses[i].append(actor_loss.item())\n",
    "                    baselines_loss.append(torch.mean(adv**2))\n",
    "\n",
    "                # loss function for value-function\n",
    "                value = self.critic(_states)\n",
    "                critic_loss = F.mse_loss(value, _ret).mean() + sum(baselines_loss)\n",
    "\n",
    "                self.critic_optimizer.zero_grad()\n",
    "                critic_loss.backward()\n",
    "                self.critic_optimizer.step()\n",
    "\n",
    "                critic_losses.append(critic_loss.item())\n",
    "\n",
    "        return [np.mean(actor_losses) for actor_losses in actors_losses], np.mean(critic_losses)\n",
    "\n",
    "    # Save network\n",
    "    def save_model(self):\n",
    "        print(f\"... Save Model to {save_model_path}\")\n",
    "        obj = {}\n",
    "        for i in range(num_agents):\n",
    "            obj[f\"actor_{i}\"] = self.actors[i].state_dict()\n",
    "            obj[f\"actor_optimizer_{i}\"] = self.actor_optimizers[i].state_dict()\n",
    "        obj[\"critic\"] = self.critic.state_dict()\n",
    "        obj[\"critic_optimizer\"] = self.critic_optimizer.state_dict()\n",
    "        torch.save(obj, save_model_path)\n",
    "\n",
    "    # logging\n",
    "    def write_summary(self, score, actors_loss, critic_loss, step):\n",
    "        self.writer.add_scalar(\"MAPOCA_run/score\", score, step)\n",
    "        for i in range(num_agents):\n",
    "            self.writer.add_scalar(f\"MAPOCA_model/actor_{i}_loss\", actors_loss[i], step)\n",
    "        self.writer.add_scalar(\"MAPOCA_model/critic_loss\", critic_loss, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b01e40",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99506e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0558bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "10 Episode / Step: 13434 / Score: 0.00 / Actors loss: [-0.0025, -0.0007, 0.0] / Critic loss: 0.0095\n",
      "20 Episode / Step: 30762 / Score: 0.10 / Actors loss: [-0.0003, -0.0004, -0.0006] / Critic loss: 0.0015\n",
      "30 Episode / Step: 44091 / Score: 0.30 / Actors loss: [-0.0006, -0.0002, -0.0003] / Critic loss: 0.0039\n",
      "40 Episode / Step: 54647 / Score: 0.50 / Actors loss: [-0.002, -0.0011, 0.0001] / Critic loss: 0.0206\n",
      "50 Episode / Step: 72172 / Score: 0.00 / Actors loss: [-0.0002, -0.0001, -0.0002] / Critic loss: 0.0019\n",
      "60 Episode / Step: 89746 / Score: 0.00 / Actors loss: [-0.0, -0.0, -0.0001] / Critic loss: 0.0010\n",
      "70 Episode / Step: 107836 / Score: 0.10 / Actors loss: [-0.0001, -0.0002, 0.0] / Critic loss: 0.0017\n",
      "80 Episode / Step: 126910 / Score: 0.00 / Actors loss: [-0.0003, -0.0002, -0.0001] / Critic loss: 0.0005\n",
      "90 Episode / Step: 143222 / Score: 0.10 / Actors loss: [-0.0001, -0.0002, -0.0001] / Critic loss: 0.0019\n",
      "100 Episode / Step: 162814 / Score: 0.00 / Actors loss: [0.0002, 0.0, -0.0] / Critic loss: 0.0004\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "110 Episode / Step: 182814 / Score: 0.00 / Actors loss: [-0.0, -0.0001, -0.0001] / Critic loss: 0.0003\n",
      "120 Episode / Step: 200178 / Score: 0.20 / Actors loss: [-0.0001, -0.0002, -0.0006] / Critic loss: 0.0034\n",
      "130 Episode / Step: 215788 / Score: 0.30 / Actors loss: [-0.0, -0.0001, -0.0003] / Critic loss: 0.0035\n",
      "140 Episode / Step: 228890 / Score: 0.50 / Actors loss: [-0.0002, -0.0002, -0.0003] / Critic loss: 0.0049\n",
      "150 Episode / Step: 238625 / Score: 0.60 / Actors loss: [-0.0006, -0.0005, 0.0001] / Critic loss: 0.0075\n",
      "160 Episode / Step: 250974 / Score: 0.50 / Actors loss: [0.0004, -0.0006, -0.0003] / Critic loss: 0.0105\n",
      "170 Episode / Step: 263594 / Score: 0.60 / Actors loss: [-0.0005, -0.0001, -0.0003] / Critic loss: 0.0073\n",
      "180 Episode / Step: 277880 / Score: 0.40 / Actors loss: [-0.0005, -0.0, 0.0015] / Critic loss: 0.0039\n",
      "190 Episode / Step: 290924 / Score: 0.50 / Actors loss: [-0.0001, -0.0004, -0.0002] / Critic loss: 0.0067\n",
      "200 Episode / Step: 304199 / Score: 0.40 / Actors loss: [-0.0003, 0.0001, 0.0] / Critic loss: 0.0056\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "210 Episode / Step: 316220 / Score: 0.60 / Actors loss: [-0.0, -0.0006, 0.0001] / Critic loss: 0.0020\n",
      "220 Episode / Step: 322864 / Score: 0.90 / Actors loss: [-0.0011, -0.0003, -0.0002] / Critic loss: 0.0093\n",
      "230 Episode / Step: 332970 / Score: 0.40 / Actors loss: [-0.0001, -0.0004, 0.0003] / Critic loss: 0.0036\n",
      "240 Episode / Step: 344414 / Score: 0.50 / Actors loss: [-0.0003, -0.0002, -0.0001] / Critic loss: 0.0051\n",
      "250 Episode / Step: 347140 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "260 Episode / Step: 356178 / Score: 0.70 / Actors loss: [-0.0008, 0.0002, 0.0001] / Critic loss: 0.0209\n",
      "270 Episode / Step: 369556 / Score: 0.50 / Actors loss: [-0.0003, -0.0005, 0.0] / Critic loss: 0.0035\n",
      "280 Episode / Step: 377044 / Score: 0.90 / Actors loss: [-0.0008, 0.0, -0.0004] / Critic loss: 0.0103\n",
      "290 Episode / Step: 384570 / Score: 0.70 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "300 Episode / Step: 391900 / Score: 0.60 / Actors loss: [-0.0, -0.0003, 0.0002] / Critic loss: 0.0077\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "310 Episode / Step: 399780 / Score: 0.80 / Actors loss: [-0.0, -0.0004, -0.0002] / Critic loss: 0.0037\n",
      "320 Episode / Step: 402894 / Score: 1.00 / Actors loss: [-0.0011, -0.0006, 0.0001] / Critic loss: 0.0128\n",
      "330 Episode / Step: 411715 / Score: 0.60 / Actors loss: [-0.0001, -0.0005, -0.0003] / Critic loss: 0.0069\n",
      "340 Episode / Step: 420574 / Score: 0.60 / Actors loss: [0.0003, 0.0003, -0.0002] / Critic loss: 0.0016\n",
      "350 Episode / Step: 426167 / Score: 0.90 / Actors loss: [-0.0004, -0.0007, 0.0003] / Critic loss: 0.0072\n",
      "360 Episode / Step: 430167 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "370 Episode / Step: 433593 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "380 Episode / Step: 439160 / Score: 0.80 / Actors loss: [-0.0007, -0.001, -0.0005] / Critic loss: 0.0132\n",
      "390 Episode / Step: 442991 / Score: 0.90 / Actors loss: [-0.0003, -0.0001, -0.0003] / Critic loss: 0.0051\n",
      "400 Episode / Step: 449200 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "410 Episode / Step: 454603 / Score: 0.80 / Actors loss: [-0.0, 0.0002, 0.0004] / Critic loss: 0.0053\n",
      "420 Episode / Step: 457935 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "430 Episode / Step: 463582 / Score: 0.80 / Actors loss: [-0.0002, -0.0006, -0.0001] / Critic loss: 0.0041\n",
      "440 Episode / Step: 465847 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "450 Episode / Step: 471614 / Score: 0.80 / Actors loss: [-0.0005, -0.0002, 0.0001] / Critic loss: 0.0074\n",
      "460 Episode / Step: 475062 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "470 Episode / Step: 476268 / Score: 1.00 / Actors loss: [-0.0003, -0.0003, -0.0003] / Critic loss: 0.0052\n",
      "480 Episode / Step: 481578 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "490 Episode / Step: 482619 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "500 Episode / Step: 485383 / Score: 0.80 / Actors loss: [-0.0001, -0.0, -0.0001] / Critic loss: 0.0119\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "510 Episode / Step: 491554 / Score: 0.80 / Actors loss: [-0.0001, 0.0001, -0.0005] / Critic loss: 0.0029\n",
      "520 Episode / Step: 496779 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "530 Episode / Step: 498262 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "540 Episode / Step: 504947 / Score: 0.80 / Actors loss: [-0.0002, -0.0, -0.0002] / Critic loss: 0.0045\n",
      "550 Episode / Step: 510347 / Score: 0.80 / Actors loss: [-0.0, 0.0002, -0.0] / Critic loss: 0.0029\n",
      "560 Episode / Step: 515833 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "570 Episode / Step: 517456 / Score: 1.00 / Actors loss: [-0.0002, -0.0001, 0.0002] / Critic loss: 0.0030\n",
      "580 Episode / Step: 519309 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "590 Episode / Step: 520598 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "600 Episode / Step: 524331 / Score: 0.90 / Actors loss: [-0.0003, -0.0005, -0.0003] / Critic loss: 0.0049\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "610 Episode / Step: 527509 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "620 Episode / Step: 530726 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "630 Episode / Step: 539681 / Score: 0.60 / Actors loss: [-0.0001, -0.0005, 0.0] / Critic loss: 0.0067\n",
      "640 Episode / Step: 542925 / Score: 0.90 / Actors loss: [-0.0006, -0.0001, 0.0] / Critic loss: 0.0047\n",
      "650 Episode / Step: 549966 / Score: 0.70 / Actors loss: [0.0002, -0.0004, 0.0002] / Critic loss: 0.0040\n",
      "660 Episode / Step: 554191 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "670 Episode / Step: 556300 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "680 Episode / Step: 559981 / Score: 0.90 / Actors loss: [-0.0004, -0.0004, -0.0004] / Critic loss: 0.0107\n",
      "690 Episode / Step: 564921 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "700 Episode / Step: 568102 / Score: 0.90 / Actors loss: [0.0002, 0.0001, -0.0003] / Critic loss: 0.0039\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "710 Episode / Step: 569092 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "720 Episode / Step: 577747 / Score: 0.60 / Actors loss: [0.0002, 0.0, 0.0001] / Critic loss: 0.0025\n",
      "730 Episode / Step: 579516 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "740 Episode / Step: 582605 / Score: 0.90 / Actors loss: [-0.0005, 0.0001, -0.0001] / Critic loss: 0.0054\n",
      "750 Episode / Step: 586000 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "760 Episode / Step: 591230 / Score: 0.80 / Actors loss: [0.0002, 0.0004, -0.0] / Critic loss: 0.0041\n",
      "770 Episode / Step: 592737 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "780 Episode / Step: 597399 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "790 Episode / Step: 602796 / Score: 0.80 / Actors loss: [-0.0003, -0.0001, -0.0] / Critic loss: 0.0049\n",
      "800 Episode / Step: 603665 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "810 Episode / Step: 604954 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "820 Episode / Step: 607681 / Score: 0.90 / Actors loss: [-0.0002, -0.0002, 0.0003] / Critic loss: 0.0062\n",
      "830 Episode / Step: 613186 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "840 Episode / Step: 614379 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "850 Episode / Step: 619390 / Score: 0.80 / Actors loss: [0.0001, 0.0001, -0.0001] / Critic loss: 0.0025\n",
      "860 Episode / Step: 620854 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "870 Episode / Step: 627658 / Score: 0.70 / Actors loss: [-0.0003, -0.0002, -0.0003] / Critic loss: 0.0028\n",
      "880 Episode / Step: 629358 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "890 Episode / Step: 632373 / Score: 0.90 / Actors loss: [-0.0004, 0.0, -0.0001] / Critic loss: 0.0086\n",
      "900 Episode / Step: 637182 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "910 Episode / Step: 638183 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "920 Episode / Step: 642269 / Score: 0.90 / Actors loss: [-0.0002, -0.0003, -0.0002] / Critic loss: 0.0055\n",
      "930 Episode / Step: 645049 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "940 Episode / Step: 646920 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "950 Episode / Step: 648060 / Score: 1.00 / Actors loss: [-0.0001, -0.0, 0.0004] / Critic loss: 0.0052\n",
      "960 Episode / Step: 653162 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "970 Episode / Step: 654019 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "980 Episode / Step: 654984 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "990 Episode / Step: 657954 / Score: 0.90 / Actors loss: [-0.0001, -0.0002, -0.0003] / Critic loss: 0.0044\n",
      "1000 Episode / Step: 659088 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "1010 Episode / Step: 661900 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1020 Episode / Step: 667168 / Score: 0.80 / Actors loss: [-0.0, 0.0001, -0.0002] / Critic loss: 0.0083\n",
      "1030 Episode / Step: 672319 / Score: 0.80 / Actors loss: [0.0002, 0.0001, 0.0001] / Critic loss: 0.0034\n",
      "1040 Episode / Step: 676986 / Score: 0.70 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1050 Episode / Step: 680242 / Score: 0.90 / Actors loss: [0.0001, -0.0001, 0.0002] / Critic loss: 0.0075\n",
      "1060 Episode / Step: 681662 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1070 Episode / Step: 684839 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1080 Episode / Step: 685573 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1090 Episode / Step: 686680 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1100 Episode / Step: 687567 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "1110 Episode / Step: 690538 / Score: 0.90 / Actors loss: [-0.0001, -0.0008, -0.0001] / Critic loss: 0.0084\n",
      "1120 Episode / Step: 693547 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1130 Episode / Step: 694850 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1140 Episode / Step: 697902 / Score: 0.90 / Actors loss: [-0.0003, 0.0002, -0.0002] / Critic loss: 0.0038\n",
      "1150 Episode / Step: 698704 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1160 Episode / Step: 699815 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1170 Episode / Step: 700666 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1180 Episode / Step: 703348 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1190 Episode / Step: 708129 / Score: 0.80 / Actors loss: [-0.0001, -0.0002, 0.0001] / Critic loss: 0.0058\n",
      "1200 Episode / Step: 710993 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "1210 Episode / Step: 712434 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1220 Episode / Step: 715326 / Score: 0.90 / Actors loss: [0.0, 0.0002, 0.0] / Critic loss: 0.0029\n",
      "1230 Episode / Step: 718095 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1240 Episode / Step: 719427 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1250 Episode / Step: 726285 / Score: 0.70 / Actors loss: [0.0002, 0.0003, 0.0002] / Critic loss: 0.0031\n",
      "1260 Episode / Step: 729345 / Score: 0.90 / Actors loss: [0.0002, -0.0006, 0.0002] / Critic loss: 0.0041\n",
      "1270 Episode / Step: 730276 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1280 Episode / Step: 731384 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1290 Episode / Step: 732486 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1300 Episode / Step: 737523 / Score: 0.80 / Actors loss: [-0.0003, -0.0014, -0.0003] / Critic loss: 0.0106\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "1310 Episode / Step: 740672 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1320 Episode / Step: 745595 / Score: 0.80 / Actors loss: [-0.0002, 0.0003, -0.0001] / Critic loss: 0.0058\n",
      "1330 Episode / Step: 747148 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1340 Episode / Step: 750024 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1350 Episode / Step: 752796 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1360 Episode / Step: 754027 / Score: 1.00 / Actors loss: [-0.0001, -0.0, -0.0] / Critic loss: 0.0053\n",
      "1370 Episode / Step: 755180 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1380 Episode / Step: 756166 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1390 Episode / Step: 756952 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1400 Episode / Step: 758028 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "1410 Episode / Step: 760874 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1420 Episode / Step: 761636 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1430 Episode / Step: 764735 / Score: 0.90 / Actors loss: [-0.0001, -0.0004, -0.0] / Critic loss: 0.0034\n",
      "1440 Episode / Step: 769935 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1450 Episode / Step: 771398 / Score: 1.00 / Actors loss: [-0.0001, -0.0, -0.0004] / Critic loss: 0.0030\n",
      "1460 Episode / Step: 774296 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1470 Episode / Step: 777433 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1480 Episode / Step: 780287 / Score: 0.90 / Actors loss: [0.0002, 0.0002, 0.0002] / Critic loss: 0.0052\n",
      "1490 Episode / Step: 783326 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1500 Episode / Step: 787978 / Score: 0.80 / Actors loss: [0.0001, -0.0001, -0.0] / Critic loss: 0.0038\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "1510 Episode / Step: 795062 / Score: 0.80 / Actors loss: [0.0001, -0.0003, -0.0] / Critic loss: 0.0052\n",
      "1520 Episode / Step: 796520 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1530 Episode / Step: 798356 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1540 Episode / Step: 804503 / Score: 0.80 / Actors loss: [-0.0001, -0.0001, -0.0001] / Critic loss: 0.0040\n",
      "1550 Episode / Step: 807171 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1560 Episode / Step: 809166 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1570 Episode / Step: 811814 / Score: 1.00 / Actors loss: [-0.0003, -0.0, 0.0002] / Critic loss: 0.0024\n",
      "1580 Episode / Step: 813391 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1590 Episode / Step: 818460 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1600 Episode / Step: 822266 / Score: 0.90 / Actors loss: [0.0003, -0.0001, 0.0003] / Critic loss: 0.0039\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "1610 Episode / Step: 823484 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1620 Episode / Step: 826769 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1630 Episode / Step: 828253 / Score: 1.00 / Actors loss: [-0.0004, -0.0001, 0.0] / Critic loss: 0.0038\n",
      "1640 Episode / Step: 829801 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1650 Episode / Step: 830982 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1660 Episode / Step: 832513 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1670 Episode / Step: 833309 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1680 Episode / Step: 834328 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1690 Episode / Step: 837287 / Score: 0.90 / Actors loss: [-0.0004, 0.0, -0.0003] / Critic loss: 0.0037\n",
      "1700 Episode / Step: 838352 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "1710 Episode / Step: 839927 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1720 Episode / Step: 840807 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1730 Episode / Step: 843907 / Score: 0.90 / Actors loss: [-0.0001, -0.0007, -0.0] / Critic loss: 0.0046\n",
      "1740 Episode / Step: 844676 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1750 Episode / Step: 845540 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1760 Episode / Step: 846153 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1770 Episode / Step: 849013 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1780 Episode / Step: 849820 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1790 Episode / Step: 850528 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1800 Episode / Step: 851237 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "1810 Episode / Step: 852084 / Score: 1.00 / Actors loss: [-0.0002, 0.0002, -0.0002] / Critic loss: 0.0036\n",
      "1820 Episode / Step: 854917 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1830 Episode / Step: 855657 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1840 Episode / Step: 856613 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1850 Episode / Step: 861308 / Score: 0.80 / Actors loss: [0.0003, 0.0001, -0.0002] / Critic loss: 0.0072\n",
      "1860 Episode / Step: 862106 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1870 Episode / Step: 863128 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1880 Episode / Step: 865936 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1890 Episode / Step: 866842 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1900 Episode / Step: 868230 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "1910 Episode / Step: 869147 / Score: 1.00 / Actors loss: [0.0, 0.0002, -0.0] / Critic loss: 0.0057\n",
      "1920 Episode / Step: 869821 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1930 Episode / Step: 870908 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1940 Episode / Step: 871669 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1950 Episode / Step: 874724 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1960 Episode / Step: 875441 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1970 Episode / Step: 878200 / Score: 0.90 / Actors loss: [-0.0002, -0.0001, 0.0003] / Critic loss: 0.0051\n",
      "1980 Episode / Step: 879413 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "1990 Episode / Step: 880545 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2000 Episode / Step: 881417 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "2010 Episode / Step: 882580 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2020 Episode / Step: 883421 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2030 Episode / Step: 886254 / Score: 0.85 / Actors loss: [-0.0006, -0.0005, -0.0005] / Critic loss: 0.0067\n",
      "2040 Episode / Step: 889086 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2050 Episode / Step: 890636 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2060 Episode / Step: 891385 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2070 Episode / Step: 892404 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2080 Episode / Step: 893149 / Score: 0.95 / Actors loss: [0.0002, 0.0, 0.0005] / Critic loss: 0.0054\n",
      "2090 Episode / Step: 894280 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2100 Episode / Step: 895153 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "2110 Episode / Step: 895967 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2120 Episode / Step: 896727 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2130 Episode / Step: 897853 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2140 Episode / Step: 898611 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2150 Episode / Step: 899574 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2160 Episode / Step: 900238 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2170 Episode / Step: 903129 / Score: 0.90 / Actors loss: [-0.0, 0.0001, 0.0] / Critic loss: 0.0047\n",
      "2180 Episode / Step: 904111 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2190 Episode / Step: 904939 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2200 Episode / Step: 907696 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "2210 Episode / Step: 908738 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2220 Episode / Step: 909746 / Score: 1.00 / Actors loss: [-0.0001, -0.0, -0.0002] / Critic loss: 0.0038\n",
      "2230 Episode / Step: 910584 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2240 Episode / Step: 911797 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2250 Episode / Step: 912680 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2260 Episode / Step: 913529 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2270 Episode / Step: 914691 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2280 Episode / Step: 915718 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2290 Episode / Step: 916438 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2300 Episode / Step: 917726 / Score: 1.00 / Actors loss: [-0.0001, 0.0002, -0.0] / Critic loss: 0.0023\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "2310 Episode / Step: 918622 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2320 Episode / Step: 919490 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2330 Episode / Step: 922275 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2340 Episode / Step: 923415 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2350 Episode / Step: 924028 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2360 Episode / Step: 924655 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2370 Episode / Step: 925466 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2380 Episode / Step: 926284 / Score: 1.00 / Actors loss: [-0.0001, 0.0001, -0.0005] / Critic loss: 0.0038\n",
      "2390 Episode / Step: 927151 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2400 Episode / Step: 927870 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "2410 Episode / Step: 928646 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2420 Episode / Step: 929345 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2430 Episode / Step: 930361 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2440 Episode / Step: 931287 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2450 Episode / Step: 931894 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2460 Episode / Step: 933128 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2470 Episode / Step: 934048 / Score: 1.00 / Actors loss: [-0.0001, -0.0002, -0.0003] / Critic loss: 0.0058\n",
      "2480 Episode / Step: 935003 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2490 Episode / Step: 935908 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2500 Episode / Step: 938632 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "2510 Episode / Step: 939580 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2520 Episode / Step: 942412 / Score: 0.80 / Actors loss: [0.0, 0.0002, -0.0002] / Critic loss: 0.0035\n",
      "2530 Episode / Step: 943121 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2540 Episode / Step: 947721 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2550 Episode / Step: 948522 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2560 Episode / Step: 951263 / Score: 0.90 / Actors loss: [0.0002, -0.0004, 0.0] / Critic loss: 0.0048\n",
      "2570 Episode / Step: 952235 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2580 Episode / Step: 954892 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2590 Episode / Step: 955826 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2600 Episode / Step: 957275 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "2610 Episode / Step: 959943 / Score: 0.90 / Actors loss: [0.0001, 0.0, 0.0003] / Critic loss: 0.0068\n",
      "2620 Episode / Step: 960969 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2630 Episode / Step: 962796 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2640 Episode / Step: 963787 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2650 Episode / Step: 964684 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2660 Episode / Step: 965630 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2670 Episode / Step: 968693 / Score: 0.90 / Actors loss: [-0.0005, 0.0003, -0.0003] / Critic loss: 0.0050\n",
      "2680 Episode / Step: 969450 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2690 Episode / Step: 970258 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2700 Episode / Step: 973696 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "2710 Episode / Step: 974963 / Score: 1.00 / Actors loss: [-0.0005, -0.0, 0.0001] / Critic loss: 0.0067\n",
      "2720 Episode / Step: 975827 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2730 Episode / Step: 977269 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2740 Episode / Step: 978627 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2750 Episode / Step: 979520 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2760 Episode / Step: 980642 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2770 Episode / Step: 981602 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2780 Episode / Step: 982579 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2790 Episode / Step: 983640 / Score: 1.00 / Actors loss: [0.0, 0.0001, 0.0004] / Critic loss: 0.0027\n",
      "2800 Episode / Step: 984313 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "2810 Episode / Step: 985273 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2820 Episode / Step: 986996 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2830 Episode / Step: 988069 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2840 Episode / Step: 989259 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2850 Episode / Step: 990648 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2860 Episode / Step: 993807 / Score: 0.90 / Actors loss: [-0.0003, -0.0, -0.0] / Critic loss: 0.0068\n",
      "2870 Episode / Step: 994835 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2880 Episode / Step: 995578 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2890 Episode / Step: 996607 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2900 Episode / Step: 997434 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "2910 Episode / Step: 998640 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "TEST START\n",
      "2920 Episode / Step: 1001427 / Score: 0.90 / Actors loss: [-0.0002, -0.0003, 0.0001] / Critic loss: 0.0037\n",
      "2930 Episode / Step: 1004502 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2940 Episode / Step: 1006999 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2950 Episode / Step: 1008219 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2960 Episode / Step: 1009021 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2970 Episode / Step: 1010465 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2980 Episode / Step: 1011561 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "2990 Episode / Step: 1012297 / Score: 0.95 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3000 Episode / Step: 1013407 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3010 Episode / Step: 1014270 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3020 Episode / Step: 1015135 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3030 Episode / Step: 1018285 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3040 Episode / Step: 1019292 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3050 Episode / Step: 1020038 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3060 Episode / Step: 1020725 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3070 Episode / Step: 1021337 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3080 Episode / Step: 1022233 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3090 Episode / Step: 1023227 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3100 Episode / Step: 1024011 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3110 Episode / Step: 1026856 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3120 Episode / Step: 1031715 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3130 Episode / Step: 1032535 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3140 Episode / Step: 1035253 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3150 Episode / Step: 1035960 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3160 Episode / Step: 1036832 / Score: 0.95 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3170 Episode / Step: 1037645 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3180 Episode / Step: 1038714 / Score: 0.95 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3190 Episode / Step: 1041438 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3200 Episode / Step: 1042385 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3210 Episode / Step: 1043369 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3220 Episode / Step: 1046644 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3230 Episode / Step: 1047616 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3240 Episode / Step: 1048750 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3250 Episode / Step: 1049519 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3260 Episode / Step: 1050505 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3270 Episode / Step: 1051841 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3280 Episode / Step: 1052999 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3290 Episode / Step: 1053877 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3300 Episode / Step: 1054760 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3310 Episode / Step: 1055441 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3320 Episode / Step: 1056481 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3330 Episode / Step: 1057250 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3340 Episode / Step: 1059914 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3350 Episode / Step: 1060888 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3360 Episode / Step: 1062057 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3370 Episode / Step: 1064875 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3380 Episode / Step: 1067378 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3390 Episode / Step: 1068495 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3400 Episode / Step: 1071234 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3410 Episode / Step: 1074201 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3420 Episode / Step: 1074943 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3430 Episode / Step: 1075822 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3440 Episode / Step: 1076696 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3450 Episode / Step: 1077433 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3460 Episode / Step: 1078203 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3470 Episode / Step: 1079089 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3480 Episode / Step: 1079701 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3490 Episode / Step: 1082367 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3500 Episode / Step: 1083269 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3510 Episode / Step: 1084183 / Score: 0.95 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3520 Episode / Step: 1085067 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3530 Episode / Step: 1085972 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3540 Episode / Step: 1087016 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3550 Episode / Step: 1088071 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3560 Episode / Step: 1089083 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3570 Episode / Step: 1089905 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3580 Episode / Step: 1090593 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3590 Episode / Step: 1091416 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3600 Episode / Step: 1094168 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3610 Episode / Step: 1095448 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3620 Episode / Step: 1096517 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3630 Episode / Step: 1097443 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3640 Episode / Step: 1098362 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3650 Episode / Step: 1099152 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "3660 Episode / Step: 1099879 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "engine_configuration_channel = EngineConfigurationChannel()\n",
    "env = UnityEnvironment(file_name=env_name,\n",
    "                       side_channels=[engine_configuration_channel],\n",
    "                       base_port=unity_base_port)\n",
    "env.reset()\n",
    "\n",
    "# Setup Unity Behavior\n",
    "behavior_name = list(env.behavior_specs.keys())[0]\n",
    "spec = env.behavior_specs[behavior_name]\n",
    "engine_configuration_channel.set_configuration_parameters(time_scale=12.0)\n",
    "\n",
    "dec, term = env.get_steps(behavior_name)\n",
    "\n",
    "# Setup agent\n",
    "agent = MAPOCAAgent()\n",
    "actors_losses, critic_losses, scores, episode, score = [[] for _ in range(num_agents)], [], [], 0, 0\n",
    "agents_id, active_agents = dec.agent_id, list(range(num_agents))\n",
    "for step in range(run_step + test_step):\n",
    "    if step == run_step:\n",
    "        if train_mode:\n",
    "            agent.save_model()\n",
    "        print(\"TEST START\")\n",
    "        train_mode = False\n",
    "        engine_configuration_channel.set_configuration_parameters(time_scale=1.0)\n",
    "\n",
    "    preprocess = lambda ray, vec: np.concatenate((ray, vec), axis=-1)\n",
    "    states = preprocess(dec.obs[RAY_OBS], dec.obs[VEC_OBS])\n",
    "    actions = agent.get_action(states, active_agents, train_mode)\n",
    "    real_action = actions + 1\n",
    "    actions_tuple = ActionTuple()\n",
    "    actions_tuple.add_discrete(real_action)\n",
    "    env.set_actions(behavior_name, actions_tuple)\n",
    "    env.step()\n",
    "    # get info from env\n",
    "    dec, term = env.get_steps(behavior_name)\n",
    "    next_states = preprocess(dec.obs[RAY_OBS], dec.obs[VEC_OBS])\n",
    "    next_active_agents = active_agents.copy()\n",
    "    for i in active_agents:\n",
    "        if agents_id[i] in term.agent_id:\n",
    "            next_active_agents.remove(i)\n",
    "\n",
    "    done = len(next_active_agents) == 0\n",
    "    rewards = list(term.group_reward) if done else \\\n",
    "                list(dec.group_reward) + list(term.group_reward)\n",
    "    global_reward = np.mean(rewards)\n",
    "    score += global_reward\n",
    "\n",
    "    if train_mode:\n",
    "        _states = np.zeros((num_agents, state_size))\n",
    "        _actions = -np.ones((num_agents, 1))\n",
    "        _active_agents = np.zeros((num_agents, 1))\n",
    "        for i in active_agents:\n",
    "            _states[i] = states[active_agents.index(i)]\n",
    "            _actions[i] = actions[active_agents.index(i)]\n",
    "            _active_agents[i] = 1\n",
    "        _next_states = np.zeros((num_agents, state_size))\n",
    "        for i in next_active_agents:\n",
    "            _next_states[i] = next_states[next_active_agents.index(i)]\n",
    "        agent.append_sample(_states, _actions, [global_reward], _next_states, [done], _active_agents)\n",
    "\n",
    "        # training\n",
    "        if (step+1) % n_step == 0:\n",
    "            actors_loss, critic_loss = agent.train_model()\n",
    "            for i in range(num_agents):\n",
    "                actors_losses[i].append(actors_loss[i])\n",
    "            critic_losses.append(critic_loss)\n",
    "\n",
    "    active_agents = next_active_agents\n",
    "\n",
    "    if done:\n",
    "        episode +=1\n",
    "        scores.append(score)\n",
    "        agents_id, active_agents, score = dec.agent_id, list(range(num_agents)), 0\n",
    "\n",
    "        # logging\n",
    "        if episode % print_interval == 0:\n",
    "            mean_score = np.mean(scores)\n",
    "            mean_actors_loss = [np.mean(actor_losses) if len(critic_losses) > 0 else 0 for actor_losses in actors_losses]\n",
    "            mean_critic_loss = np.mean(critic_losses)  if len(critic_losses) > 0 else 0\n",
    "            agent.write_summary(mean_score, mean_actors_loss, mean_critic_loss, step)\n",
    "            actors_losses, critic_losses, scores = [[] for _ in range(num_agents)], [], []\n",
    "\n",
    "            actors_loss = [round(loss, 4) for loss in mean_actors_loss]\n",
    "            print(f\"{episode} Episode / Step: {step} / Score: {mean_score:.2f} / \" +\\\n",
    "                    f\"Actors loss: {actors_loss} / Critic loss: {mean_critic_loss:.4f}\" )\n",
    "\n",
    "        # model save\n",
    "        if train_mode and episode % save_interval == 0:\n",
    "            agent.save_model()\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3f52b",
   "metadata": {},
   "source": [
    "## Test the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bf21572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "... Load Model from /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/EscapeRoom/MAPOCA/20250926165447/EscapeRoom_MAPOCA.ckpt\n",
      "10 Episode / Step: 673 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "20 Episode / Step: 1527 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "30 Episode / Step: 2307 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "40 Episode / Step: 3175 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "50 Episode / Step: 4209 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "60 Episode / Step: 4819 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "70 Episode / Step: 5462 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "80 Episode / Step: 6311 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "90 Episode / Step: 6973 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "100 Episode / Step: 8122 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "110 Episode / Step: 8981 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "120 Episode / Step: 9871 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "130 Episode / Step: 10998 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "140 Episode / Step: 11912 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "150 Episode / Step: 13135 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "160 Episode / Step: 14172 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "170 Episode / Step: 15157 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "180 Episode / Step: 16299 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "190 Episode / Step: 17199 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "200 Episode / Step: 17930 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "210 Episode / Step: 18671 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "220 Episode / Step: 19435 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "230 Episode / Step: 20254 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "240 Episode / Step: 21020 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "250 Episode / Step: 21861 / Score: 0.95 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "260 Episode / Step: 22883 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "270 Episode / Step: 23821 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "280 Episode / Step: 24923 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "290 Episode / Step: 25737 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "300 Episode / Step: 26895 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "310 Episode / Step: 28073 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "320 Episode / Step: 28821 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "330 Episode / Step: 31658 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "340 Episode / Step: 34614 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "350 Episode / Step: 35382 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "360 Episode / Step: 36021 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "370 Episode / Step: 37010 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "380 Episode / Step: 37965 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "390 Episode / Step: 38732 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "400 Episode / Step: 39586 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "410 Episode / Step: 40658 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "420 Episode / Step: 41500 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "430 Episode / Step: 42464 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "440 Episode / Step: 43034 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "450 Episode / Step: 44001 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "460 Episode / Step: 44981 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "470 Episode / Step: 45803 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "480 Episode / Step: 46642 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "490 Episode / Step: 47413 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "500 Episode / Step: 48212 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "510 Episode / Step: 49351 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "520 Episode / Step: 50638 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "530 Episode / Step: 51508 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "540 Episode / Step: 52152 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "550 Episode / Step: 55183 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "560 Episode / Step: 56051 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "570 Episode / Step: 56863 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "580 Episode / Step: 57728 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "590 Episode / Step: 58378 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "600 Episode / Step: 59071 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "610 Episode / Step: 61859 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "620 Episode / Step: 62456 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "630 Episode / Step: 63027 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "640 Episode / Step: 63715 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "650 Episode / Step: 65083 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "660 Episode / Step: 66274 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "670 Episode / Step: 67212 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "680 Episode / Step: 70153 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "690 Episode / Step: 70857 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "700 Episode / Step: 71749 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "710 Episode / Step: 72451 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "720 Episode / Step: 73113 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "730 Episode / Step: 74059 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "740 Episode / Step: 75268 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "750 Episode / Step: 76011 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "760 Episode / Step: 77345 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "770 Episode / Step: 78238 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "780 Episode / Step: 79300 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "790 Episode / Step: 82409 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "800 Episode / Step: 83178 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "810 Episode / Step: 84018 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "820 Episode / Step: 84935 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "830 Episode / Step: 85946 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "840 Episode / Step: 86961 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "850 Episode / Step: 87577 / Score: 0.90 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "860 Episode / Step: 88140 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "870 Episode / Step: 92900 / Score: 0.80 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "880 Episode / Step: 93808 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "890 Episode / Step: 94541 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "900 Episode / Step: 95507 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "910 Episode / Step: 96327 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "920 Episode / Step: 97314 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n",
      "930 Episode / Step: 98076 / Score: 1.00 / Actors loss: [0, 0, 0] / Critic loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "load_model = True\n",
    "train_mode = False\n",
    "\n",
    "load_model_path = save_model_path\n",
    "\n",
    "engine_configuration_channel = EngineConfigurationChannel()\n",
    "env = UnityEnvironment(file_name=env_name,\n",
    "                       side_channels=[engine_configuration_channel],\n",
    "                       base_port=unity_base_port)\n",
    "env.reset()\n",
    "\n",
    "# Setup Unity Behavior\n",
    "behavior_name = list(env.behavior_specs.keys())[0]\n",
    "spec = env.behavior_specs[behavior_name]\n",
    "engine_configuration_channel.set_configuration_parameters(time_scale=1.0)\n",
    "\n",
    "dec, term = env.get_steps(behavior_name)\n",
    "\n",
    "# Setup agent\n",
    "agent = MAPOCAAgent()\n",
    "actors_losses, critic_losses, scores, episode, score = [[] for _ in range(num_agents)], [], [], 0, 0\n",
    "agents_id, active_agents = dec.agent_id, list(range(num_agents))\n",
    "for step in range(test_step):\n",
    "    preprocess = lambda ray, vec: np.concatenate((ray, vec), axis=-1)\n",
    "    states = preprocess(dec.obs[RAY_OBS], dec.obs[VEC_OBS])\n",
    "    actions = agent.get_action(states, active_agents, train_mode)\n",
    "    real_action = actions + 1\n",
    "    actions_tuple = ActionTuple()\n",
    "    actions_tuple.add_discrete(real_action)\n",
    "    env.set_actions(behavior_name, actions_tuple)\n",
    "    env.step()\n",
    "    # get info from env\n",
    "    dec, term = env.get_steps(behavior_name)\n",
    "    next_states = preprocess(dec.obs[RAY_OBS], dec.obs[VEC_OBS])\n",
    "    next_active_agents = active_agents.copy()\n",
    "    for i in active_agents:\n",
    "        if agents_id[i] in term.agent_id:\n",
    "            next_active_agents.remove(i)\n",
    "\n",
    "    done = len(next_active_agents) == 0\n",
    "    rewards = list(term.group_reward) if done else \\\n",
    "                list(dec.group_reward) + list(term.group_reward)\n",
    "    global_reward = np.mean(rewards)\n",
    "    score += global_reward\n",
    "\n",
    "    active_agents = next_active_agents\n",
    "\n",
    "    if done:\n",
    "        episode +=1\n",
    "        scores.append(score)\n",
    "        agents_id, active_agents, score = dec.agent_id, list(range(num_agents)), 0\n",
    "\n",
    "        # logging\n",
    "        if episode % print_interval == 0:\n",
    "            mean_score = np.mean(scores)\n",
    "            mean_actors_loss = [np.mean(actor_losses) if len(critic_losses) > 0 else 0 for actor_losses in actors_losses]\n",
    "            mean_critic_loss = np.mean(critic_losses)  if len(critic_losses) > 0 else 0\n",
    "            agent.write_summary(mean_score, mean_actors_loss, mean_critic_loss, step)\n",
    "            actors_losses, critic_losses, scores = [[] for _ in range(num_agents)], [], []\n",
    "\n",
    "            actors_loss = [round(loss, 4) for loss in mean_actors_loss]\n",
    "            print(f\"{episode} Episode / Step: {step} / Score: {mean_score:.2f} / \" +\\\n",
    "                    f\"Actors loss: {actors_loss} / Critic loss: {mean_critic_loss:.4f}\" )\n",
    "\n",
    "env.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
