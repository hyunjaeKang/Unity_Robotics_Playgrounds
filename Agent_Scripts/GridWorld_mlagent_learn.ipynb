{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# GridWorld_DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8ba6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "test_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"mlagents_learn_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a62e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unity Enviroment\n",
    "game = \"GridWorld\"\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01b4cca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Gridworld.yaml\n",
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Unity6000_Envs/GridWorld_Darwin.app\n",
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld\n"
     ]
    }
   ],
   "source": [
    "config_fp = os.path.join(cur_dir, \"config\", \"Gridworld.yaml\")\n",
    "env_fp = os.path.join(env_dir, env_name)\n",
    "run_id = os.path.join(test_dir, game)\n",
    "\n",
    "print(config_fp)\n",
    "print(env_fp)\n",
    "print(run_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47b032",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6886efe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: GridWorld?team=0\n",
      "[INFO] Hyperparameters for behavior name GridWorld: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t2048\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t200000\n",
      "\ttime_horizon:\t64\n",
      "\tsummary_freq:\t2000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] GridWorld. Step: 2000. Time Elapsed: 12.293 s. Mean Reward: -0.232. Std of Reward: 1.017. Training.\n",
      "[INFO] GridWorld. Step: 4000. Time Elapsed: 23.969 s. Mean Reward: -0.031. Std of Reward: 0.980. Training.\n",
      "[INFO] GridWorld. Step: 6000. Time Elapsed: 35.828 s. Mean Reward: 0.099. Std of Reward: 0.922. Training.\n",
      "[INFO] GridWorld. Step: 8000. Time Elapsed: 47.718 s. Mean Reward: 0.276. Std of Reward: 0.863. Training.\n",
      "[INFO] GridWorld. Step: 10000. Time Elapsed: 59.839 s. Mean Reward: 0.409. Std of Reward: 0.824. Training.\n",
      "[INFO] GridWorld. Step: 12000. Time Elapsed: 71.861 s. Mean Reward: 0.491. Std of Reward: 0.772. Training.\n",
      "[INFO] GridWorld. Step: 14000. Time Elapsed: 84.160 s. Mean Reward: 0.546. Std of Reward: 0.749. Training.\n",
      "[INFO] GridWorld. Step: 16000. Time Elapsed: 96.304 s. Mean Reward: 0.599. Std of Reward: 0.707. Training.\n",
      "[INFO] GridWorld. Step: 18000. Time Elapsed: 108.613 s. Mean Reward: 0.665. Std of Reward: 0.625. Training.\n",
      "[INFO] GridWorld. Step: 20000. Time Elapsed: 121.037 s. Mean Reward: 0.596. Std of Reward: 0.719. Training.\n",
      "[INFO] GridWorld. Step: 22000. Time Elapsed: 133.348 s. Mean Reward: 0.640. Std of Reward: 0.687. Training.\n",
      "[INFO] GridWorld. Step: 24000. Time Elapsed: 145.647 s. Mean Reward: 0.623. Std of Reward: 0.708. Training.\n",
      "[INFO] GridWorld. Step: 26000. Time Elapsed: 158.127 s. Mean Reward: 0.678. Std of Reward: 0.651. Training.\n",
      "[INFO] GridWorld. Step: 28000. Time Elapsed: 170.617 s. Mean Reward: 0.684. Std of Reward: 0.668. Training.\n",
      "[INFO] GridWorld. Step: 30000. Time Elapsed: 182.940 s. Mean Reward: 0.732. Std of Reward: 0.604. Training.\n",
      "[INFO] GridWorld. Step: 32000. Time Elapsed: 195.849 s. Mean Reward: 0.724. Std of Reward: 0.625. Training.\n",
      "[INFO] GridWorld. Step: 34000. Time Elapsed: 208.435 s. Mean Reward: 0.791. Std of Reward: 0.541. Training.\n",
      "[INFO] GridWorld. Step: 36000. Time Elapsed: 221.068 s. Mean Reward: 0.806. Std of Reward: 0.514. Training.\n",
      "[INFO] GridWorld. Step: 38000. Time Elapsed: 233.926 s. Mean Reward: 0.832. Std of Reward: 0.482. Training.\n",
      "[INFO] GridWorld. Step: 40000. Time Elapsed: 246.826 s. Mean Reward: 0.850. Std of Reward: 0.445. Training.\n",
      "[INFO] GridWorld. Step: 42000. Time Elapsed: 259.981 s. Mean Reward: 0.745. Std of Reward: 0.619. Training.\n",
      "[INFO] GridWorld. Step: 44000. Time Elapsed: 272.952 s. Mean Reward: 0.765. Std of Reward: 0.590. Training.\n",
      "[INFO] GridWorld. Step: 46000. Time Elapsed: 285.674 s. Mean Reward: 0.800. Std of Reward: 0.542. Training.\n",
      "[INFO] GridWorld. Step: 48000. Time Elapsed: 298.946 s. Mean Reward: 0.785. Std of Reward: 0.563. Training.\n",
      "[INFO] GridWorld. Step: 50000. Time Elapsed: 311.749 s. Mean Reward: 0.797. Std of Reward: 0.549. Training.\n",
      "[INFO] GridWorld. Step: 52000. Time Elapsed: 324.886 s. Mean Reward: 0.829. Std of Reward: 0.494. Training.\n",
      "[INFO] GridWorld. Step: 54000. Time Elapsed: 337.740 s. Mean Reward: 0.808. Std of Reward: 0.533. Training.\n",
      "[INFO] GridWorld. Step: 56000. Time Elapsed: 350.641 s. Mean Reward: 0.844. Std of Reward: 0.475. Training.\n",
      "[INFO] GridWorld. Step: 58000. Time Elapsed: 363.816 s. Mean Reward: 0.818. Std of Reward: 0.518. Training.\n",
      "[INFO] GridWorld. Step: 60000. Time Elapsed: 376.785 s. Mean Reward: 0.824. Std of Reward: 0.513. Training.\n",
      "[INFO] GridWorld. Step: 62000. Time Elapsed: 390.024 s. Mean Reward: 0.868. Std of Reward: 0.427. Training.\n",
      "[INFO] GridWorld. Step: 64000. Time Elapsed: 403.028 s. Mean Reward: 0.865. Std of Reward: 0.437. Training.\n",
      "[INFO] GridWorld. Step: 66000. Time Elapsed: 415.974 s. Mean Reward: 0.812. Std of Reward: 0.532. Training.\n",
      "[INFO] GridWorld. Step: 68000. Time Elapsed: 428.991 s. Mean Reward: 0.831. Std of Reward: 0.498. Training.\n",
      "[INFO] GridWorld. Step: 70000. Time Elapsed: 441.945 s. Mean Reward: 0.837. Std of Reward: 0.482. Training.\n",
      "[INFO] GridWorld. Step: 72000. Time Elapsed: 455.012 s. Mean Reward: 0.824. Std of Reward: 0.515. Training.\n",
      "[INFO] GridWorld. Step: 74000. Time Elapsed: 468.170 s. Mean Reward: 0.883. Std of Reward: 0.401. Training.\n",
      "[INFO] GridWorld. Step: 76000. Time Elapsed: 477.521 s. Mean Reward: 0.859. Std of Reward: 0.446. Training.\n",
      "[INFO] GridWorld. Step: 78000. Time Elapsed: 490.896 s. Mean Reward: 0.857. Std of Reward: 0.458. Training.\n",
      "[INFO] GridWorld. Step: 80000. Time Elapsed: 503.913 s. Mean Reward: 0.864. Std of Reward: 0.434. Training.\n",
      "[INFO] GridWorld. Step: 82000. Time Elapsed: 516.942 s. Mean Reward: 0.870. Std of Reward: 0.433. Training.\n",
      "[INFO] GridWorld. Step: 84000. Time Elapsed: 530.113 s. Mean Reward: 0.860. Std of Reward: 0.442. Training.\n",
      "[INFO] GridWorld. Step: 86000. Time Elapsed: 543.293 s. Mean Reward: 0.869. Std of Reward: 0.429. Training.\n",
      "[INFO] GridWorld. Step: 88000. Time Elapsed: 556.484 s. Mean Reward: 0.903. Std of Reward: 0.346. Training.\n",
      "[INFO] GridWorld. Step: 90000. Time Elapsed: 569.202 s. Mean Reward: 0.882. Std of Reward: 0.398. Training.\n",
      "[INFO] GridWorld. Step: 92000. Time Elapsed: 582.431 s. Mean Reward: 0.887. Std of Reward: 0.398. Training.\n",
      "[INFO] GridWorld. Step: 94000. Time Elapsed: 595.631 s. Mean Reward: 0.905. Std of Reward: 0.353. Training.\n",
      "[INFO] GridWorld. Step: 96000. Time Elapsed: 608.560 s. Mean Reward: 0.918. Std of Reward: 0.317. Training.\n",
      "[INFO] GridWorld. Step: 98000. Time Elapsed: 621.952 s. Mean Reward: 0.936. Std of Reward: 0.261. Training.\n",
      "[INFO] GridWorld. Step: 100000. Time Elapsed: 635.140 s. Mean Reward: 0.876. Std of Reward: 0.426. Training.\n",
      "[INFO] GridWorld. Step: 102000. Time Elapsed: 648.582 s. Mean Reward: 0.938. Std of Reward: 0.258. Training.\n",
      "[INFO] GridWorld. Step: 104000. Time Elapsed: 661.703 s. Mean Reward: 0.912. Std of Reward: 0.335. Training.\n",
      "[INFO] GridWorld. Step: 106000. Time Elapsed: 674.953 s. Mean Reward: 0.926. Std of Reward: 0.302. Training.\n",
      "[INFO] GridWorld. Step: 108000. Time Elapsed: 688.232 s. Mean Reward: 0.913. Std of Reward: 0.332. Training.\n",
      "[INFO] GridWorld. Step: 110000. Time Elapsed: 701.024 s. Mean Reward: 0.912. Std of Reward: 0.326. Training.\n",
      "[INFO] GridWorld. Step: 112000. Time Elapsed: 714.437 s. Mean Reward: 0.893. Std of Reward: 0.384. Training.\n",
      "[INFO] GridWorld. Step: 114000. Time Elapsed: 727.351 s. Mean Reward: 0.940. Std of Reward: 0.237. Training.\n",
      "[INFO] GridWorld. Step: 116000. Time Elapsed: 740.640 s. Mean Reward: 0.925. Std of Reward: 0.299. Training.\n",
      "[INFO] GridWorld. Step: 118000. Time Elapsed: 753.932 s. Mean Reward: 0.923. Std of Reward: 0.304. Training.\n",
      "[INFO] GridWorld. Step: 120000. Time Elapsed: 766.954 s. Mean Reward: 0.919. Std of Reward: 0.315. Training.\n",
      "[INFO] GridWorld. Step: 122000. Time Elapsed: 780.489 s. Mean Reward: 0.901. Std of Reward: 0.367. Training.\n",
      "[INFO] GridWorld. Step: 124000. Time Elapsed: 793.671 s. Mean Reward: 0.873. Std of Reward: 0.427. Training.\n",
      "[INFO] GridWorld. Step: 126000. Time Elapsed: 806.928 s. Mean Reward: 0.940. Std of Reward: 0.254. Training.\n",
      "[INFO] GridWorld. Step: 128000. Time Elapsed: 820.214 s. Mean Reward: 0.947. Std of Reward: 0.225. Training.\n",
      "[INFO] GridWorld. Step: 130000. Time Elapsed: 833.430 s. Mean Reward: 0.912. Std of Reward: 0.344. Training.\n",
      "[INFO] GridWorld. Step: 132000. Time Elapsed: 846.951 s. Mean Reward: 0.924. Std of Reward: 0.307. Training.\n",
      "[INFO] GridWorld. Step: 134000. Time Elapsed: 860.521 s. Mean Reward: 0.913. Std of Reward: 0.342. Training.\n",
      "[INFO] GridWorld. Step: 136000. Time Elapsed: 873.405 s. Mean Reward: 0.937. Std of Reward: 0.254. Training.\n",
      "[INFO] GridWorld. Step: 138000. Time Elapsed: 886.727 s. Mean Reward: 0.917. Std of Reward: 0.318. Training.\n",
      "[INFO] GridWorld. Step: 140000. Time Elapsed: 899.794 s. Mean Reward: 0.953. Std of Reward: 0.194. Training.\n",
      "[INFO] GridWorld. Step: 142000. Time Elapsed: 913.306 s. Mean Reward: 0.947. Std of Reward: 0.225. Training.\n",
      "[INFO] GridWorld. Step: 144000. Time Elapsed: 926.545 s. Mean Reward: 0.935. Std of Reward: 0.270. Training.\n",
      "[INFO] GridWorld. Step: 146000. Time Elapsed: 939.473 s. Mean Reward: 0.937. Std of Reward: 0.254. Training.\n",
      "[INFO] GridWorld. Step: 148000. Time Elapsed: 953.001 s. Mean Reward: 0.941. Std of Reward: 0.252. Training.\n",
      "[INFO] GridWorld. Step: 150000. Time Elapsed: 966.008 s. Mean Reward: 0.955. Std of Reward: 0.177. Training.\n",
      "[INFO] GridWorld. Step: 152000. Time Elapsed: 979.490 s. Mean Reward: 0.949. Std of Reward: 0.222. Training.\n",
      "[INFO] GridWorld. Step: 154000. Time Elapsed: 992.816 s. Mean Reward: 0.938. Std of Reward: 0.264. Training.\n",
      "[INFO] GridWorld. Step: 156000. Time Elapsed: 1002.288 s. Mean Reward: 0.964. Std of Reward: 0.126. Training.\n",
      "[INFO] GridWorld. Step: 158000. Time Elapsed: 1015.465 s. Mean Reward: 0.949. Std of Reward: 0.211. Training.\n",
      "[INFO] GridWorld. Step: 160000. Time Elapsed: 1028.698 s. Mean Reward: 0.931. Std of Reward: 0.285. Training.\n",
      "[INFO] GridWorld. Step: 162000. Time Elapsed: 1041.942 s. Mean Reward: 0.951. Std of Reward: 0.208. Training.\n",
      "[INFO] GridWorld. Step: 164000. Time Elapsed: 1055.173 s. Mean Reward: 0.942. Std of Reward: 0.247. Training.\n",
      "[INFO] GridWorld. Step: 166000. Time Elapsed: 1068.637 s. Mean Reward: 0.951. Std of Reward: 0.210. Training.\n",
      "[INFO] GridWorld. Step: 168000. Time Elapsed: 1081.886 s. Mean Reward: 0.963. Std of Reward: 0.148. Training.\n",
      "[INFO] GridWorld. Step: 170000. Time Elapsed: 1095.194 s. Mean Reward: 0.952. Std of Reward: 0.207. Training.\n",
      "[INFO] GridWorld. Step: 172000. Time Elapsed: 1108.642 s. Mean Reward: 0.956. Std of Reward: 0.189. Training.\n",
      "[INFO] GridWorld. Step: 174000. Time Elapsed: 1121.915 s. Mean Reward: 0.957. Std of Reward: 0.186. Training.\n",
      "[INFO] GridWorld. Step: 176000. Time Elapsed: 1135.307 s. Mean Reward: 0.953. Std of Reward: 0.205. Training.\n",
      "[INFO] GridWorld. Step: 178000. Time Elapsed: 1148.659 s. Mean Reward: 0.960. Std of Reward: 0.168. Training.\n",
      "[INFO] GridWorld. Step: 180000. Time Elapsed: 1161.964 s. Mean Reward: 0.937. Std of Reward: 0.266. Training.\n",
      "[INFO] GridWorld. Step: 182000. Time Elapsed: 1175.314 s. Mean Reward: 0.944. Std of Reward: 0.239. Training.\n",
      "[INFO] GridWorld. Step: 184000. Time Elapsed: 1188.489 s. Mean Reward: 0.963. Std of Reward: 0.146. Training.\n",
      "[INFO] GridWorld. Step: 186000. Time Elapsed: 1201.918 s. Mean Reward: 0.957. Std of Reward: 0.172. Training.\n",
      "[INFO] GridWorld. Step: 188000. Time Elapsed: 1215.212 s. Mean Reward: 0.964. Std of Reward: 0.146. Training.\n",
      "[INFO] GridWorld. Step: 190000. Time Elapsed: 1228.619 s. Mean Reward: 0.950. Std of Reward: 0.221. Training.\n",
      "[INFO] GridWorld. Step: 192000. Time Elapsed: 1241.968 s. Mean Reward: 0.952. Std of Reward: 0.205. Training.\n",
      "[INFO] GridWorld. Step: 194000. Time Elapsed: 1255.076 s. Mean Reward: 0.959. Std of Reward: 0.171. Training.\n",
      "[INFO] GridWorld. Step: 196000. Time Elapsed: 1268.633 s. Mean Reward: 0.931. Std of Reward: 0.294. Training.\n",
      "[INFO] GridWorld. Step: 198000. Time Elapsed: 1282.097 s. Mean Reward: 0.957. Std of Reward: 0.185. Training.\n",
      "[INFO] GridWorld. Step: 200000. Time Elapsed: 1295.351 s. Mean Reward: 0.958. Std of Reward: 0.172. Training.\n",
      "/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:1176: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_PPO/GridWorld/GridWorld-200001.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_PPO/GridWorld/GridWorld-200001.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_PPO/GridWorld.onnx.\n"
     ]
    }
   ],
   "source": [
    "!mlagents-learn $config_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$test_dir \\\n",
    "               --run-id=GridWorld_PPO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad33878",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f5c2e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: GridWorld?team=0\n",
      "[INFO] Hyperparameters for behavior name GridWorld: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t2048\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t200000\n",
      "\ttime_horizon:\t64\n",
      "\tsummary_freq:\t2000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] Resuming from /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_PPO/GridWorld.\n",
      "[INFO] Resuming training from step 200001.\n",
      "[INFO] GridWorld. Step: 202000. Time Elapsed: 13.218 s. Mean Reward: 0.946. Std of Reward: 0.236. Not Training.\n",
      "[INFO] GridWorld. Step: 204000. Time Elapsed: 22.215 s. Mean Reward: 0.963. Std of Reward: 0.147. Not Training.\n",
      "[INFO] GridWorld. Step: 206000. Time Elapsed: 31.208 s. Mean Reward: 0.938. Std of Reward: 0.264. Not Training.\n",
      "[INFO] GridWorld. Step: 208000. Time Elapsed: 40.217 s. Mean Reward: 0.959. Std of Reward: 0.171. Not Training.\n",
      "[INFO] GridWorld. Step: 210000. Time Elapsed: 49.217 s. Mean Reward: 0.951. Std of Reward: 0.208. Not Training.\n",
      "[INFO] GridWorld. Step: 212000. Time Elapsed: 58.231 s. Mean Reward: 0.956. Std of Reward: 0.188. Not Training.\n",
      "[INFO] GridWorld. Step: 214000. Time Elapsed: 67.335 s. Mean Reward: 0.961. Std of Reward: 0.166. Not Training.\n",
      "[INFO] GridWorld. Step: 216000. Time Elapsed: 76.363 s. Mean Reward: 0.952. Std of Reward: 0.206. Not Training.\n",
      "[INFO] GridWorld. Step: 218000. Time Elapsed: 85.363 s. Mean Reward: 0.947. Std of Reward: 0.234. Not Training.\n",
      "[INFO] GridWorld. Step: 220000. Time Elapsed: 94.367 s. Mean Reward: 0.945. Std of Reward: 0.239. Not Training.\n",
      "[INFO] GridWorld. Step: 222000. Time Elapsed: 103.431 s. Mean Reward: 0.933. Std of Reward: 0.285. Not Training.\n",
      "[INFO] GridWorld. Step: 224000. Time Elapsed: 112.483 s. Mean Reward: 0.953. Std of Reward: 0.206. Not Training.\n",
      "[INFO] GridWorld. Step: 226000. Time Elapsed: 121.442 s. Mean Reward: 0.962. Std of Reward: 0.149. Not Training.\n",
      "[INFO] GridWorld. Step: 228000. Time Elapsed: 130.437 s. Mean Reward: 0.951. Std of Reward: 0.210. Not Training.\n",
      "[INFO] GridWorld. Step: 230000. Time Elapsed: 139.512 s. Mean Reward: 0.960. Std of Reward: 0.169. Not Training.\n",
      "[INFO] GridWorld. Step: 232000. Time Elapsed: 148.662 s. Mean Reward: 0.928. Std of Reward: 0.303. Not Training.\n",
      "[INFO] GridWorld. Step: 234000. Time Elapsed: 157.732 s. Mean Reward: 0.956. Std of Reward: 0.187. Not Training.\n",
      "[INFO] GridWorld. Step: 236000. Time Elapsed: 166.817 s. Mean Reward: 0.954. Std of Reward: 0.202. Not Training.\n",
      "[INFO] GridWorld. Step: 238000. Time Elapsed: 175.887 s. Mean Reward: 0.953. Std of Reward: 0.204. Not Training.\n",
      "[INFO] GridWorld. Step: 240000. Time Elapsed: 184.979 s. Mean Reward: 0.946. Std of Reward: 0.235. Not Training.\n",
      "[INFO] GridWorld. Step: 242000. Time Elapsed: 193.955 s. Mean Reward: 0.952. Std of Reward: 0.209. Not Training.\n",
      "[INFO] GridWorld. Step: 244000. Time Elapsed: 203.050 s. Mean Reward: 0.954. Std of Reward: 0.204. Not Training.\n",
      "[INFO] GridWorld. Step: 246000. Time Elapsed: 212.179 s. Mean Reward: 0.954. Std of Reward: 0.203. Not Training.\n",
      "[INFO] GridWorld. Step: 248000. Time Elapsed: 221.258 s. Mean Reward: 0.967. Std of Reward: 0.120. Not Training.\n",
      "[INFO] GridWorld. Step: 250000. Time Elapsed: 230.352 s. Mean Reward: 0.957. Std of Reward: 0.187. Not Training.\n",
      "[INFO] GridWorld. Step: 252000. Time Elapsed: 239.381 s. Mean Reward: 0.952. Std of Reward: 0.206. Not Training.\n",
      "[INFO] GridWorld. Step: 254000. Time Elapsed: 248.374 s. Mean Reward: 0.949. Std of Reward: 0.223. Not Training.\n",
      "[INFO] GridWorld. Step: 256000. Time Elapsed: 257.529 s. Mean Reward: 0.959. Std of Reward: 0.169. Not Training.\n",
      "[INFO] GridWorld. Step: 258000. Time Elapsed: 266.552 s. Mean Reward: 0.952. Std of Reward: 0.205. Not Training.\n",
      "[INFO] GridWorld. Step: 260000. Time Elapsed: 275.575 s. Mean Reward: 0.954. Std of Reward: 0.192. Not Training.\n",
      "[INFO] GridWorld. Step: 262000. Time Elapsed: 284.662 s. Mean Reward: 0.938. Std of Reward: 0.271. Not Training.\n",
      "[INFO] GridWorld. Step: 264000. Time Elapsed: 293.653 s. Mean Reward: 0.941. Std of Reward: 0.253. Not Training.\n",
      "[INFO] GridWorld. Step: 266000. Time Elapsed: 302.801 s. Mean Reward: 0.938. Std of Reward: 0.272. Not Training.\n",
      "[INFO] GridWorld. Step: 268000. Time Elapsed: 311.922 s. Mean Reward: 0.956. Std of Reward: 0.188. Not Training.\n",
      "[INFO] GridWorld. Step: 270000. Time Elapsed: 321.032 s. Mean Reward: 0.964. Std of Reward: 0.145. Not Training.\n",
      "[INFO] GridWorld. Step: 272000. Time Elapsed: 330.026 s. Mean Reward: 0.937. Std of Reward: 0.267. Not Training.\n",
      "[INFO] GridWorld. Step: 274000. Time Elapsed: 339.136 s. Mean Reward: 0.957. Std of Reward: 0.186. Not Training.\n",
      "[INFO] GridWorld. Step: 276000. Time Elapsed: 348.341 s. Mean Reward: 0.961. Std of Reward: 0.166. Not Training.\n",
      "^C\n",
      "Exception ignored in atexit callback: <function _exit_function at 0x12f50eb90>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/multiprocessing/util.py\", line 357, in _exit_function\n",
      "    p.join()\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/multiprocessing/popen_fork.py\", line 43, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/multiprocessing/popen_fork.py\", line 27, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "!mlagents-learn $config_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$test_dir \\\n",
    "               --run-id=GridWorld_PPO \\\n",
    "               --resume --inference\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
