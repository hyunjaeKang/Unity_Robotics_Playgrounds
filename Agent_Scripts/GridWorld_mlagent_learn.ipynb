{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# GridWorld_PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ba6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "output_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"mlagents_learn_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a62e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Unity6000_Envs/GridWorld_Darwin.app\n"
     ]
    }
   ],
   "source": [
    "# Unity Enviroment\n",
    "game = \"GridWorld\"\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")\n",
    "env_fp = os.path.join(env_dir, env_name)\n",
    "print(env_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a25ba76",
   "metadata": {},
   "source": [
    "## Training PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "360531c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Gridworld_ppo.yaml\n",
      "GridWorld_PPO\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: GridWorld?team=0\n",
      "[INFO] Hyperparameters for behavior name GridWorld: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t2048\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t200000\n",
      "\ttime_horizon:\t64\n",
      "\tsummary_freq:\t2000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] GridWorld. Step: 2000. Time Elapsed: 12.419 s. Mean Reward: -0.461. Std of Reward: 0.989. Training.\n",
      "[INFO] GridWorld. Step: 4000. Time Elapsed: 24.534 s. Mean Reward: 0.029. Std of Reward: 0.990. Training.\n",
      "[INFO] GridWorld. Step: 6000. Time Elapsed: 37.536 s. Mean Reward: 0.337. Std of Reward: 0.883. Training.\n",
      "[INFO] GridWorld. Step: 8000. Time Elapsed: 52.315 s. Mean Reward: 0.420. Std of Reward: 0.785. Training.\n",
      "[INFO] GridWorld. Step: 10000. Time Elapsed: 66.701 s. Mean Reward: 0.475. Std of Reward: 0.747. Training.\n",
      "[INFO] GridWorld. Step: 12000. Time Elapsed: 81.424 s. Mean Reward: 0.471. Std of Reward: 0.776. Training.\n",
      "[INFO] GridWorld. Step: 14000. Time Elapsed: 96.291 s. Mean Reward: 0.565. Std of Reward: 0.729. Training.\n",
      "[INFO] GridWorld. Step: 16000. Time Elapsed: 111.034 s. Mean Reward: 0.658. Std of Reward: 0.654. Training.\n",
      "[INFO] GridWorld. Step: 18000. Time Elapsed: 126.151 s. Mean Reward: 0.667. Std of Reward: 0.630. Training.\n",
      "[INFO] GridWorld. Step: 20000. Time Elapsed: 141.311 s. Mean Reward: 0.667. Std of Reward: 0.653. Training.\n",
      "[INFO] GridWorld. Step: 22000. Time Elapsed: 156.297 s. Mean Reward: 0.692. Std of Reward: 0.639. Training.\n",
      "[INFO] GridWorld. Step: 24000. Time Elapsed: 171.394 s. Mean Reward: 0.666. Std of Reward: 0.659. Training.\n",
      "[INFO] GridWorld. Step: 26000. Time Elapsed: 186.659 s. Mean Reward: 0.731. Std of Reward: 0.594. Training.\n",
      "[INFO] GridWorld. Step: 28000. Time Elapsed: 202.010 s. Mean Reward: 0.679. Std of Reward: 0.653. Training.\n",
      "[INFO] GridWorld. Step: 30000. Time Elapsed: 217.400 s. Mean Reward: 0.779. Std of Reward: 0.541. Training.\n",
      "[INFO] GridWorld. Step: 32000. Time Elapsed: 233.234 s. Mean Reward: 0.699. Std of Reward: 0.650. Training.\n",
      "[INFO] GridWorld. Step: 34000. Time Elapsed: 248.823 s. Mean Reward: 0.728. Std of Reward: 0.615. Training.\n",
      "[INFO] GridWorld. Step: 36000. Time Elapsed: 264.723 s. Mean Reward: 0.750. Std of Reward: 0.600. Training.\n",
      "[INFO] GridWorld. Step: 38000. Time Elapsed: 280.681 s. Mean Reward: 0.784. Std of Reward: 0.556. Training.\n",
      "[INFO] GridWorld. Step: 40000. Time Elapsed: 296.853 s. Mean Reward: 0.738. Std of Reward: 0.620. Training.\n",
      "[INFO] GridWorld. Step: 42000. Time Elapsed: 312.973 s. Mean Reward: 0.820. Std of Reward: 0.509. Training.\n",
      "[INFO] GridWorld. Step: 44000. Time Elapsed: 327.594 s. Mean Reward: 0.790. Std of Reward: 0.552. Training.\n",
      "[INFO] GridWorld. Step: 46000. Time Elapsed: 341.273 s. Mean Reward: 0.792. Std of Reward: 0.547. Training.\n",
      "[INFO] GridWorld. Step: 48000. Time Elapsed: 354.739 s. Mean Reward: 0.799. Std of Reward: 0.531. Training.\n",
      "[INFO] GridWorld. Step: 50000. Time Elapsed: 369.810 s. Mean Reward: 0.777. Std of Reward: 0.568. Training.\n",
      "[INFO] GridWorld. Step: 52000. Time Elapsed: 385.933 s. Mean Reward: 0.875. Std of Reward: 0.411. Training.\n",
      "[INFO] GridWorld. Step: 54000. Time Elapsed: 401.940 s. Mean Reward: 0.853. Std of Reward: 0.449. Training.\n",
      "[INFO] GridWorld. Step: 56000. Time Elapsed: 418.163 s. Mean Reward: 0.791. Std of Reward: 0.561. Training.\n",
      "[INFO] GridWorld. Step: 58000. Time Elapsed: 434.321 s. Mean Reward: 0.793. Std of Reward: 0.556. Training.\n",
      "[INFO] GridWorld. Step: 60000. Time Elapsed: 450.381 s. Mean Reward: 0.818. Std of Reward: 0.519. Training.\n",
      "[INFO] GridWorld. Step: 62000. Time Elapsed: 466.833 s. Mean Reward: 0.845. Std of Reward: 0.474. Training.\n",
      "[INFO] GridWorld. Step: 64000. Time Elapsed: 483.080 s. Mean Reward: 0.842. Std of Reward: 0.482. Training.\n",
      "[INFO] GridWorld. Step: 66000. Time Elapsed: 499.243 s. Mean Reward: 0.834. Std of Reward: 0.493. Training.\n",
      "[INFO] GridWorld. Step: 68000. Time Elapsed: 515.667 s. Mean Reward: 0.882. Std of Reward: 0.400. Training.\n",
      "[INFO] GridWorld. Step: 70000. Time Elapsed: 531.996 s. Mean Reward: 0.851. Std of Reward: 0.467. Training.\n",
      "[INFO] GridWorld. Step: 72000. Time Elapsed: 548.105 s. Mean Reward: 0.827. Std of Reward: 0.508. Training.\n",
      "[INFO] GridWorld. Step: 74000. Time Elapsed: 559.275 s. Mean Reward: 0.861. Std of Reward: 0.448. Training.\n",
      "[INFO] GridWorld. Step: 76000. Time Elapsed: 575.844 s. Mean Reward: 0.892. Std of Reward: 0.379. Training.\n",
      "[INFO] GridWorld. Step: 78000. Time Elapsed: 592.160 s. Mean Reward: 0.849. Std of Reward: 0.471. Training.\n",
      "[INFO] GridWorld. Step: 80000. Time Elapsed: 608.389 s. Mean Reward: 0.863. Std of Reward: 0.443. Training.\n",
      "[INFO] GridWorld. Step: 82000. Time Elapsed: 624.674 s. Mean Reward: 0.827. Std of Reward: 0.510. Training.\n",
      "[INFO] GridWorld. Step: 84000. Time Elapsed: 641.381 s. Mean Reward: 0.872. Std of Reward: 0.429. Training.\n",
      "[INFO] GridWorld. Step: 86000. Time Elapsed: 657.911 s. Mean Reward: 0.909. Std of Reward: 0.346. Training.\n",
      "[INFO] GridWorld. Step: 88000. Time Elapsed: 674.410 s. Mean Reward: 0.880. Std of Reward: 0.415. Training.\n",
      "[INFO] GridWorld. Step: 90000. Time Elapsed: 691.160 s. Mean Reward: 0.870. Std of Reward: 0.441. Training.\n",
      "[INFO] GridWorld. Step: 92000. Time Elapsed: 707.679 s. Mean Reward: 0.894. Std of Reward: 0.389. Training.\n",
      "[INFO] GridWorld. Step: 94000. Time Elapsed: 724.090 s. Mean Reward: 0.878. Std of Reward: 0.423. Training.\n",
      "[INFO] GridWorld. Step: 96000. Time Elapsed: 740.635 s. Mean Reward: 0.899. Std of Reward: 0.369. Training.\n",
      "[INFO] GridWorld. Step: 98000. Time Elapsed: 756.904 s. Mean Reward: 0.915. Std of Reward: 0.317. Training.\n",
      "[INFO] GridWorld. Step: 100000. Time Elapsed: 773.182 s. Mean Reward: 0.912. Std of Reward: 0.336. Training.\n",
      "[INFO] GridWorld. Step: 102000. Time Elapsed: 789.408 s. Mean Reward: 0.899. Std of Reward: 0.371. Training.\n",
      "[INFO] GridWorld. Step: 104000. Time Elapsed: 805.844 s. Mean Reward: 0.908. Std of Reward: 0.349. Training.\n",
      "[INFO] GridWorld. Step: 106000. Time Elapsed: 822.106 s. Mean Reward: 0.909. Std of Reward: 0.340. Training.\n",
      "[INFO] GridWorld. Step: 108000. Time Elapsed: 838.581 s. Mean Reward: 0.869. Std of Reward: 0.435. Training.\n",
      "[INFO] GridWorld. Step: 110000. Time Elapsed: 854.987 s. Mean Reward: 0.934. Std of Reward: 0.274. Training.\n",
      "[INFO] GridWorld. Step: 112000. Time Elapsed: 871.204 s. Mean Reward: 0.915. Std of Reward: 0.334. Training.\n",
      "[INFO] GridWorld. Step: 114000. Time Elapsed: 887.701 s. Mean Reward: 0.885. Std of Reward: 0.406. Training.\n",
      "[INFO] GridWorld. Step: 116000. Time Elapsed: 904.139 s. Mean Reward: 0.904. Std of Reward: 0.362. Training.\n",
      "[INFO] GridWorld. Step: 118000. Time Elapsed: 920.410 s. Mean Reward: 0.903. Std of Reward: 0.364. Training.\n",
      "[INFO] GridWorld. Step: 120000. Time Elapsed: 936.585 s. Mean Reward: 0.881. Std of Reward: 0.415. Training.\n",
      "[INFO] GridWorld. Step: 122000. Time Elapsed: 953.063 s. Mean Reward: 0.921. Std of Reward: 0.316. Training.\n",
      "[INFO] GridWorld. Step: 124000. Time Elapsed: 969.479 s. Mean Reward: 0.921. Std of Reward: 0.317. Training.\n",
      "[INFO] GridWorld. Step: 126000. Time Elapsed: 985.905 s. Mean Reward: 0.912. Std of Reward: 0.339. Training.\n",
      "[INFO] GridWorld. Step: 128000. Time Elapsed: 1002.257 s. Mean Reward: 0.884. Std of Reward: 0.403. Training.\n",
      "[INFO] GridWorld. Step: 130000. Time Elapsed: 1018.744 s. Mean Reward: 0.935. Std of Reward: 0.275. Training.\n",
      "[INFO] GridWorld. Step: 132000. Time Elapsed: 1035.565 s. Mean Reward: 0.932. Std of Reward: 0.282. Training.\n",
      "[INFO] GridWorld. Step: 134000. Time Elapsed: 1052.056 s. Mean Reward: 0.936. Std of Reward: 0.268. Training.\n",
      "[INFO] GridWorld. Step: 136000. Time Elapsed: 1068.433 s. Mean Reward: 0.932. Std of Reward: 0.281. Training.\n",
      "[INFO] GridWorld. Step: 138000. Time Elapsed: 1084.853 s. Mean Reward: 0.937. Std of Reward: 0.259. Training.\n",
      "[INFO] GridWorld. Step: 140000. Time Elapsed: 1101.498 s. Mean Reward: 0.934. Std of Reward: 0.273. Training.\n",
      "[INFO] GridWorld. Step: 142000. Time Elapsed: 1118.014 s. Mean Reward: 0.937. Std of Reward: 0.266. Training.\n",
      "[INFO] GridWorld. Step: 144000. Time Elapsed: 1134.726 s. Mean Reward: 0.924. Std of Reward: 0.310. Training.\n",
      "[INFO] GridWorld. Step: 146000. Time Elapsed: 1151.082 s. Mean Reward: 0.940. Std of Reward: 0.249. Training.\n",
      "[INFO] GridWorld. Step: 148000. Time Elapsed: 1167.495 s. Mean Reward: 0.920. Std of Reward: 0.322. Training.\n",
      "[INFO] GridWorld. Step: 150000. Time Elapsed: 1184.078 s. Mean Reward: 0.937. Std of Reward: 0.265. Training.\n",
      "[INFO] GridWorld. Step: 152000. Time Elapsed: 1200.896 s. Mean Reward: 0.951. Std of Reward: 0.209. Training.\n",
      "[INFO] GridWorld. Step: 154000. Time Elapsed: 1212.057 s. Mean Reward: 0.933. Std of Reward: 0.278. Training.\n",
      "[INFO] GridWorld. Step: 156000. Time Elapsed: 1229.256 s. Mean Reward: 0.938. Std of Reward: 0.256. Training.\n",
      "[INFO] GridWorld. Step: 158000. Time Elapsed: 1246.158 s. Mean Reward: 0.948. Std of Reward: 0.223. Training.\n",
      "[INFO] GridWorld. Step: 160000. Time Elapsed: 1262.862 s. Mean Reward: 0.951. Std of Reward: 0.207. Training.\n",
      "[INFO] GridWorld. Step: 162000. Time Elapsed: 1279.550 s. Mean Reward: 0.940. Std of Reward: 0.253. Training.\n",
      "[INFO] GridWorld. Step: 164000. Time Elapsed: 1296.229 s. Mean Reward: 0.952. Std of Reward: 0.206. Training.\n",
      "[INFO] GridWorld. Step: 166000. Time Elapsed: 1312.591 s. Mean Reward: 0.938. Std of Reward: 0.258. Training.\n",
      "[INFO] GridWorld. Step: 168000. Time Elapsed: 1329.208 s. Mean Reward: 0.939. Std of Reward: 0.263. Training.\n",
      "[INFO] GridWorld. Step: 170000. Time Elapsed: 1346.099 s. Mean Reward: 0.941. Std of Reward: 0.259. Training.\n",
      "[INFO] GridWorld. Step: 172000. Time Elapsed: 1362.584 s. Mean Reward: 0.952. Std of Reward: 0.206. Training.\n",
      "[INFO] GridWorld. Step: 174000. Time Elapsed: 1379.233 s. Mean Reward: 0.935. Std of Reward: 0.275. Training.\n",
      "[INFO] GridWorld. Step: 176000. Time Elapsed: 1395.804 s. Mean Reward: 0.929. Std of Reward: 0.291. Training.\n",
      "[INFO] GridWorld. Step: 178000. Time Elapsed: 1412.589 s. Mean Reward: 0.954. Std of Reward: 0.202. Training.\n",
      "[INFO] GridWorld. Step: 180000. Time Elapsed: 1429.182 s. Mean Reward: 0.948. Std of Reward: 0.227. Training.\n",
      "[INFO] GridWorld. Step: 182000. Time Elapsed: 1445.784 s. Mean Reward: 0.959. Std of Reward: 0.170. Training.\n",
      "[INFO] GridWorld. Step: 184000. Time Elapsed: 1462.258 s. Mean Reward: 0.951. Std of Reward: 0.207. Training.\n",
      "[INFO] GridWorld. Step: 186000. Time Elapsed: 1478.773 s. Mean Reward: 0.960. Std of Reward: 0.169. Training.\n",
      "[INFO] GridWorld. Step: 188000. Time Elapsed: 1495.443 s. Mean Reward: 0.949. Std of Reward: 0.223. Training.\n",
      "[INFO] GridWorld. Step: 190000. Time Elapsed: 1512.015 s. Mean Reward: 0.952. Std of Reward: 0.207. Training.\n",
      "[INFO] GridWorld. Step: 192000. Time Elapsed: 1528.434 s. Mean Reward: 0.956. Std of Reward: 0.189. Training.\n",
      "[INFO] GridWorld. Step: 194000. Time Elapsed: 1544.953 s. Mean Reward: 0.943. Std of Reward: 0.247. Training.\n",
      "[INFO] GridWorld. Step: 196000. Time Elapsed: 1561.469 s. Mean Reward: 0.947. Std of Reward: 0.224. Training.\n",
      "[INFO] GridWorld. Step: 198000. Time Elapsed: 1578.060 s. Mean Reward: 0.941. Std of Reward: 0.251. Training.\n",
      "[INFO] GridWorld. Step: 200000. Time Elapsed: 1594.777 s. Mean Reward: 0.958. Std of Reward: 0.171. Training.\n",
      "/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:1176: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_PPO/GridWorld/GridWorld-200001.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_PPO/GridWorld/GridWorld-200001.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_PPO/GridWorld.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_ppo_fp = os.path.join(cur_dir, \"config\", \"Gridworld_ppo.yaml\")\n",
    "run_ppo_id = \"GridWorld_PPO\"\n",
    "print(config_ppo_fp)\n",
    "print(run_ppo_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_ppo_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8c3c8",
   "metadata": {},
   "source": [
    "## Training SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590578c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Gridworld_ppo.yaml\n",
      "GridWorld_SAC\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: GridWorld?team=0\n",
      "[INFO] Hyperparameters for behavior name GridWorld: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t2048\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t200000\n",
      "\ttime_horizon:\t64\n",
      "\tsummary_freq:\t2000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] GridWorld. Step: 2000. Time Elapsed: 14.167 s. Mean Reward: -0.332. Std of Reward: 1.052. Training.\n",
      "[INFO] GridWorld. Step: 4000. Time Elapsed: 28.856 s. Mean Reward: 0.005. Std of Reward: 0.971. Training.\n",
      "[INFO] GridWorld. Step: 6000. Time Elapsed: 43.359 s. Mean Reward: 0.167. Std of Reward: 0.932. Training.\n",
      "[INFO] GridWorld. Step: 8000. Time Elapsed: 57.934 s. Mean Reward: 0.185. Std of Reward: 0.918. Training.\n",
      "[INFO] GridWorld. Step: 10000. Time Elapsed: 72.419 s. Mean Reward: 0.545. Std of Reward: 0.678. Training.\n",
      "[INFO] GridWorld. Step: 12000. Time Elapsed: 87.043 s. Mean Reward: 0.536. Std of Reward: 0.733. Training.\n",
      "[INFO] GridWorld. Step: 14000. Time Elapsed: 101.782 s. Mean Reward: 0.578. Std of Reward: 0.694. Training.\n",
      "[INFO] GridWorld. Step: 16000. Time Elapsed: 116.473 s. Mean Reward: 0.434. Std of Reward: 0.828. Training.\n",
      "[INFO] GridWorld. Step: 18000. Time Elapsed: 131.445 s. Mean Reward: 0.652. Std of Reward: 0.660. Training.\n",
      "[INFO] GridWorld. Step: 20000. Time Elapsed: 146.309 s. Mean Reward: 0.722. Std of Reward: 0.555. Training.\n",
      "[INFO] GridWorld. Step: 22000. Time Elapsed: 161.297 s. Mean Reward: 0.612. Std of Reward: 0.713. Training.\n",
      "[INFO] GridWorld. Step: 24000. Time Elapsed: 176.103 s. Mean Reward: 0.698. Std of Reward: 0.614. Training.\n",
      "[INFO] GridWorld. Step: 26000. Time Elapsed: 191.183 s. Mean Reward: 0.677. Std of Reward: 0.641. Training.\n",
      "[INFO] GridWorld. Step: 28000. Time Elapsed: 206.440 s. Mean Reward: 0.742. Std of Reward: 0.577. Training.\n",
      "[INFO] GridWorld. Step: 30000. Time Elapsed: 221.636 s. Mean Reward: 0.694. Std of Reward: 0.645. Training.\n",
      "[INFO] GridWorld. Step: 32000. Time Elapsed: 236.871 s. Mean Reward: 0.725. Std of Reward: 0.613. Training.\n",
      "[INFO] GridWorld. Step: 34000. Time Elapsed: 252.175 s. Mean Reward: 0.733. Std of Reward: 0.614. Training.\n",
      "[INFO] GridWorld. Step: 36000. Time Elapsed: 267.533 s. Mean Reward: 0.776. Std of Reward: 0.557. Training.\n",
      "[INFO] GridWorld. Step: 38000. Time Elapsed: 282.875 s. Mean Reward: 0.753. Std of Reward: 0.593. Training.\n",
      "[INFO] GridWorld. Step: 40000. Time Elapsed: 298.114 s. Mean Reward: 0.727. Std of Reward: 0.623. Training.\n",
      "[INFO] GridWorld. Step: 42000. Time Elapsed: 313.455 s. Mean Reward: 0.754. Std of Reward: 0.594. Training.\n",
      "[INFO] GridWorld. Step: 44000. Time Elapsed: 328.701 s. Mean Reward: 0.837. Std of Reward: 0.471. Training.\n",
      "[INFO] GridWorld. Step: 46000. Time Elapsed: 344.168 s. Mean Reward: 0.746. Std of Reward: 0.613. Training.\n",
      "[INFO] GridWorld. Step: 48000. Time Elapsed: 359.839 s. Mean Reward: 0.765. Std of Reward: 0.588. Training.\n",
      "[INFO] GridWorld. Step: 50000. Time Elapsed: 375.420 s. Mean Reward: 0.819. Std of Reward: 0.510. Training.\n",
      "[INFO] GridWorld. Step: 52000. Time Elapsed: 391.156 s. Mean Reward: 0.801. Std of Reward: 0.536. Training.\n",
      "[INFO] GridWorld. Step: 54000. Time Elapsed: 406.804 s. Mean Reward: 0.798. Std of Reward: 0.547. Training.\n",
      "[INFO] GridWorld. Step: 56000. Time Elapsed: 422.540 s. Mean Reward: 0.847. Std of Reward: 0.473. Training.\n",
      "[INFO] GridWorld. Step: 58000. Time Elapsed: 438.127 s. Mean Reward: 0.796. Std of Reward: 0.553. Training.\n",
      "[INFO] GridWorld. Step: 60000. Time Elapsed: 453.872 s. Mean Reward: 0.830. Std of Reward: 0.495. Training.\n",
      "[INFO] GridWorld. Step: 62000. Time Elapsed: 469.386 s. Mean Reward: 0.799. Std of Reward: 0.539. Training.\n",
      "[INFO] GridWorld. Step: 64000. Time Elapsed: 485.084 s. Mean Reward: 0.822. Std of Reward: 0.510. Training.\n",
      "[INFO] GridWorld. Step: 66000. Time Elapsed: 500.985 s. Mean Reward: 0.825. Std of Reward: 0.509. Training.\n",
      "[INFO] GridWorld. Step: 68000. Time Elapsed: 516.790 s. Mean Reward: 0.845. Std of Reward: 0.469. Training.\n",
      "[INFO] GridWorld. Step: 70000. Time Elapsed: 532.538 s. Mean Reward: 0.853. Std of Reward: 0.455. Training.\n",
      "[INFO] GridWorld. Step: 72000. Time Elapsed: 548.358 s. Mean Reward: 0.813. Std of Reward: 0.527. Training.\n",
      "[INFO] GridWorld. Step: 74000. Time Elapsed: 563.956 s. Mean Reward: 0.889. Std of Reward: 0.385. Training.\n",
      "[INFO] GridWorld. Step: 76000. Time Elapsed: 574.753 s. Mean Reward: 0.859. Std of Reward: 0.456. Training.\n",
      "[INFO] GridWorld. Step: 78000. Time Elapsed: 590.616 s. Mean Reward: 0.861. Std of Reward: 0.453. Training.\n",
      "[INFO] GridWorld. Step: 80000. Time Elapsed: 606.492 s. Mean Reward: 0.879. Std of Reward: 0.420. Training.\n",
      "[INFO] GridWorld. Step: 82000. Time Elapsed: 622.112 s. Mean Reward: 0.847. Std of Reward: 0.477. Training.\n",
      "[INFO] GridWorld. Step: 84000. Time Elapsed: 637.945 s. Mean Reward: 0.890. Std of Reward: 0.389. Training.\n",
      "[INFO] GridWorld. Step: 86000. Time Elapsed: 653.746 s. Mean Reward: 0.891. Std of Reward: 0.387. Training.\n",
      "[INFO] GridWorld. Step: 88000. Time Elapsed: 669.455 s. Mean Reward: 0.853. Std of Reward: 0.471. Training.\n",
      "[INFO] GridWorld. Step: 90000. Time Elapsed: 685.079 s. Mean Reward: 0.892. Std of Reward: 0.374. Training.\n",
      "[INFO] GridWorld. Step: 92000. Time Elapsed: 700.745 s. Mean Reward: 0.858. Std of Reward: 0.455. Training.\n",
      "[INFO] GridWorld. Step: 94000. Time Elapsed: 716.528 s. Mean Reward: 0.878. Std of Reward: 0.420. Training.\n",
      "[INFO] GridWorld. Step: 96000. Time Elapsed: 732.458 s. Mean Reward: 0.867. Std of Reward: 0.439. Training.\n",
      "[INFO] GridWorld. Step: 98000. Time Elapsed: 748.332 s. Mean Reward: 0.895. Std of Reward: 0.378. Training.\n",
      "[INFO] GridWorld. Step: 100000. Time Elapsed: 764.300 s. Mean Reward: 0.894. Std of Reward: 0.382. Training.\n",
      "[INFO] GridWorld. Step: 102000. Time Elapsed: 780.261 s. Mean Reward: 0.906. Std of Reward: 0.357. Training.\n",
      "[INFO] GridWorld. Step: 104000. Time Elapsed: 795.950 s. Mean Reward: 0.894. Std of Reward: 0.384. Training.\n",
      "[INFO] GridWorld. Step: 106000. Time Elapsed: 811.770 s. Mean Reward: 0.906. Std of Reward: 0.352. Training.\n",
      "[INFO] GridWorld. Step: 108000. Time Elapsed: 827.638 s. Mean Reward: 0.901. Std of Reward: 0.361. Training.\n",
      "[INFO] GridWorld. Step: 110000. Time Elapsed: 843.433 s. Mean Reward: 0.927. Std of Reward: 0.291. Training.\n",
      "[INFO] GridWorld. Step: 112000. Time Elapsed: 859.180 s. Mean Reward: 0.895. Std of Reward: 0.376. Training.\n",
      "[INFO] GridWorld. Step: 114000. Time Elapsed: 874.900 s. Mean Reward: 0.924. Std of Reward: 0.296. Training.\n",
      "[INFO] GridWorld. Step: 116000. Time Elapsed: 890.648 s. Mean Reward: 0.902. Std of Reward: 0.364. Training.\n",
      "[INFO] GridWorld. Step: 118000. Time Elapsed: 906.550 s. Mean Reward: 0.920. Std of Reward: 0.317. Training.\n",
      "[INFO] GridWorld. Step: 120000. Time Elapsed: 922.480 s. Mean Reward: 0.889. Std of Reward: 0.397. Training.\n",
      "[INFO] GridWorld. Step: 122000. Time Elapsed: 938.406 s. Mean Reward: 0.931. Std of Reward: 0.283. Training.\n",
      "[INFO] GridWorld. Step: 124000. Time Elapsed: 954.183 s. Mean Reward: 0.912. Std of Reward: 0.330. Training.\n",
      "[INFO] GridWorld. Step: 126000. Time Elapsed: 970.200 s. Mean Reward: 0.932. Std of Reward: 0.276. Training.\n",
      "[INFO] GridWorld. Step: 128000. Time Elapsed: 986.115 s. Mean Reward: 0.934. Std of Reward: 0.273. Training.\n",
      "[INFO] GridWorld. Step: 130000. Time Elapsed: 1002.150 s. Mean Reward: 0.917. Std of Reward: 0.328. Training.\n",
      "[INFO] GridWorld. Step: 132000. Time Elapsed: 1018.160 s. Mean Reward: 0.934. Std of Reward: 0.272. Training.\n",
      "[INFO] GridWorld. Step: 134000. Time Elapsed: 1034.096 s. Mean Reward: 0.900. Std of Reward: 0.376. Training.\n",
      "[INFO] GridWorld. Step: 136000. Time Elapsed: 1049.944 s. Mean Reward: 0.907. Std of Reward: 0.355. Training.\n",
      "[INFO] GridWorld. Step: 138000. Time Elapsed: 1066.054 s. Mean Reward: 0.910. Std of Reward: 0.350. Training.\n",
      "[INFO] GridWorld. Step: 140000. Time Elapsed: 1081.774 s. Mean Reward: 0.901. Std of Reward: 0.368. Training.\n",
      "[INFO] GridWorld. Step: 142000. Time Elapsed: 1097.925 s. Mean Reward: 0.938. Std of Reward: 0.263. Training.\n",
      "[INFO] GridWorld. Step: 144000. Time Elapsed: 1113.790 s. Mean Reward: 0.934. Std of Reward: 0.272. Training.\n",
      "[INFO] GridWorld. Step: 146000. Time Elapsed: 1129.927 s. Mean Reward: 0.942. Std of Reward: 0.251. Training.\n",
      "[INFO] GridWorld. Step: 148000. Time Elapsed: 1145.872 s. Mean Reward: 0.929. Std of Reward: 0.291. Training.\n",
      "[INFO] GridWorld. Step: 150000. Time Elapsed: 1161.952 s. Mean Reward: 0.955. Std of Reward: 0.191. Training.\n",
      "[INFO] GridWorld. Step: 152000. Time Elapsed: 1173.001 s. Mean Reward: 0.954. Std of Reward: 0.192. Training.\n",
      "[INFO] GridWorld. Step: 154000. Time Elapsed: 1189.114 s. Mean Reward: 0.941. Std of Reward: 0.254. Training.\n",
      "[INFO] GridWorld. Step: 156000. Time Elapsed: 1205.156 s. Mean Reward: 0.906. Std of Reward: 0.361. Training.\n",
      "[INFO] GridWorld. Step: 158000. Time Elapsed: 1221.414 s. Mean Reward: 0.920. Std of Reward: 0.322. Training.\n",
      "[INFO] GridWorld. Step: 160000. Time Elapsed: 1237.721 s. Mean Reward: 0.945. Std of Reward: 0.239. Training.\n",
      "[INFO] GridWorld. Step: 162000. Time Elapsed: 1253.384 s. Mean Reward: 0.931. Std of Reward: 0.273. Training.\n",
      "[INFO] GridWorld. Step: 164000. Time Elapsed: 1269.293 s. Mean Reward: 0.937. Std of Reward: 0.261. Training.\n",
      "[INFO] GridWorld. Step: 166000. Time Elapsed: 1285.301 s. Mean Reward: 0.950. Std of Reward: 0.209. Training.\n",
      "[INFO] GridWorld. Step: 168000. Time Elapsed: 1301.253 s. Mean Reward: 0.935. Std of Reward: 0.273. Training.\n",
      "[INFO] GridWorld. Step: 170000. Time Elapsed: 1317.021 s. Mean Reward: 0.953. Std of Reward: 0.193. Training.\n",
      "[INFO] GridWorld. Step: 172000. Time Elapsed: 1332.803 s. Mean Reward: 0.953. Std of Reward: 0.193. Training.\n",
      "[INFO] GridWorld. Step: 174000. Time Elapsed: 1348.846 s. Mean Reward: 0.932. Std of Reward: 0.286. Training.\n",
      "[INFO] GridWorld. Step: 176000. Time Elapsed: 1364.880 s. Mean Reward: 0.945. Std of Reward: 0.236. Training.\n",
      "[INFO] GridWorld. Step: 178000. Time Elapsed: 1380.885 s. Mean Reward: 0.948. Std of Reward: 0.231. Training.\n",
      "[INFO] GridWorld. Step: 180000. Time Elapsed: 1396.984 s. Mean Reward: 0.954. Std of Reward: 0.203. Training.\n",
      "[INFO] GridWorld. Step: 182000. Time Elapsed: 1413.038 s. Mean Reward: 0.948. Std of Reward: 0.224. Training.\n",
      "[INFO] GridWorld. Step: 184000. Time Elapsed: 1429.193 s. Mean Reward: 0.964. Std of Reward: 0.146. Training.\n",
      "[INFO] GridWorld. Step: 186000. Time Elapsed: 1445.243 s. Mean Reward: 0.936. Std of Reward: 0.268. Training.\n",
      "[INFO] GridWorld. Step: 188000. Time Elapsed: 1461.501 s. Mean Reward: 0.955. Std of Reward: 0.200. Training.\n",
      "[INFO] GridWorld. Step: 190000. Time Elapsed: 1477.574 s. Mean Reward: 0.957. Std of Reward: 0.187. Training.\n",
      "[INFO] GridWorld. Step: 192000. Time Elapsed: 1490.901 s. Mean Reward: 0.956. Std of Reward: 0.188. Training.\n",
      "[INFO] GridWorld. Step: 194000. Time Elapsed: 1504.225 s. Mean Reward: 0.957. Std of Reward: 0.186. Training.\n",
      "[INFO] GridWorld. Step: 196000. Time Elapsed: 1517.450 s. Mean Reward: 0.949. Std of Reward: 0.221. Training.\n",
      "[INFO] GridWorld. Step: 198000. Time Elapsed: 1530.912 s. Mean Reward: 0.934. Std of Reward: 0.279. Training.\n",
      "[INFO] GridWorld. Step: 200000. Time Elapsed: 1544.151 s. Mean Reward: 0.938. Std of Reward: 0.264. Training.\n",
      "/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:1176: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_SAC/GridWorld/GridWorld-200005.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_SAC/GridWorld/GridWorld-200005.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_SAC/GridWorld.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_sac_fp = os.path.join(cur_dir, \"config\", \"Gridworld_sac.yaml\")\n",
    "run_sac_id = \"GridWorld_SAC\"\n",
    "print(config_ppo_fp)\n",
    "print(run_sac_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_sac_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47b032",
   "metadata": {},
   "source": [
    "## Training POCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6886efe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Gridworld_poca.yaml\n",
      "GridWorld_POCA\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 3.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: GridWorld?team=0\n",
      "[INFO] Hyperparameters for behavior name GridWorld: \n",
      "\ttrainer_type:\tpoca\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t2048\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t200000\n",
      "\ttime_horizon:\t64\n",
      "\tsummary_freq:\t2000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] GridWorld. Step: 2000. Time Elapsed: 12.705 s. Mean Reward: -0.314. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 4000. Time Elapsed: 25.973 s. Mean Reward: 0.008. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 6000. Time Elapsed: 39.446 s. Mean Reward: 0.071. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 8000. Time Elapsed: 53.086 s. Mean Reward: 0.383. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 10000. Time Elapsed: 66.863 s. Mean Reward: 0.362. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 12000. Time Elapsed: 80.682 s. Mean Reward: 0.481. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 14000. Time Elapsed: 94.255 s. Mean Reward: 0.453. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 16000. Time Elapsed: 107.952 s. Mean Reward: 0.608. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 18000. Time Elapsed: 121.450 s. Mean Reward: 0.556. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 20000. Time Elapsed: 135.297 s. Mean Reward: 0.690. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 22000. Time Elapsed: 149.228 s. Mean Reward: 0.616. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 24000. Time Elapsed: 163.290 s. Mean Reward: 0.683. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 26000. Time Elapsed: 177.389 s. Mean Reward: 0.672. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 28000. Time Elapsed: 191.565 s. Mean Reward: 0.691. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 30000. Time Elapsed: 205.688 s. Mean Reward: 0.676. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 32000. Time Elapsed: 219.716 s. Mean Reward: 0.725. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 34000. Time Elapsed: 233.724 s. Mean Reward: 0.742. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 36000. Time Elapsed: 248.107 s. Mean Reward: 0.778. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 38000. Time Elapsed: 262.686 s. Mean Reward: 0.720. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 40000. Time Elapsed: 277.043 s. Mean Reward: 0.711. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 42000. Time Elapsed: 291.593 s. Mean Reward: 0.766. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 44000. Time Elapsed: 306.115 s. Mean Reward: 0.742. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 46000. Time Elapsed: 320.579 s. Mean Reward: 0.774. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 48000. Time Elapsed: 335.598 s. Mean Reward: 0.814. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 50000. Time Elapsed: 350.260 s. Mean Reward: 0.819. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 52000. Time Elapsed: 365.103 s. Mean Reward: 0.783. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 54000. Time Elapsed: 380.013 s. Mean Reward: 0.822. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 56000. Time Elapsed: 394.803 s. Mean Reward: 0.829. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 58000. Time Elapsed: 409.504 s. Mean Reward: 0.752. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 60000. Time Elapsed: 424.130 s. Mean Reward: 0.825. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 62000. Time Elapsed: 438.936 s. Mean Reward: 0.832. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 64000. Time Elapsed: 453.941 s. Mean Reward: 0.828. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 66000. Time Elapsed: 468.477 s. Mean Reward: 0.874. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 68000. Time Elapsed: 483.630 s. Mean Reward: 0.868. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 70000. Time Elapsed: 498.751 s. Mean Reward: 0.813. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 72000. Time Elapsed: 513.452 s. Mean Reward: 0.860. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 74000. Time Elapsed: 523.144 s. Mean Reward: 0.900. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 76000. Time Elapsed: 538.489 s. Mean Reward: 0.840. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 78000. Time Elapsed: 553.576 s. Mean Reward: 0.880. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 80000. Time Elapsed: 568.600 s. Mean Reward: 0.888. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 82000. Time Elapsed: 583.696 s. Mean Reward: 0.904. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 84000. Time Elapsed: 598.672 s. Mean Reward: 0.906. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 86000. Time Elapsed: 613.831 s. Mean Reward: 0.876. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 88000. Time Elapsed: 628.971 s. Mean Reward: 0.885. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 90000. Time Elapsed: 643.993 s. Mean Reward: 0.913. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 92000. Time Elapsed: 659.187 s. Mean Reward: 0.849. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 94000. Time Elapsed: 674.523 s. Mean Reward: 0.917. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 96000. Time Elapsed: 689.605 s. Mean Reward: 0.884. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 98000. Time Elapsed: 704.622 s. Mean Reward: 0.909. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 100000. Time Elapsed: 719.701 s. Mean Reward: 0.919. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 102000. Time Elapsed: 734.999 s. Mean Reward: 0.900. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 104000. Time Elapsed: 750.061 s. Mean Reward: 0.909. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 106000. Time Elapsed: 764.984 s. Mean Reward: 0.904. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 108000. Time Elapsed: 780.389 s. Mean Reward: 0.892. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 110000. Time Elapsed: 795.786 s. Mean Reward: 0.916. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 112000. Time Elapsed: 810.950 s. Mean Reward: 0.920. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 114000. Time Elapsed: 826.264 s. Mean Reward: 0.935. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 116000. Time Elapsed: 841.664 s. Mean Reward: 0.906. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 118000. Time Elapsed: 856.730 s. Mean Reward: 0.927. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 120000. Time Elapsed: 871.970 s. Mean Reward: 0.901. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 122000. Time Elapsed: 887.217 s. Mean Reward: 0.947. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 124000. Time Elapsed: 902.385 s. Mean Reward: 0.931. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 126000. Time Elapsed: 917.358 s. Mean Reward: 0.923. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 128000. Time Elapsed: 932.434 s. Mean Reward: 0.933. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 130000. Time Elapsed: 947.781 s. Mean Reward: 0.929. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 132000. Time Elapsed: 963.093 s. Mean Reward: 0.932. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 134000. Time Elapsed: 978.110 s. Mean Reward: 0.931. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 136000. Time Elapsed: 993.248 s. Mean Reward: 0.926. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 138000. Time Elapsed: 1008.511 s. Mean Reward: 0.930. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 140000. Time Elapsed: 1023.718 s. Mean Reward: 0.934. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 142000. Time Elapsed: 1039.227 s. Mean Reward: 0.931. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 144000. Time Elapsed: 1054.356 s. Mean Reward: 0.947. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 146000. Time Elapsed: 1069.752 s. Mean Reward: 0.952. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 148000. Time Elapsed: 1085.212 s. Mean Reward: 0.917. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 150000. Time Elapsed: 1100.335 s. Mean Reward: 0.951. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 152000. Time Elapsed: 1115.577 s. Mean Reward: 0.941. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 154000. Time Elapsed: 1130.864 s. Mean Reward: 0.951. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 156000. Time Elapsed: 1140.931 s. Mean Reward: 0.942. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 158000. Time Elapsed: 1156.211 s. Mean Reward: 0.944. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 160000. Time Elapsed: 1171.311 s. Mean Reward: 0.936. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 162000. Time Elapsed: 1186.557 s. Mean Reward: 0.952. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 164000. Time Elapsed: 1201.745 s. Mean Reward: 0.960. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 166000. Time Elapsed: 1216.965 s. Mean Reward: 0.959. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 168000. Time Elapsed: 1232.199 s. Mean Reward: 0.937. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 170000. Time Elapsed: 1247.603 s. Mean Reward: 0.961. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 172000. Time Elapsed: 1262.812 s. Mean Reward: 0.939. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 174000. Time Elapsed: 1278.024 s. Mean Reward: 0.936. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 176000. Time Elapsed: 1293.337 s. Mean Reward: 0.957. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 178000. Time Elapsed: 1308.419 s. Mean Reward: 0.939. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 180000. Time Elapsed: 1323.612 s. Mean Reward: 0.959. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 182000. Time Elapsed: 1338.908 s. Mean Reward: 0.950. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 184000. Time Elapsed: 1354.191 s. Mean Reward: 0.961. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 186000. Time Elapsed: 1369.241 s. Mean Reward: 0.952. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 188000. Time Elapsed: 1384.648 s. Mean Reward: 0.958. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 190000. Time Elapsed: 1399.932 s. Mean Reward: 0.942. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 192000. Time Elapsed: 1414.856 s. Mean Reward: 0.941. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 194000. Time Elapsed: 1430.247 s. Mean Reward: 0.963. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 196000. Time Elapsed: 1445.691 s. Mean Reward: 0.960. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 198000. Time Elapsed: 1460.987 s. Mean Reward: 0.954. Mean Group Reward: 0.000. Training.\n",
      "[INFO] GridWorld. Step: 200000. Time Elapsed: 1476.021 s. Mean Reward: 0.951. Mean Group Reward: 0.000. Training.\n",
      "/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:1176: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_POCA/GridWorld/GridWorld-200002.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_POCA/GridWorld/GridWorld-200002.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/GridWorld_POCA/GridWorld.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_poca_fp = os.path.join(cur_dir, \"config\", \"Gridworld_poca.yaml\")\n",
    "run_poca_id = \"GridWorld_POCA\"\n",
    "print(config_poca_fp)\n",
    "print(run_poca_id)\n",
    "\n",
    "!mlagents-learn $config_poca_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_poca_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad33878",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f5c2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mlagents-learn $config_fp \\\n",
    "#                --env=$env_fp \\\n",
    "#                --results-dir=$test_dir \\\n",
    "#                --run-id=$run_id \\\n",
    "#                --resume --inference\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
