{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# Kart_BC_GAIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c6c95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ba6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "output_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"mlagents_learn_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a62e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Unity6000_Envs/Kart_Darwin.app\n"
     ]
    }
   ],
   "source": [
    "# Unity Enviroment\n",
    "game = \"Kart\"\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")\n",
    "env_fp = os.path.join(env_dir, env_name)\n",
    "print(env_fp)\n",
    "baseport = 1991"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e227b",
   "metadata": {},
   "source": [
    "## Training PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01b4cca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Kart_ppo_BC_GAIL.yaml\n",
      "Kart_PPO_BC_GAIL\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: ArcadeDriver?team=0\n",
      "[INFO] Hyperparameters for behavior name ArcadeDriver: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t1024\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t256\n",
      "\t  num_layers:\t5\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\t  gail:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t0.05\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t64\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\t    learning_rate:\t0.0003\n",
      "\t    encoding_size:\tNone\n",
      "\t    use_actions:\tTrue\n",
      "\t    use_vail:\tFalse\n",
      "\t    demo_path:\tdemo/KartAgent.demo\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t5000000\n",
      "\ttime_horizon:\t64\n",
      "\tsummary_freq:\t15000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\t\n",
      "\t  demo_path:\tdemo/KartAgent.demo\n",
      "\t  steps:\t0\n",
      "\t  strength:\t0.05\n",
      "\t  samples_per_update:\t512\n",
      "\t  num_epoch:\tNone\n",
      "\t  batch_size:\tNone\n",
      "[INFO] ArcadeDriver. Step: 15000. Time Elapsed: 48.843 s. Mean Reward: -5.975. Std of Reward: 0.232. Training.\n",
      "[INFO] ArcadeDriver. Step: 30000. Time Elapsed: 92.127 s. Mean Reward: -5.950. Std of Reward: 0.212. Training.\n",
      "[INFO] ArcadeDriver. Step: 45000. Time Elapsed: 134.893 s. Mean Reward: -5.913. Std of Reward: 0.278. Training.\n",
      "[INFO] ArcadeDriver. Step: 60000. Time Elapsed: 178.902 s. Mean Reward: -5.932. Std of Reward: 0.248. Training.\n",
      "[INFO] ArcadeDriver. Step: 75000. Time Elapsed: 223.276 s. Mean Reward: -5.948. Std of Reward: 0.218. Training.\n",
      "[INFO] ArcadeDriver. Step: 90000. Time Elapsed: 267.661 s. Mean Reward: -5.958. Std of Reward: 0.201. Training.\n",
      "[INFO] ArcadeDriver. Step: 105000. Time Elapsed: 312.143 s. Mean Reward: -5.952. Std of Reward: 0.205. Training.\n",
      "[INFO] ArcadeDriver. Step: 120000. Time Elapsed: 356.727 s. Mean Reward: -5.832. Std of Reward: 0.367. Training.\n",
      "[INFO] ArcadeDriver. Step: 135000. Time Elapsed: 400.920 s. Mean Reward: -5.962. Std of Reward: 0.186. Training.\n",
      "[INFO] ArcadeDriver. Step: 150000. Time Elapsed: 445.753 s. Mean Reward: -5.995. Std of Reward: 0.033. Training.\n",
      "[INFO] ArcadeDriver. Step: 165000. Time Elapsed: 489.286 s. Mean Reward: -5.993. Std of Reward: 0.018. Training.\n",
      "[INFO] ArcadeDriver. Step: 180000. Time Elapsed: 533.127 s. Mean Reward: -5.997. Std of Reward: 0.040. Training.\n",
      "[INFO] ArcadeDriver. Step: 195000. Time Elapsed: 576.611 s. Mean Reward: -6.002. Std of Reward: 0.037. Training.\n",
      "[INFO] ArcadeDriver. Step: 210000. Time Elapsed: 620.352 s. Mean Reward: -6.008. Std of Reward: 0.021. Training.\n",
      "[INFO] ArcadeDriver. Step: 225000. Time Elapsed: 663.919 s. Mean Reward: -6.011. Std of Reward: 0.024. Training.\n",
      "[INFO] ArcadeDriver. Step: 240000. Time Elapsed: 711.835 s. Mean Reward: -6.013. Std of Reward: 0.023. Training.\n",
      "[INFO] ArcadeDriver. Step: 255000. Time Elapsed: 761.055 s. Mean Reward: -6.015. Std of Reward: 0.023. Training.\n",
      "[INFO] ArcadeDriver. Step: 270000. Time Elapsed: 809.756 s. Mean Reward: -6.016. Std of Reward: 0.023. Training.\n",
      "[INFO] ArcadeDriver. Step: 285000. Time Elapsed: 853.555 s. Mean Reward: -6.013. Std of Reward: 0.022. Training.\n",
      "[INFO] ArcadeDriver. Step: 300000. Time Elapsed: 897.256 s. Mean Reward: -6.010. Std of Reward: 0.020. Training.\n",
      "[INFO] ArcadeDriver. Step: 315000. Time Elapsed: 940.398 s. Mean Reward: -6.005. Std of Reward: 0.018. Training.\n",
      "[INFO] ArcadeDriver. Step: 330000. Time Elapsed: 984.366 s. Mean Reward: -6.001. Std of Reward: 0.040. Training.\n",
      "[INFO] ArcadeDriver. Step: 345000. Time Elapsed: 1030.940 s. Mean Reward: -6.000. Std of Reward: 0.063. Training.\n",
      "[INFO] ArcadeDriver. Step: 360000. Time Elapsed: 1075.883 s. Mean Reward: -6.003. Std of Reward: 0.021. Training.\n",
      "[INFO] ArcadeDriver. Step: 375000. Time Elapsed: 1125.760 s. Mean Reward: -5.475. Std of Reward: 0.499. Training.\n",
      "[INFO] ArcadeDriver. Step: 390000. Time Elapsed: 1175.767 s. Mean Reward: -5.649. Std of Reward: 0.479. Training.\n",
      "[INFO] ArcadeDriver. Step: 405000. Time Elapsed: 1220.617 s. Mean Reward: -6.006. Std of Reward: 0.016. Training.\n",
      "[INFO] ArcadeDriver. Step: 420000. Time Elapsed: 1265.217 s. Mean Reward: -6.008. Std of Reward: 0.019. Training.\n",
      "[INFO] ArcadeDriver. Step: 435000. Time Elapsed: 1309.185 s. Mean Reward: -5.906. Std of Reward: 0.302. Training.\n",
      "[INFO] ArcadeDriver. Step: 450000. Time Elapsed: 1353.301 s. Mean Reward: -5.200. Std of Reward: 0.396. Training.\n",
      "[INFO] ArcadeDriver. Step: 465000. Time Elapsed: 1397.202 s. Mean Reward: -5.121. Std of Reward: 0.324. Training.\n",
      "[INFO] ArcadeDriver. Step: 480000. Time Elapsed: 1442.095 s. Mean Reward: -6.002. Std of Reward: 0.069. Training.\n",
      "[INFO] ArcadeDriver. Step: 495000. Time Elapsed: 1486.428 s. Mean Reward: -6.010. Std of Reward: 0.029. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Kart_PPO_BC_GAIL/ArcadeDriver/ArcadeDriver-499984.onnx\n",
      "[INFO] ArcadeDriver. Step: 510000. Time Elapsed: 1530.653 s. Mean Reward: -6.007. Std of Reward: 0.063. Training.\n",
      "[INFO] ArcadeDriver. Step: 525000. Time Elapsed: 1575.904 s. Mean Reward: -6.010. Std of Reward: 0.030. Training.\n",
      "[INFO] ArcadeDriver. Step: 540000. Time Elapsed: 1619.753 s. Mean Reward: -6.008. Std of Reward: 0.076. Training.\n",
      "[INFO] ArcadeDriver. Step: 555000. Time Elapsed: 1663.753 s. Mean Reward: -6.009. Std of Reward: 0.025. Training.\n",
      "[INFO] ArcadeDriver. Step: 570000. Time Elapsed: 1707.504 s. Mean Reward: -5.841. Std of Reward: 0.375. Training.\n",
      "[INFO] ArcadeDriver. Step: 585000. Time Elapsed: 1752.138 s. Mean Reward: -4.997. Std of Reward: 0.022. Training.\n",
      "[INFO] ArcadeDriver. Step: 600000. Time Elapsed: 1800.091 s. Mean Reward: -4.997. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 615000. Time Elapsed: 1845.079 s. Mean Reward: -4.995. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 630000. Time Elapsed: 1889.329 s. Mean Reward: -4.994. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 645000. Time Elapsed: 1933.872 s. Mean Reward: -4.995. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 660000. Time Elapsed: 1981.473 s. Mean Reward: -4.994. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 675000. Time Elapsed: 2026.806 s. Mean Reward: -4.995. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 690000. Time Elapsed: 2073.820 s. Mean Reward: -4.995. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 705000. Time Elapsed: 2118.391 s. Mean Reward: -4.994. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 720000. Time Elapsed: 2163.500 s. Mean Reward: -4.994. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 735000. Time Elapsed: 2212.341 s. Mean Reward: -4.994. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 750000. Time Elapsed: 2258.638 s. Mean Reward: -4.995. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 765000. Time Elapsed: 2306.785 s. Mean Reward: -4.995. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 780000. Time Elapsed: 2352.260 s. Mean Reward: -4.995. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 795000. Time Elapsed: 2396.938 s. Mean Reward: -4.995. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 810000. Time Elapsed: 2453.035 s. Mean Reward: -4.995. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 825000. Time Elapsed: 2497.504 s. Mean Reward: -4.996. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 840000. Time Elapsed: 2544.837 s. Mean Reward: -4.995. Std of Reward: 0.011. Training.\n",
      "[INFO] ArcadeDriver. Step: 855000. Time Elapsed: 2591.062 s. Mean Reward: -4.995. Std of Reward: 0.011. Training.\n",
      "[INFO] ArcadeDriver. Step: 870000. Time Elapsed: 2635.239 s. Mean Reward: -4.996. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 885000. Time Elapsed: 2679.764 s. Mean Reward: -4.995. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 900000. Time Elapsed: 2724.589 s. Mean Reward: -4.995. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 915000. Time Elapsed: 2769.339 s. Mean Reward: -4.995. Std of Reward: 0.011. Training.\n",
      "[INFO] ArcadeDriver. Step: 930000. Time Elapsed: 2814.123 s. Mean Reward: -4.995. Std of Reward: 0.011. Training.\n",
      "[INFO] ArcadeDriver. Step: 945000. Time Elapsed: 2859.809 s. Mean Reward: -4.995. Std of Reward: 0.011. Training.\n",
      "[INFO] ArcadeDriver. Step: 960000. Time Elapsed: 2919.402 s. Mean Reward: -4.995. Std of Reward: 0.011. Training.\n",
      "[INFO] ArcadeDriver. Step: 975000. Time Elapsed: 2967.177 s. Mean Reward: -4.996. Std of Reward: 0.011. Training.\n",
      "[INFO] ArcadeDriver. Step: 990000. Time Elapsed: 3015.409 s. Mean Reward: -4.998. Std of Reward: 0.011. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Kart_PPO_BC_GAIL/ArcadeDriver/ArcadeDriver-999984.onnx\n",
      "[INFO] ArcadeDriver. Step: 1005000. Time Elapsed: 3061.292 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1020000. Time Elapsed: 3107.418 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1035000. Time Elapsed: 3152.186 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1050000. Time Elapsed: 3198.469 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1065000. Time Elapsed: 3245.855 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1080000. Time Elapsed: 3296.271 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1095000. Time Elapsed: 3342.963 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1110000. Time Elapsed: 3387.624 s. Mean Reward: -4.995. Std of Reward: 0.011. Training.\n",
      "[INFO] ArcadeDriver. Step: 1125000. Time Elapsed: 3432.363 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1140000. Time Elapsed: 3479.106 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1155000. Time Elapsed: 3525.398 s. Mean Reward: -4.997. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1170000. Time Elapsed: 3570.524 s. Mean Reward: -4.997. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1185000. Time Elapsed: 3616.243 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1200000. Time Elapsed: 3667.461 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1215000. Time Elapsed: 3717.434 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1230000. Time Elapsed: 3766.509 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1245000. Time Elapsed: 3815.617 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1260000. Time Elapsed: 3863.484 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1275000. Time Elapsed: 3909.454 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1290000. Time Elapsed: 3955.627 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1305000. Time Elapsed: 4000.961 s. Mean Reward: -4.996. Std of Reward: 0.011. Training.\n",
      "[INFO] ArcadeDriver. Step: 1320000. Time Elapsed: 4050.143 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1335000. Time Elapsed: 4097.294 s. Mean Reward: -4.997. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1350000. Time Elapsed: 4145.202 s. Mean Reward: -4.997. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1365000. Time Elapsed: 4191.729 s. Mean Reward: -4.997. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1380000. Time Elapsed: 4236.754 s. Mean Reward: -4.997. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1395000. Time Elapsed: 4281.612 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1410000. Time Elapsed: 4326.820 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1425000. Time Elapsed: 4370.787 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1440000. Time Elapsed: 4413.921 s. Mean Reward: -4.996. Std of Reward: 0.009. Training.\n",
      "[INFO] ArcadeDriver. Step: 1455000. Time Elapsed: 4458.795 s. Mean Reward: -4.995. Std of Reward: 0.009. Training.\n",
      "[INFO] ArcadeDriver. Step: 1470000. Time Elapsed: 4502.498 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1485000. Time Elapsed: 4555.700 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1500000. Time Elapsed: 4616.062 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Kart_PPO_BC_GAIL/ArcadeDriver/ArcadeDriver-1499984.onnx\n",
      "[INFO] ArcadeDriver. Step: 1515000. Time Elapsed: 4676.873 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1530000. Time Elapsed: 4720.631 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1545000. Time Elapsed: 4765.097 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1560000. Time Elapsed: 4811.589 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1575000. Time Elapsed: 4860.598 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1590000. Time Elapsed: 4917.423 s. Mean Reward: -4.996. Std of Reward: 0.009. Training.\n",
      "[INFO] ArcadeDriver. Step: 1605000. Time Elapsed: 4967.016 s. Mean Reward: -4.996. Std of Reward: 0.009. Training.\n",
      "[INFO] ArcadeDriver. Step: 1620000. Time Elapsed: 5011.082 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1635000. Time Elapsed: 5055.566 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1650000. Time Elapsed: 5099.554 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1665000. Time Elapsed: 5146.225 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1680000. Time Elapsed: 5194.743 s. Mean Reward: -4.995. Std of Reward: 0.009. Training.\n",
      "[INFO] ArcadeDriver. Step: 1695000. Time Elapsed: 5242.992 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1710000. Time Elapsed: 5290.517 s. Mean Reward: -4.995. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1725000. Time Elapsed: 5344.124 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1740000. Time Elapsed: 5393.410 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1755000. Time Elapsed: 5441.469 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1770000. Time Elapsed: 5487.778 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1785000. Time Elapsed: 5533.369 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 1800000. Time Elapsed: 5576.878 s. Mean Reward: -4.996. Std of Reward: 0.010. Training.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/bin/mlagents-learn\", line 7, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 270, in main\n",
      "    run_cli(parse_command_line())\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 266, in run_cli\n",
      "    run_training(run_seed, options, num_areas)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 142, in run_training\n",
      "    write_timing_tree(run_logs_dir)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 168, in write_timing_tree\n",
      "    json.dump(get_timer_tree(), f, indent=4)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/json/encoder.py\", line 431, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/json/encoder.py\", line 382, in _iterencode_dict\n",
      "    yield _encoder(key)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "config_ppo_fp = os.path.join(cur_dir, \"config\", \"Kart_ppo_BC_GAIL.yaml\")\n",
    "run_ppo_id = \"Kart_PPO_BC_GAIL\"\n",
    "print(config_ppo_fp)\n",
    "print(run_ppo_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_ppo_id --base-port=$baseport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47b032",
   "metadata": {},
   "source": [
    "## Training SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sac_fp = os.path.join(cur_dir, \"config\", \"Kart_sac_BC_GAIL.yaml\")\n",
    "run_sac_id = \"Kart_SAC_BC_GAIL\"\n",
    "print(config_ppo_fp)\n",
    "print(run_sac_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_sac_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c13bd",
   "metadata": {},
   "source": [
    "## Training POCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_poca_fp = os.path.join(cur_dir, \"config\", \"Kart_poca_BC_GAIL.yaml\")\n",
    "run_poca_id = \"Kart_POCA_BC_GAIL\"\n",
    "print(config_poca_fp)\n",
    "print(run_poca_id)\n",
    "\n",
    "!mlagents-learn $config_poca_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_poca_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad33878",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mlagents-learn $config_fp \\\n",
    "#                --env=$env_fp \\\n",
    "#                --results-dir=$test_dir \\\n",
    "#                --run-id=$run_id \\\n",
    "#                --resume --inference\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
