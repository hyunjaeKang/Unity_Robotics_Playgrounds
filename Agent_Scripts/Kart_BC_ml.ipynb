{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# Kart_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ba6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "output_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"mlagents_learn_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a62e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Unity6000_Envs/Kart_Darwin.app\n"
     ]
    }
   ],
   "source": [
    "# Unity Enviroment\n",
    "game = \"Kart\"\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")\n",
    "env_fp = os.path.join(env_dir, env_name)\n",
    "print(env_fp)\n",
    "\n",
    "baseport = 1999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e227b",
   "metadata": {},
   "source": [
    "## Training PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01b4cca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Kart_ppo_BC.yaml\n",
      "Kart_PPO_BC\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: ArcadeDriver?team=0\n",
      "[INFO] Hyperparameters for behavior name ArcadeDriver: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t1024\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t256\n",
      "\t  num_layers:\t5\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t5000000\n",
      "\ttime_horizon:\t64\n",
      "\tsummary_freq:\t15000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\t\n",
      "\t  demo_path:\tdemo/KartAgent.demo\n",
      "\t  steps:\t0\n",
      "\t  strength:\t0.05\n",
      "\t  samples_per_update:\t512\n",
      "\t  num_epoch:\tNone\n",
      "\t  batch_size:\tNone\n",
      "[INFO] ArcadeDriver. Step: 15000. Time Elapsed: 40.161 s. Mean Reward: -5.938. Std of Reward: 0.340. Training.\n",
      "[INFO] ArcadeDriver. Step: 30000. Time Elapsed: 81.725 s. Mean Reward: -5.964. Std of Reward: 0.182. Training.\n",
      "[INFO] ArcadeDriver. Step: 45000. Time Elapsed: 123.285 s. Mean Reward: -5.961. Std of Reward: 0.189. Training.\n",
      "[INFO] ArcadeDriver. Step: 60000. Time Elapsed: 165.384 s. Mean Reward: -5.929. Std of Reward: 0.253. Training.\n",
      "[INFO] ArcadeDriver. Step: 75000. Time Elapsed: 207.518 s. Mean Reward: -5.877. Std of Reward: 0.327. Training.\n",
      "[INFO] ArcadeDriver. Step: 90000. Time Elapsed: 250.660 s. Mean Reward: -5.925. Std of Reward: 0.261. Training.\n",
      "[INFO] ArcadeDriver. Step: 105000. Time Elapsed: 293.152 s. Mean Reward: -5.998. Std of Reward: 0.054. Training.\n",
      "[INFO] ArcadeDriver. Step: 120000. Time Elapsed: 336.410 s. Mean Reward: -5.996. Std of Reward: 0.025. Training.\n",
      "[INFO] ArcadeDriver. Step: 135000. Time Elapsed: 379.093 s. Mean Reward: -5.991. Std of Reward: 0.024. Training.\n",
      "[INFO] ArcadeDriver. Step: 150000. Time Elapsed: 422.026 s. Mean Reward: -5.991. Std of Reward: 0.021. Training.\n",
      "[INFO] ArcadeDriver. Step: 165000. Time Elapsed: 465.668 s. Mean Reward: -5.992. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 180000. Time Elapsed: 508.251 s. Mean Reward: -5.993. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 195000. Time Elapsed: 550.427 s. Mean Reward: -5.994. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 210000. Time Elapsed: 592.910 s. Mean Reward: -5.994. Std of Reward: 0.048. Training.\n",
      "[INFO] ArcadeDriver. Step: 225000. Time Elapsed: 635.219 s. Mean Reward: -5.999. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 240000. Time Elapsed: 677.810 s. Mean Reward: -6.001. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 255000. Time Elapsed: 720.519 s. Mean Reward: -6.002. Std of Reward: 0.069. Training.\n",
      "[INFO] ArcadeDriver. Step: 270000. Time Elapsed: 766.645 s. Mean Reward: -6.004. Std of Reward: 0.016. Training.\n",
      "[INFO] ArcadeDriver. Step: 285000. Time Elapsed: 813.846 s. Mean Reward: -6.003. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 300000. Time Elapsed: 859.997 s. Mean Reward: -6.002. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 315000. Time Elapsed: 902.255 s. Mean Reward: -6.005. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 330000. Time Elapsed: 944.681 s. Mean Reward: -6.004. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 345000. Time Elapsed: 986.564 s. Mean Reward: -6.004. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 360000. Time Elapsed: 1029.398 s. Mean Reward: -6.004. Std of Reward: 0.011. Training.\n",
      "[INFO] ArcadeDriver. Step: 375000. Time Elapsed: 1073.465 s. Mean Reward: -6.004. Std of Reward: 0.011. Training.\n",
      "[INFO] ArcadeDriver. Step: 390000. Time Elapsed: 1116.541 s. Mean Reward: -6.007. Std of Reward: 0.016. Training.\n",
      "[INFO] ArcadeDriver. Step: 405000. Time Elapsed: 1164.784 s. Mean Reward: -6.012. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 420000. Time Elapsed: 1213.151 s. Mean Reward: -6.012. Std of Reward: 0.016. Training.\n",
      "[INFO] ArcadeDriver. Step: 435000. Time Elapsed: 1256.709 s. Mean Reward: -6.012. Std of Reward: 0.022. Training.\n",
      "[INFO] ArcadeDriver. Step: 450000. Time Elapsed: 1299.958 s. Mean Reward: -6.007. Std of Reward: 0.084. Training.\n",
      "[INFO] ArcadeDriver. Step: 465000. Time Elapsed: 1342.501 s. Mean Reward: -5.934. Std of Reward: 0.243. Training.\n",
      "[INFO] ArcadeDriver. Step: 480000. Time Elapsed: 1385.209 s. Mean Reward: -5.978. Std of Reward: 0.044. Training.\n",
      "[INFO] ArcadeDriver. Step: 495000. Time Elapsed: 1427.926 s. Mean Reward: -5.982. Std of Reward: 0.042. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Kart_PPO_BC/ArcadeDriver/ArcadeDriver-499984.onnx\n",
      "[INFO] ArcadeDriver. Step: 510000. Time Elapsed: 1470.877 s. Mean Reward: -5.984. Std of Reward: 0.029. Training.\n",
      "[INFO] ArcadeDriver. Step: 525000. Time Elapsed: 1513.918 s. Mean Reward: -5.988. Std of Reward: 0.019. Training.\n",
      "[INFO] ArcadeDriver. Step: 540000. Time Elapsed: 1556.602 s. Mean Reward: -5.991. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 555000. Time Elapsed: 1600.377 s. Mean Reward: -5.992. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 570000. Time Elapsed: 1642.919 s. Mean Reward: -5.993. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 585000. Time Elapsed: 1685.586 s. Mean Reward: -5.992. Std of Reward: 0.050. Training.\n",
      "[INFO] ArcadeDriver. Step: 600000. Time Elapsed: 1727.786 s. Mean Reward: -5.995. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 615000. Time Elapsed: 1770.412 s. Mean Reward: -5.997. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 630000. Time Elapsed: 1814.521 s. Mean Reward: -6.000. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 645000. Time Elapsed: 1859.996 s. Mean Reward: -6.000. Std of Reward: 0.039. Training.\n",
      "[INFO] ArcadeDriver. Step: 660000. Time Elapsed: 1902.571 s. Mean Reward: -5.973. Std of Reward: 0.154. Training.\n",
      "[INFO] ArcadeDriver. Step: 675000. Time Elapsed: 1945.405 s. Mean Reward: -5.881. Std of Reward: 0.316. Training.\n",
      "[INFO] ArcadeDriver. Step: 690000. Time Elapsed: 1988.473 s. Mean Reward: -5.780. Std of Reward: 0.413. Training.\n",
      "[INFO] ArcadeDriver. Step: 705000. Time Elapsed: 2034.365 s. Mean Reward: -5.816. Std of Reward: 0.386. Training.\n",
      "[INFO] ArcadeDriver. Step: 720000. Time Elapsed: 2077.305 s. Mean Reward: -5.975. Std of Reward: 0.145. Training.\n",
      "[INFO] ArcadeDriver. Step: 735000. Time Elapsed: 2123.197 s. Mean Reward: -5.996. Std of Reward: 0.021. Training.\n",
      "[INFO] ArcadeDriver. Step: 750000. Time Elapsed: 2165.548 s. Mean Reward: -5.997. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 765000. Time Elapsed: 2209.790 s. Mean Reward: -5.994. Std of Reward: 0.083. Training.\n",
      "[INFO] ArcadeDriver. Step: 780000. Time Elapsed: 2255.515 s. Mean Reward: -6.002. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 795000. Time Elapsed: 2300.347 s. Mean Reward: -6.004. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 810000. Time Elapsed: 2345.026 s. Mean Reward: -6.001. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 825000. Time Elapsed: 2388.626 s. Mean Reward: -6.001. Std of Reward: 0.036. Training.\n",
      "[INFO] ArcadeDriver. Step: 840000. Time Elapsed: 2431.152 s. Mean Reward: -6.006. Std of Reward: 0.016. Training.\n",
      "[INFO] ArcadeDriver. Step: 855000. Time Elapsed: 2483.953 s. Mean Reward: -6.008. Std of Reward: 0.016. Training.\n",
      "[INFO] ArcadeDriver. Step: 870000. Time Elapsed: 2528.337 s. Mean Reward: -6.008. Std of Reward: 0.017. Training.\n",
      "[INFO] ArcadeDriver. Step: 885000. Time Elapsed: 2572.712 s. Mean Reward: -6.010. Std of Reward: 0.022. Training.\n",
      "[INFO] ArcadeDriver. Step: 900000. Time Elapsed: 2617.921 s. Mean Reward: -6.008. Std of Reward: 0.020. Training.\n",
      "[INFO] ArcadeDriver. Step: 915000. Time Elapsed: 2660.829 s. Mean Reward: -6.010. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 930000. Time Elapsed: 2703.479 s. Mean Reward: -6.009. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 945000. Time Elapsed: 2746.739 s. Mean Reward: -6.008. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 960000. Time Elapsed: 2789.639 s. Mean Reward: -6.010. Std of Reward: 0.017. Training.\n",
      "[INFO] ArcadeDriver. Step: 975000. Time Elapsed: 2832.639 s. Mean Reward: -6.009. Std of Reward: 0.018. Training.\n",
      "[INFO] ArcadeDriver. Step: 990000. Time Elapsed: 2875.773 s. Mean Reward: -6.010. Std of Reward: 0.016. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Kart_PPO_BC/ArcadeDriver/ArcadeDriver-999984.onnx\n",
      "[INFO] ArcadeDriver. Step: 1005000. Time Elapsed: 2928.530 s. Mean Reward: -6.009. Std of Reward: 0.022. Training.\n",
      "[INFO] ArcadeDriver. Step: 1020000. Time Elapsed: 2978.561 s. Mean Reward: -6.006. Std of Reward: 0.016. Training.\n",
      "[INFO] ArcadeDriver. Step: 1035000. Time Elapsed: 3022.657 s. Mean Reward: -6.008. Std of Reward: 0.016. Training.\n",
      "[INFO] ArcadeDriver. Step: 1050000. Time Elapsed: 3069.609 s. Mean Reward: -6.008. Std of Reward: 0.016. Training.\n",
      "[INFO] ArcadeDriver. Step: 1065000. Time Elapsed: 3113.117 s. Mean Reward: -6.007. Std of Reward: 0.016. Training.\n",
      "[INFO] ArcadeDriver. Step: 1080000. Time Elapsed: 3156.835 s. Mean Reward: -6.009. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 1095000. Time Elapsed: 3199.726 s. Mean Reward: -6.008. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 1110000. Time Elapsed: 3244.193 s. Mean Reward: -6.008. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 1125000. Time Elapsed: 3289.670 s. Mean Reward: -6.010. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 1140000. Time Elapsed: 3337.437 s. Mean Reward: -6.009. Std of Reward: 0.015. Training.\n",
      "[INFO] ArcadeDriver. Step: 1155000. Time Elapsed: 3382.354 s. Mean Reward: -6.008. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 1170000. Time Elapsed: 3425.453 s. Mean Reward: -6.011. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 1185000. Time Elapsed: 3468.463 s. Mean Reward: -6.010. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 1200000. Time Elapsed: 3512.012 s. Mean Reward: -6.009. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 1215000. Time Elapsed: 3557.997 s. Mean Reward: -6.011. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 1230000. Time Elapsed: 3601.423 s. Mean Reward: -6.010. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 1245000. Time Elapsed: 3644.197 s. Mean Reward: -6.009. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 1260000. Time Elapsed: 3688.498 s. Mean Reward: -6.011. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 1275000. Time Elapsed: 3742.458 s. Mean Reward: -6.011. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 1290000. Time Elapsed: 3787.274 s. Mean Reward: -6.009. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 1305000. Time Elapsed: 3835.866 s. Mean Reward: -6.011. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 1320000. Time Elapsed: 3881.567 s. Mean Reward: -6.011. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 1335000. Time Elapsed: 3925.967 s. Mean Reward: -6.010. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 1350000. Time Elapsed: 3971.692 s. Mean Reward: -6.009. Std of Reward: 0.076. Training.\n",
      "[INFO] ArcadeDriver. Step: 1365000. Time Elapsed: 4014.801 s. Mean Reward: -6.011. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 1380000. Time Elapsed: 4059.301 s. Mean Reward: -6.010. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 1395000. Time Elapsed: 4105.068 s. Mean Reward: -6.012. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 1410000. Time Elapsed: 4151.610 s. Mean Reward: -6.012. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 1425000. Time Elapsed: 4196.676 s. Mean Reward: -6.010. Std of Reward: 0.013. Training.\n",
      "[INFO] ArcadeDriver. Step: 1440000. Time Elapsed: 4240.977 s. Mean Reward: -6.007. Std of Reward: 0.075. Training.\n",
      "[INFO] ArcadeDriver. Step: 1455000. Time Elapsed: 4284.377 s. Mean Reward: -6.011. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 1470000. Time Elapsed: 4327.944 s. Mean Reward: -6.010. Std of Reward: 0.061. Training.\n",
      "[INFO] ArcadeDriver. Step: 1485000. Time Elapsed: 4371.741 s. Mean Reward: -6.007. Std of Reward: 0.012. Training.\n",
      "[INFO] ArcadeDriver. Step: 1500000. Time Elapsed: 4414.253 s. Mean Reward: -6.007. Std of Reward: 0.011. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Kart_PPO_BC/ArcadeDriver/ArcadeDriver-1499984.onnx\n",
      "[INFO] ArcadeDriver. Step: 1515000. Time Elapsed: 4456.595 s. Mean Reward: -6.006. Std of Reward: 0.008. Training.\n",
      "[INFO] ArcadeDriver. Step: 1530000. Time Elapsed: 4499.946 s. Mean Reward: -6.006. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1545000. Time Elapsed: 4542.654 s. Mean Reward: -6.005. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1560000. Time Elapsed: 4591.548 s. Mean Reward: -6.005. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1575000. Time Elapsed: 4650.674 s. Mean Reward: -6.005. Std of Reward: 0.004. Training.\n",
      "[INFO] ArcadeDriver. Step: 1590000. Time Elapsed: 4710.588 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1605000. Time Elapsed: 4754.998 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1620000. Time Elapsed: 4797.966 s. Mean Reward: -6.005. Std of Reward: 0.004. Training.\n",
      "[INFO] ArcadeDriver. Step: 1635000. Time Elapsed: 4841.883 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1650000. Time Elapsed: 4889.350 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1665000. Time Elapsed: 4943.516 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1680000. Time Elapsed: 4994.417 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1695000. Time Elapsed: 5037.275 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1710000. Time Elapsed: 5080.367 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1725000. Time Elapsed: 5123.484 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1740000. Time Elapsed: 5166.586 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1755000. Time Elapsed: 5211.252 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1770000. Time Elapsed: 5260.485 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1785000. Time Elapsed: 5305.802 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1800000. Time Elapsed: 5351.453 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1815000. Time Elapsed: 5402.595 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1830000. Time Elapsed: 5452.304 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1845000. Time Elapsed: 5499.821 s. Mean Reward: -6.005. Std of Reward: 0.004. Training.\n",
      "[INFO] ArcadeDriver. Step: 1860000. Time Elapsed: 5543.296 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1875000. Time Elapsed: 5586.696 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "[INFO] ArcadeDriver. Step: 1890000. Time Elapsed: 5629.263 s. Mean Reward: -6.005. Std of Reward: 0.003. Training.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/bin/mlagents-learn\", line 7, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 270, in main\n",
      "    run_cli(parse_command_line())\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 266, in run_cli\n",
      "    run_training(run_seed, options, num_areas)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 142, in run_training\n",
      "    write_timing_tree(run_logs_dir)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 168, in write_timing_tree\n",
      "    json.dump(get_timer_tree(), f, indent=4)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/json/__init__.py\", line 180, in dump\n",
      "    fp.write(chunk)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "config_ppo_fp = os.path.join(cur_dir, \"config\", \"Kart_ppo_BC.yaml\")\n",
    "run_ppo_id = \"Kart_PPO_BC\"\n",
    "print(config_ppo_fp)\n",
    "print(run_ppo_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_ppo_id --base-port=$baseport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47b032",
   "metadata": {},
   "source": [
    "## Training SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sac_fp = os.path.join(cur_dir, \"config\", \"Kart_sac_BC.yaml\")\n",
    "run_sac_id = \"Kart_SAC_BC\"\n",
    "print(config_ppo_fp)\n",
    "print(run_sac_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_sac_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c13bd",
   "metadata": {},
   "source": [
    "## Training POCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_poca_fp = os.path.join(cur_dir, \"config\", \"Kart_poca_BC.yaml\")\n",
    "run_poca_id = \"Kart_POCA_BC\"\n",
    "print(config_poca_fp)\n",
    "print(run_poca_id)\n",
    "\n",
    "!mlagents-learn $config_poca_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_poca_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad33878",
   "metadata": {},
   "source": [
    "## Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
