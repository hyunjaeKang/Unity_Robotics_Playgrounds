{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# Kart_ML-Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8ba6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "output_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"mlagents_learn_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a62e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Unity6000_Envs/Kart_Darwin.app\n"
     ]
    }
   ],
   "source": [
    "# Unity Enviroment\n",
    "game = \"Kart\"\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")\n",
    "env_fp = os.path.join(env_dir, env_name)\n",
    "print(env_fp)\n",
    "\n",
    "baseport = 1990"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e227b",
   "metadata": {},
   "source": [
    "## Training PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b4cca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Kart_ppo.yaml\n",
      "Kart_PPO\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: ArcadeDriver?team=0\n",
      "[INFO] Hyperparameters for behavior name ArcadeDriver: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t1024\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t256\n",
      "\t  num_layers:\t5\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t5000000\n",
      "\ttime_horizon:\t64\n",
      "\tsummary_freq:\t15000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] ArcadeDriver. Step: 15000. Time Elapsed: 50.033 s. Mean Reward: -5.622. Std of Reward: 0.811. Training.\n",
      "[INFO] ArcadeDriver. Step: 30000. Time Elapsed: 97.997 s. Mean Reward: -5.990. Std of Reward: 0.028. Training.\n",
      "[INFO] ArcadeDriver. Step: 45000. Time Elapsed: 144.630 s. Mean Reward: -5.981. Std of Reward: 0.032. Training.\n",
      "[INFO] ArcadeDriver. Step: 60000. Time Elapsed: 180.680 s. Mean Reward: -5.989. Std of Reward: 0.018. Training.\n",
      "[INFO] ArcadeDriver. Step: 75000. Time Elapsed: 221.098 s. Mean Reward: -5.992. Std of Reward: 0.014. Training.\n",
      "[INFO] ArcadeDriver. Step: 90000. Time Elapsed: 262.155 s. Mean Reward: -5.992. Std of Reward: 0.010. Training.\n",
      "[INFO] ArcadeDriver. Step: 105000. Time Elapsed: 302.679 s. Mean Reward: -5.992. Std of Reward: 0.008. Training.\n",
      "[INFO] ArcadeDriver. Step: 120000. Time Elapsed: 344.130 s. Mean Reward: -5.992. Std of Reward: 0.009. Training.\n",
      "[INFO] ArcadeDriver. Step: 135000. Time Elapsed: 385.963 s. Mean Reward: -5.991. Std of Reward: 0.008. Training.\n",
      "[INFO] ArcadeDriver. Step: 150000. Time Elapsed: 427.689 s. Mean Reward: -5.992. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 165000. Time Elapsed: 469.730 s. Mean Reward: -5.992. Std of Reward: 0.008. Training.\n",
      "[INFO] ArcadeDriver. Step: 180000. Time Elapsed: 511.438 s. Mean Reward: -5.992. Std of Reward: 0.008. Training.\n",
      "[INFO] ArcadeDriver. Step: 195000. Time Elapsed: 553.088 s. Mean Reward: -5.991. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 210000. Time Elapsed: 595.730 s. Mean Reward: -5.991. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 225000. Time Elapsed: 636.814 s. Mean Reward: -5.992. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 240000. Time Elapsed: 678.080 s. Mean Reward: -5.991. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 255000. Time Elapsed: 719.163 s. Mean Reward: -5.991. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 270000. Time Elapsed: 760.530 s. Mean Reward: -5.991. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 285000. Time Elapsed: 801.739 s. Mean Reward: -5.992. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 300000. Time Elapsed: 843.447 s. Mean Reward: -5.991. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 315000. Time Elapsed: 887.890 s. Mean Reward: -5.991. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 330000. Time Elapsed: 934.016 s. Mean Reward: -5.992. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 345000. Time Elapsed: 978.868 s. Mean Reward: -5.991. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 360000. Time Elapsed: 1020.383 s. Mean Reward: -5.991. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 375000. Time Elapsed: 1061.284 s. Mean Reward: -5.991. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 390000. Time Elapsed: 1102.309 s. Mean Reward: -5.991. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 405000. Time Elapsed: 1143.200 s. Mean Reward: -5.991. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 420000. Time Elapsed: 1186.536 s. Mean Reward: -5.991. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 435000. Time Elapsed: 1229.019 s. Mean Reward: -5.984. Std of Reward: 0.145. Training.\n",
      "[INFO] ArcadeDriver. Step: 450000. Time Elapsed: 1275.486 s. Mean Reward: -5.990. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 465000. Time Elapsed: 1320.396 s. Mean Reward: -5.990. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 480000. Time Elapsed: 1365.395 s. Mean Reward: -5.990. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 495000. Time Elapsed: 1407.820 s. Mean Reward: -5.991. Std of Reward: 0.006. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Kart_PPO/ArcadeDriver/ArcadeDriver-499984.onnx\n",
      "[INFO] ArcadeDriver. Step: 510000. Time Elapsed: 1449.170 s. Mean Reward: -5.990. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 525000. Time Elapsed: 1490.830 s. Mean Reward: -5.990. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 540000. Time Elapsed: 1532.247 s. Mean Reward: -5.986. Std of Reward: 0.106. Training.\n",
      "[INFO] ArcadeDriver. Step: 555000. Time Elapsed: 1573.711 s. Mean Reward: -5.991. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 570000. Time Elapsed: 1615.612 s. Mean Reward: -5.990. Std of Reward: 0.004. Training.\n",
      "[INFO] ArcadeDriver. Step: 585000. Time Elapsed: 1657.162 s. Mean Reward: -5.990. Std of Reward: 0.004. Training.\n",
      "[INFO] ArcadeDriver. Step: 600000. Time Elapsed: 1698.655 s. Mean Reward: -5.991. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 615000. Time Elapsed: 1741.346 s. Mean Reward: -5.990. Std of Reward: 0.004. Training.\n",
      "[INFO] ArcadeDriver. Step: 630000. Time Elapsed: 1782.738 s. Mean Reward: -5.990. Std of Reward: 0.004. Training.\n",
      "[INFO] ArcadeDriver. Step: 645000. Time Elapsed: 1824.222 s. Mean Reward: -5.990. Std of Reward: 0.004. Training.\n",
      "[INFO] ArcadeDriver. Step: 660000. Time Elapsed: 1865.472 s. Mean Reward: -5.809. Std of Reward: 0.380. Training.\n",
      "[INFO] ArcadeDriver. Step: 675000. Time Elapsed: 1907.248 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 690000. Time Elapsed: 1950.790 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 705000. Time Elapsed: 1994.582 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 720000. Time Elapsed: 2036.081 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 735000. Time Elapsed: 2077.681 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 750000. Time Elapsed: 2120.800 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 765000. Time Elapsed: 2164.441 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 780000. Time Elapsed: 2206.133 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 795000. Time Elapsed: 2251.117 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 810000. Time Elapsed: 2292.407 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 825000. Time Elapsed: 2335.751 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 840000. Time Elapsed: 2380.602 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 855000. Time Elapsed: 2424.140 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 870000. Time Elapsed: 2468.069 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 885000. Time Elapsed: 2510.745 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 900000. Time Elapsed: 2552.212 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 915000. Time Elapsed: 2603.521 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 930000. Time Elapsed: 2646.988 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 945000. Time Elapsed: 2689.880 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 960000. Time Elapsed: 2734.272 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 975000. Time Elapsed: 2775.756 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 990000. Time Elapsed: 2817.615 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Kart_PPO/ArcadeDriver/ArcadeDriver-999984.onnx\n",
      "[INFO] ArcadeDriver. Step: 1005000. Time Elapsed: 2859.457 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1020000. Time Elapsed: 2901.399 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1035000. Time Elapsed: 2942.933 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1050000. Time Elapsed: 2985.259 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1065000. Time Elapsed: 3027.685 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1080000. Time Elapsed: 3083.379 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1095000. Time Elapsed: 3129.176 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1110000. Time Elapsed: 3173.602 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1125000. Time Elapsed: 3217.453 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1140000. Time Elapsed: 3260.569 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1155000. Time Elapsed: 3302.753 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1170000. Time Elapsed: 3344.670 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1185000. Time Elapsed: 3389.913 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1200000. Time Elapsed: 3435.097 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1215000. Time Elapsed: 3481.155 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1230000. Time Elapsed: 3523.739 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1245000. Time Elapsed: 3565.431 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1260000. Time Elapsed: 3607.915 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1275000. Time Elapsed: 3652.223 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1290000. Time Elapsed: 3695.408 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1305000. Time Elapsed: 3737.566 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1320000. Time Elapsed: 3780.416 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1335000. Time Elapsed: 3826.221 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1350000. Time Elapsed: 3876.018 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1365000. Time Elapsed: 3920.302 s. Mean Reward: -4.997. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 1380000. Time Elapsed: 3967.285 s. Mean Reward: -4.997. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 1395000. Time Elapsed: 4012.269 s. Mean Reward: -4.997. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 1410000. Time Elapsed: 4055.644 s. Mean Reward: -4.997. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 1425000. Time Elapsed: 4100.345 s. Mean Reward: -4.997. Std of Reward: 0.007. Training.\n",
      "[INFO] ArcadeDriver. Step: 1440000. Time Elapsed: 4142.468 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1455000. Time Elapsed: 4186.362 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1470000. Time Elapsed: 4231.337 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1485000. Time Elapsed: 4276.912 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1500000. Time Elapsed: 4321.237 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Kart_PPO/ArcadeDriver/ArcadeDriver-1499984.onnx\n",
      "[INFO] ArcadeDriver. Step: 1515000. Time Elapsed: 4364.763 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1530000. Time Elapsed: 4406.980 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1545000. Time Elapsed: 4449.721 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1560000. Time Elapsed: 4492.288 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1575000. Time Elapsed: 4533.901 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1590000. Time Elapsed: 4574.805 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1605000. Time Elapsed: 4617.864 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1620000. Time Elapsed: 4659.182 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1635000. Time Elapsed: 4704.976 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1650000. Time Elapsed: 4762.067 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1665000. Time Elapsed: 4819.969 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1680000. Time Elapsed: 4867.699 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1695000. Time Elapsed: 4909.741 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1710000. Time Elapsed: 4951.191 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1725000. Time Elapsed: 4996.984 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1740000. Time Elapsed: 5042.510 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1755000. Time Elapsed: 5099.609 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1770000. Time Elapsed: 5143.985 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1785000. Time Elapsed: 5185.051 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1800000. Time Elapsed: 5227.343 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1815000. Time Elapsed: 5268.785 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1830000. Time Elapsed: 5312.546 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1845000. Time Elapsed: 5358.453 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1860000. Time Elapsed: 5403.636 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1875000. Time Elapsed: 5448.055 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1890000. Time Elapsed: 5497.807 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1905000. Time Elapsed: 5544.196 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1920000. Time Elapsed: 5591.504 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1935000. Time Elapsed: 5636.380 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "[INFO] ArcadeDriver. Step: 1950000. Time Elapsed: 5678.222 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1965000. Time Elapsed: 5720.081 s. Mean Reward: -4.997. Std of Reward: 0.006. Training.\n",
      "[INFO] ArcadeDriver. Step: 1980000. Time Elapsed: 5760.680 s. Mean Reward: -4.997. Std of Reward: 0.005. Training.\n",
      "^C\n",
      "Exception ignored in atexit callback: <bound method finalize._exitfunc of <class 'weakref.finalize'>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/weakref.py\", line 667, in _exitfunc\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/bin/mlagents-learn\", line 7, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 270, in main\n",
      "    run_cli(parse_command_line())\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 266, in run_cli\n",
      "    run_training(run_seed, options, num_areas)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 142, in run_training\n",
      "    write_timing_tree(run_logs_dir)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 167, in write_timing_tree\n",
      "    with open(timing_path, \"w\") as f:\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/codecs.py\", line 186, in __init__\n",
      "    f()\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/weakref.py\", line 591, in __call__\n",
      "    def __init__(self, errors='strict'):\n",
      "KeyboardInterrupt\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/torch/library.py\", line 479, in _del_library\n",
      "    handle.destroy()\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/torch/_library/utils.py\", line 42, in destroy\n",
      "    self._on_destroy()\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/torch/_library/fake_impl.py\", line 79, in deregister_fake_kernel\n",
      "    self.kernels.remove(kernel)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "config_ppo_fp = os.path.join(cur_dir, \"config\", \"Kart_ppo.yaml\")\n",
    "run_ppo_id = \"Kart_PPO\"\n",
    "print(config_ppo_fp)\n",
    "print(run_ppo_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_ppo_id --base-port=$baseport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_ppo_id --base-port=$baseport --resume --inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47b032",
   "metadata": {},
   "source": [
    "## Training SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sac_fp = os.path.join(cur_dir, \"config\", \"Kart_sac.yaml\")\n",
    "run_sac_id = \"Kart_SAC\"\n",
    "print(config_ppo_fp)\n",
    "print(run_sac_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_sac_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c13bd",
   "metadata": {},
   "source": [
    "## Training POCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_poca_fp = os.path.join(cur_dir, \"config\", \"Kart_poca.yaml\")\n",
    "run_poca_id = \"Kart_POCA\"\n",
    "print(config_poca_fp)\n",
    "print(run_poca_id)\n",
    "\n",
    "!mlagents-learn $config_poca_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_poca_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad33878",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mlagents-learn $config_fp \\\n",
    "#                --env=$env_fp \\\n",
    "#                --results-dir=$test_dir \\\n",
    "#                --run-id=$run_id \\\n",
    "#                --resume --inference\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
