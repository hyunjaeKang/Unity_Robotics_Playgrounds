{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# Maze RND PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d197bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import datetime\n",
    "import platform\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from mlagents_envs.environment import UnityEnvironment, ActionTuple\n",
    "from mlagents_envs.side_channel.engine_configuration_channel\\\n",
    "                             import EngineConfigurationChannel\n",
    "from mlagents_envs.side_channel.environment_parameters_channel\\\n",
    "                             import EnvironmentParametersChannel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2fb148",
   "metadata": {},
   "source": [
    "## Setting environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8093df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "test_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"pytorch_output\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d33761",
   "metadata": {},
   "source": [
    "### Pytorch Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "521fc2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Pytorch Device\n",
    "if torch.backends.mps.is_available():\n",
    "    g_device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    g_device = torch.device(\"cuda\")\n",
    "else:\n",
    "    g_device = torch.device(\"cpu\")\n",
    "\n",
    "print(g_device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485c2ea",
   "metadata": {},
   "source": [
    "### Unity Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f1e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unity Enviroment\n",
    "game = \"Maze\"\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be65174e",
   "metadata": {},
   "source": [
    "### Seting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ee7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "state_size = [3*2, 32, 32]\n",
    "action_size = 6\n",
    "action_branches = np.array(\n",
    "          [[0,0,1], [0,0,2], [0,1,0],\n",
    "           [0,1,1], [0,1,2], [1,1,0]])\n",
    "\n",
    "load_model = False\n",
    "train_mode = True\n",
    "\n",
    "discount_factor = 0.999\n",
    "learning_rate = 3e-4\n",
    "n_step = 4096\n",
    "batch_size = 512\n",
    "n_epoch = 3\n",
    "_lambda = 0.95\n",
    "epsilon = 0.2\n",
    "\n",
    "rnd_learning_rate = 1e-4\n",
    "rnd_strength = 0.1\n",
    "rnd_discount_factor = 0.99\n",
    "rnd_feature_size = 128\n",
    "\n",
    "run_step = 1000000 if train_mode else 0\n",
    "test_step = 50000\n",
    "\n",
    "print_interval = 1\n",
    "save_interval = 50\n",
    "\n",
    "\n",
    "unity_base_port = 1996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce97f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN model : Save and Load\n",
    "date_time = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "save_path = os.path.join(test_dir, f\"saved_models/{game}/RND_PPO/{date_time}\")\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "save_model_path = os.path.join(save_path, 'MAZE_RND_PPO.ckpt')\n",
    "# print(f\"save_path :{save_path}\")\n",
    "# print(f\"save_model_path :{save_model_path}\")\n",
    "load_model_path = \"\" # Need to update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aded1f",
   "metadata": {},
   "source": [
    "## Model for PPONetwork (Actor Network, Critic Network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa3fdab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for PPONetwork (Actor Network, Critic Network)\n",
    "class PPONetwork(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PPONetwork, self).__init__(**kwargs)\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=state_size[0], out_channels=16,\n",
    "                                     kernel_size=8, stride=4)\n",
    "        dim1 = ((state_size[1] - 8)//4 + 1, (state_size[2] - 8)//4 + 1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32,\n",
    "                                     kernel_size=4, stride=2)\n",
    "        dim2 = ((dim1[0] - 4)//2 + 1, (dim1[1] - 4)//2 + 1)\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.d1 = torch.nn.Linear(32*dim2[0]*dim2[1], 512)\n",
    "        self.d2 = torch.nn.Linear(512, 512)\n",
    "        self.pi = torch.nn.Linear(512, action_size)\n",
    "        self.v = torch.nn.Linear(512, 1)\n",
    "        self.v_i = torch.nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.permute(0, 3, 1, 2)\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = self.flat(x)\n",
    "        x = F.relu(self.d1(x))\n",
    "        x = F.relu(self.d2(x))\n",
    "        return F.softmax(self.pi(x), dim=-1), self.v(x)\n",
    "\n",
    "    def get_vi(self, x):\n",
    "        # x = x.permute(0, 3, 1, 2)\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = self.flat(x)\n",
    "        x = F.relu(self.d1(x))\n",
    "        x = F.relu(self.d2(x))\n",
    "        return self.v_i(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f20d7",
   "metadata": {},
   "source": [
    "## Model for RNDNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfef641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for RNDNetwork\n",
    "class RNDNetwork(torch.nn.Module):\n",
    "    def __init__(self, is_predictor, **kwargs):\n",
    "        super(RNDNetwork, self).__init__(**kwargs)\n",
    "        self.is_predictor = is_predictor\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=state_size[0], out_channels=16,\n",
    "                                     kernel_size=8, stride=4)\n",
    "        dim1 = ((state_size[1] - 8)//4 + 1, (state_size[2] - 8)//4 + 1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32,\n",
    "                                     kernel_size=4, stride=2)\n",
    "        dim2 = ((dim1[0] - 4)//2 + 1, (dim1[1] - 4)//2 + 1)\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        if is_predictor:\n",
    "            self.d1 = torch.nn.Linear(32*dim2[0]*dim2[1], 128)\n",
    "            self.d2 = torch.nn.Linear(128, 128)\n",
    "            self.feature = torch.nn.Linear(128, rnd_feature_size)\n",
    "        else:\n",
    "            self.feature = torch.nn.Linear(32*dim2[0]*dim2[1], rnd_feature_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.permute(0, 3, 1, 2)\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = self.flat(x)\n",
    "        if self.is_predictor:\n",
    "            x = F.relu(self.d1(x))\n",
    "            x = F.relu(self.d2(x))\n",
    "        return self.feature(x)\n",
    "\n",
    "\n",
    "## Modified version of https://github.com/openai/random-network-distillation\n",
    "class RunningMeanStd(torch.nn.Module):\n",
    "    def __init__(self, shape, epsilon=1e-4):\n",
    "        super(RunningMeanStd, self).__init__()\n",
    "        self.mean = torch.nn.Parameter(torch.zeros(shape), requires_grad=False)\n",
    "        self.var = torch.nn.Parameter(torch.zeros(shape), requires_grad=False)\n",
    "        self.count = torch.nn.Parameter(torch.tensor(epsilon), requires_grad=False)\n",
    "\n",
    "    def update(self, x):\n",
    "        batch_mean, batch_std, batch_count = x.mean(axis=0), x.std(axis=0), x.shape[0]\n",
    "        batch_var = torch.square(batch_std)\n",
    "        self.update_from_moments(batch_mean, batch_var, batch_count)\n",
    "\n",
    "    def update_from_moments(self, batch_mean, batch_var, batch_count):\n",
    "        delta = batch_mean - self.mean\n",
    "        tot_count = self.count + batch_count\n",
    "\n",
    "        new_mean = self.mean + delta * batch_count / tot_count\n",
    "        m_a = self.var * self.count\n",
    "        m_b = batch_var * batch_count\n",
    "        M2 = (\n",
    "            m_a\n",
    "            + m_b\n",
    "            + torch.square(delta)\n",
    "            * self.count\n",
    "            * batch_count\n",
    "            / (self.count + batch_count)\n",
    "        )\n",
    "        new_var = M2 / (self.count + batch_count)\n",
    "\n",
    "        new_count = batch_count + self.count\n",
    "\n",
    "        self.mean.data = new_mean\n",
    "        self.var.data = new_var\n",
    "        self.count.data = new_count\n",
    "\n",
    "    def normalize(self, x):\n",
    "        return torch.clip((x - self.mean) / (torch.sqrt(self.var) + 1e-7), min=-5.0, max=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41c622",
   "metadata": {},
   "source": [
    "## Agent class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af439a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNDPPOAgent:\n",
    "    def __init__(self):\n",
    "        # random network and predictor network\n",
    "        self.random_network = RNDNetwork(is_predictor=False).to(g_device)\n",
    "        self.predictor_network = RNDNetwork(is_predictor=True).to(g_device)\n",
    "        self.rnd_optimizer = torch.optim.Adam(self.predictor_network.parameters(), lr=rnd_learning_rate)\n",
    "\n",
    "        # raw_state_size = state_size[1:] + state_size[:1] # CWH -> WHC\n",
    "        raw_state_size = state_size\n",
    "        self.obs_rms = RunningMeanStd(raw_state_size).to(g_device)\n",
    "        self.ri_rms = RunningMeanStd(1).to(g_device)\n",
    "\n",
    "        self.network = PPONetwork().to(g_device)\n",
    "        self.optimizer = torch.optim.Adam(self.network.parameters(), lr=learning_rate)\n",
    "        self.memory = list()\n",
    "        self.writer = SummaryWriter(save_path)\n",
    "\n",
    "        if load_model == True:\n",
    "            print(f\"... Load Model from {load_model_path} ...\")\n",
    "            checkpoint = torch.load(load_model_path, map_location=g_device)\n",
    "            self.network.load_state_dict(checkpoint[\"network\"])\n",
    "            self.optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # get action\n",
    "    def get_action(self, state, training=True):\n",
    "        self.network.train(training)\n",
    "\n",
    "        pi, _ = self.network(torch.FloatTensor(state).to(g_device))\n",
    "        action = torch.multinomial(pi, num_samples=1).cpu().numpy()\n",
    "        return action\n",
    "\n",
    "    # Add replay memory\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    # training\n",
    "    def train_model(self):\n",
    "        self.network.train()\n",
    "        self.predictor_network.train()\n",
    "        self.random_network.train(False)\n",
    "\n",
    "        state      = np.stack([m[0] for m in self.memory], axis=0)\n",
    "        action     = np.stack([m[1] for m in self.memory], axis=0)\n",
    "        reward     = np.stack([m[2] for m in self.memory], axis=0)\n",
    "        next_state = np.stack([m[3] for m in self.memory], axis=0)\n",
    "        done       = np.stack([m[4] for m in self.memory], axis=0)\n",
    "        self.memory.clear()\n",
    "\n",
    "        state, action, reward, next_state, done = map(lambda x: torch.FloatTensor(x).to(g_device),\n",
    "                                                        [state, action, reward, next_state, done])\n",
    "\n",
    "        # update obs_rms\n",
    "        self.obs_rms.update(state)\n",
    "\n",
    "        # prob_old, adv, ret\n",
    "        with torch.no_grad():\n",
    "            # obs normalization\n",
    "            normalized_next_state = self.obs_rms.normalize(next_state)\n",
    "            target = self.random_network(normalized_next_state)\n",
    "            pred = self.predictor_network(normalized_next_state)\n",
    "            reward_i = torch.sum(torch.square(pred - target), dim = 1, keepdim=True)\n",
    "\n",
    "            # updated ri_rms\n",
    "            self.ri_rms.update(reward_i)\n",
    "\n",
    "            # ri 정규화\n",
    "            reward_i /= torch.sqrt(self.ri_rms.var) + 1e-7\n",
    "\n",
    "            pi_old, value = self.network(state)\n",
    "            prob_old = pi_old.gather(1, action.long())\n",
    "            value_i = self.network.get_vi(state)\n",
    "\n",
    "            _, next_value = self.network(next_state)\n",
    "            delta = reward + (1 - done) * discount_factor * next_value - value\n",
    "\n",
    "            next_value_i = self.network.get_vi(next_state)\n",
    "            delta_i = reward_i + rnd_discount_factor * next_value_i - value_i\n",
    "\n",
    "            adv, adv_i = delta.clone(), delta_i.clone()\n",
    "            adv, adv_i, done = map(lambda x: x.view(n_step, -1).transpose(0,1).contiguous(), [adv, adv_i, done])\n",
    "            for t in reversed(range(n_step-1)):\n",
    "                adv[:, t] += (1 - done[:, t]) * discount_factor * _lambda * adv[:, t+1]\n",
    "                adv_i[:, t] += rnd_discount_factor * _lambda * adv_i[:, t+1]\n",
    "\n",
    "            # adv\n",
    "            adv = (adv - adv.mean(dim=1, keepdim=True)) / (adv.std(dim=1, keepdim=True) + 1e-7)\n",
    "            adv_i = (adv_i - adv_i.mean(dim=1, keepdim=True)) / (adv_i.std(dim=1, keepdim=True) + 1e-7)\n",
    "\n",
    "            adv, adv_i = map(lambda x: x.transpose(0,1).contiguous().view(-1, 1), [adv, adv_i])\n",
    "\n",
    "            ret = adv + value\n",
    "            ret_i = adv_i + value_i\n",
    "\n",
    "            # adv\n",
    "            adv = adv + rnd_strength * adv_i\n",
    "\n",
    "        # trainings\n",
    "        actor_losses, critic_losses, rnd_losses = [], [], []\n",
    "        idxs = np.arange(len(reward))\n",
    "        for _ in range(n_epoch):\n",
    "            np.random.shuffle(idxs)\n",
    "            for offset in range(0, len(reward), batch_size):\n",
    "                idx = idxs[offset : offset + batch_size]\n",
    "\n",
    "                _state, _next_state, _action, _ret, _ret_i, _adv, _prob_old =\\\n",
    "                    map(lambda x: x[idx], [state, next_state, action, ret, ret_i, adv, prob_old])\n",
    "\n",
    "                pi, value = self.network(_state)\n",
    "                prob = pi.gather(1, _action.long())\n",
    "\n",
    "                # loss for policy\n",
    "                ratio = prob / (_prob_old + 1e-7)\n",
    "                surr1 = ratio * _adv\n",
    "                surr2 = torch.clamp(ratio, min=1-epsilon, max=1+epsilon) * _adv\n",
    "                actor_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "                # loss for value function\n",
    "                critic_loss_e = F.mse_loss(value, _ret).mean()\n",
    "\n",
    "                # loss for inner value function\n",
    "                value_i = self.network.get_vi(_state)\n",
    "                critic_loss_i = F.mse_loss(value_i, _ret_i).mean()\n",
    "\n",
    "                critic_loss = critic_loss_e + critic_loss_i\n",
    "\n",
    "                total_loss = actor_loss + critic_loss\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # loss function for predictor\n",
    "                _normalized_next_state = self.obs_rms.normalize(_next_state)\n",
    "                with torch.no_grad():\n",
    "                    target = self.random_network(_normalized_next_state)\n",
    "                pred = self.predictor_network(_normalized_next_state)\n",
    "                rnd_loss = torch.sum(torch.square(pred - target), dim = 1).mean()\n",
    "\n",
    "                self.rnd_optimizer.zero_grad()\n",
    "                rnd_loss.backward()\n",
    "                self.rnd_optimizer.step()\n",
    "\n",
    "                actor_losses.append(actor_loss.item())\n",
    "                critic_losses.append(critic_loss.item())\n",
    "                rnd_losses.append(rnd_loss.item())\n",
    "\n",
    "        return np.mean(actor_losses), np.mean(critic_losses), np.mean(rnd_losses)\n",
    "\n",
    "    # save model\n",
    "    def save_model(self):\n",
    "        print(f\"... Save Model to {save_model_path}...\")\n",
    "        torch.save({\n",
    "            \"network\" : self.network.state_dict(),\n",
    "            \"optimizer\" : self.optimizer.state_dict(),\n",
    "        }, save_model_path)\n",
    "\n",
    "    # logging\n",
    "    def write_summary(self, score, actor_loss, critic_loss, rnd_loss, step):\n",
    "        self.writer.add_scalar(\"Maze_RND_PPO_run/score\", score, step)\n",
    "        self.writer.add_scalar(\"Maze_RND_PPO_model/actor_loss\", actor_loss, step)\n",
    "        self.writer.add_scalar(\"Maze_RND_PPO_model/critic_loss\", critic_loss, step)\n",
    "        self.writer.add_scalar(\"Maze_RND_PPO_model/rnd_loss\", rnd_loss, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b01e40",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0558bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "1 Episode / Step: 1499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "2 Episode / Step: 2999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "3 Episode / Step: 4499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.4365 / RND loss: 0.3388\n",
      "4 Episode / Step: 5999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "5 Episode / Step: 7499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "6 Episode / Step: 8999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9158 / RND loss: 0.0170\n",
      "7 Episode / Step: 10499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "8 Episode / Step: 11999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "9 Episode / Step: 13499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9430 / RND loss: 0.0138\n",
      "10 Episode / Step: 14999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "11 Episode / Step: 16499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.2986 / RND loss: 0.0078\n",
      "12 Episode / Step: 17999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "13 Episode / Step: 19499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "14 Episode / Step: 20999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.2612 / RND loss: 0.0085\n",
      "15 Episode / Step: 22499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "16 Episode / Step: 23999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "17 Episode / Step: 25499 / Score: 0.00 / Actor loss: 0.01 / Critic loss: 1.2317 / RND loss: 0.0092\n",
      "18 Episode / Step: 26999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "19 Episode / Step: 28499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "20 Episode / Step: 29999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.3888 / RND loss: 0.0066\n",
      "21 Episode / Step: 31499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "22 Episode / Step: 32999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1485 / RND loss: 0.0053\n",
      "23 Episode / Step: 34499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "24 Episode / Step: 35999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "25 Episode / Step: 37499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.2700 / RND loss: 0.0091\n",
      "26 Episode / Step: 38999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "27 Episode / Step: 40499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "28 Episode / Step: 41999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.2229 / RND loss: 0.0068\n",
      "29 Episode / Step: 43499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "30 Episode / Step: 44999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "31 Episode / Step: 46499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.2122 / RND loss: 0.0066\n",
      "32 Episode / Step: 47999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "33 Episode / Step: 49499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.2619 / RND loss: 0.0060\n",
      "34 Episode / Step: 50999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "35 Episode / Step: 52499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "36 Episode / Step: 53999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0893 / RND loss: 0.0068\n",
      "37 Episode / Step: 55499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "38 Episode / Step: 56999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "39 Episode / Step: 58499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.2714 / RND loss: 0.0072\n",
      "40 Episode / Step: 59999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "41 Episode / Step: 61499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.1230 / RND loss: 0.0058\n",
      "42 Episode / Step: 62999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "43 Episode / Step: 64499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "44 Episode / Step: 65999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1200 / RND loss: 0.0058\n",
      "45 Episode / Step: 67499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "46 Episode / Step: 68999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "47 Episode / Step: 70499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0430 / RND loss: 0.0078\n",
      "48 Episode / Step: 71999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "49 Episode / Step: 73499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "50 Episode / Step: 74999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1934 / RND loss: 0.0075\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "51 Episode / Step: 76499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "52 Episode / Step: 77999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0839 / RND loss: 0.0106\n",
      "53 Episode / Step: 79499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "54 Episode / Step: 80999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "55 Episode / Step: 82499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.2156 / RND loss: 0.0138\n",
      "56 Episode / Step: 83999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "57 Episode / Step: 85499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "58 Episode / Step: 86999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0571 / RND loss: 0.0149\n",
      "59 Episode / Step: 88499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "60 Episode / Step: 89999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "61 Episode / Step: 91499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0329 / RND loss: 0.0221\n",
      "62 Episode / Step: 92999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "63 Episode / Step: 94499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.8450 / RND loss: 0.0301\n",
      "64 Episode / Step: 95999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "65 Episode / Step: 97499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "66 Episode / Step: 98999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0190 / RND loss: 0.0311\n",
      "67 Episode / Step: 100499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "68 Episode / Step: 101999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "69 Episode / Step: 103499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9922 / RND loss: 0.0340\n",
      "70 Episode / Step: 104999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "71 Episode / Step: 106499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1709 / RND loss: 0.0373\n",
      "72 Episode / Step: 107999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "73 Episode / Step: 109499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "74 Episode / Step: 110999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0688 / RND loss: 0.0337\n",
      "75 Episode / Step: 112499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "76 Episode / Step: 113999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "77 Episode / Step: 115499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.3121 / RND loss: 0.0341\n",
      "78 Episode / Step: 116999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "79 Episode / Step: 118499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "80 Episode / Step: 119999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0350 / RND loss: 0.0415\n",
      "81 Episode / Step: 121499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "82 Episode / Step: 122999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.2597 / RND loss: 0.0351\n",
      "83 Episode / Step: 124499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "84 Episode / Step: 125999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "85 Episode / Step: 127499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0161 / RND loss: 0.0322\n",
      "86 Episode / Step: 128999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "87 Episode / Step: 130499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "88 Episode / Step: 131999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1594 / RND loss: 0.0388\n",
      "89 Episode / Step: 133499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "90 Episode / Step: 134999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "91 Episode / Step: 136499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0283 / RND loss: 0.0266\n",
      "92 Episode / Step: 137999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "93 Episode / Step: 139499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1818 / RND loss: 0.0343\n",
      "94 Episode / Step: 140999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "95 Episode / Step: 142499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "96 Episode / Step: 143999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1955 / RND loss: 0.0382\n",
      "97 Episode / Step: 145499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "98 Episode / Step: 146999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "99 Episode / Step: 148499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1165 / RND loss: 0.0376\n",
      "100 Episode / Step: 149999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "101 Episode / Step: 151499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "102 Episode / Step: 152999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1400 / RND loss: 0.0378\n",
      "103 Episode / Step: 154499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "104 Episode / Step: 155999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0518 / RND loss: 0.0415\n",
      "105 Episode / Step: 157499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "106 Episode / Step: 158999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "107 Episode / Step: 160499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.2080 / RND loss: 0.0406\n",
      "108 Episode / Step: 161999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "109 Episode / Step: 163499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "110 Episode / Step: 164999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1060 / RND loss: 0.0419\n",
      "111 Episode / Step: 166499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "112 Episode / Step: 167999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.2128 / RND loss: 0.0386\n",
      "113 Episode / Step: 169499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "114 Episode / Step: 170999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "115 Episode / Step: 172499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0440 / RND loss: 0.0419\n",
      "116 Episode / Step: 173999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "117 Episode / Step: 175499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "118 Episode / Step: 176999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1550 / RND loss: 0.0410\n",
      "119 Episode / Step: 178499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "120 Episode / Step: 179999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "121 Episode / Step: 181499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9798 / RND loss: 0.0401\n",
      "122 Episode / Step: 182999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "123 Episode / Step: 184499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0206 / RND loss: 0.0356\n",
      "124 Episode / Step: 185999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "125 Episode / Step: 187499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "126 Episode / Step: 188999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0817 / RND loss: 0.0402\n",
      "127 Episode / Step: 190499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "128 Episode / Step: 191999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "129 Episode / Step: 193499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0220 / RND loss: 0.0414\n",
      "130 Episode / Step: 194999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "131 Episode / Step: 196499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "132 Episode / Step: 197999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0438 / RND loss: 0.0390\n",
      "133 Episode / Step: 199499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "134 Episode / Step: 200999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0149 / RND loss: 0.0380\n",
      "135 Episode / Step: 202499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "136 Episode / Step: 203999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "137 Episode / Step: 205499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0348 / RND loss: 0.0376\n",
      "138 Episode / Step: 206999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "139 Episode / Step: 208499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "140 Episode / Step: 209999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0439 / RND loss: 0.0379\n",
      "141 Episode / Step: 211499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "142 Episode / Step: 212999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0179 / RND loss: 0.0366\n",
      "143 Episode / Step: 214499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "144 Episode / Step: 215999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "145 Episode / Step: 217499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9404 / RND loss: 0.0277\n",
      "146 Episode / Step: 218999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "147 Episode / Step: 220499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "148 Episode / Step: 221999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0766 / RND loss: 0.0340\n",
      "149 Episode / Step: 223499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "150 Episode / Step: 224999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "151 Episode / Step: 226499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9104 / RND loss: 0.0375\n",
      "152 Episode / Step: 227999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "153 Episode / Step: 229499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0460 / RND loss: 0.0366\n",
      "154 Episode / Step: 230999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "155 Episode / Step: 232499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "156 Episode / Step: 233999 / Score: 0.00 / Actor loss: -0.01 / Critic loss: 1.0019 / RND loss: 0.0376\n",
      "157 Episode / Step: 235499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "158 Episode / Step: 236999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "159 Episode / Step: 238499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9890 / RND loss: 0.0405\n",
      "160 Episode / Step: 239999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "161 Episode / Step: 241499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "162 Episode / Step: 242999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9662 / RND loss: 0.0380\n",
      "163 Episode / Step: 244499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "164 Episode / Step: 245999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0696 / RND loss: 0.0395\n",
      "165 Episode / Step: 247499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "166 Episode / Step: 248999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "167 Episode / Step: 250499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0294 / RND loss: 0.0393\n",
      "168 Episode / Step: 251999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "169 Episode / Step: 253499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "170 Episode / Step: 254999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0783 / RND loss: 0.0411\n",
      "171 Episode / Step: 256499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "172 Episode / Step: 257999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "173 Episode / Step: 259499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0320 / RND loss: 0.0391\n",
      "174 Episode / Step: 260999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "175 Episode / Step: 262499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0019 / RND loss: 0.0405\n",
      "176 Episode / Step: 263999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "177 Episode / Step: 265499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "178 Episode / Step: 266999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9901 / RND loss: 0.0400\n",
      "179 Episode / Step: 268499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "180 Episode / Step: 269999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "181 Episode / Step: 271499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0854 / RND loss: 0.0422\n",
      "182 Episode / Step: 272999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "183 Episode / Step: 274499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0067 / RND loss: 0.0419\n",
      "184 Episode / Step: 275999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "185 Episode / Step: 277499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "186 Episode / Step: 278999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0024 / RND loss: 0.0402\n",
      "187 Episode / Step: 280499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "188 Episode / Step: 281999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "189 Episode / Step: 283499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9387 / RND loss: 0.0425\n",
      "190 Episode / Step: 284999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "191 Episode / Step: 286499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "192 Episode / Step: 287999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0818 / RND loss: 0.0422\n",
      "193 Episode / Step: 289499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "194 Episode / Step: 290999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9520 / RND loss: 0.0392\n",
      "195 Episode / Step: 292499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "196 Episode / Step: 293999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "197 Episode / Step: 295499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0391 / RND loss: 0.0417\n",
      "198 Episode / Step: 296999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "199 Episode / Step: 298499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "200 Episode / Step: 299999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9493 / RND loss: 0.0450\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "201 Episode / Step: 301499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "202 Episode / Step: 302999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "203 Episode / Step: 304499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0196 / RND loss: 0.0422\n",
      "204 Episode / Step: 305999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "205 Episode / Step: 307499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0250 / RND loss: 0.0459\n",
      "206 Episode / Step: 308999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "207 Episode / Step: 310499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "208 Episode / Step: 311999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0125 / RND loss: 0.0429\n",
      "209 Episode / Step: 313499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "210 Episode / Step: 314999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "211 Episode / Step: 316499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0003 / RND loss: 0.0442\n",
      "212 Episode / Step: 317999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "213 Episode / Step: 319499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9673 / RND loss: 0.0436\n",
      "214 Episode / Step: 320999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "215 Episode / Step: 322499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "216 Episode / Step: 323999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9854 / RND loss: 0.0459\n",
      "217 Episode / Step: 325499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "218 Episode / Step: 326999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "219 Episode / Step: 328499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9192 / RND loss: 0.0481\n",
      "220 Episode / Step: 329999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "221 Episode / Step: 331499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "222 Episode / Step: 332999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9449 / RND loss: 0.0453\n",
      "223 Episode / Step: 334499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "224 Episode / Step: 335999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.8818 / RND loss: 0.0442\n",
      "225 Episode / Step: 337499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "226 Episode / Step: 338999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "227 Episode / Step: 340499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9668 / RND loss: 0.0445\n",
      "228 Episode / Step: 341999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "229 Episode / Step: 343499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "230 Episode / Step: 344999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9869 / RND loss: 0.0419\n",
      "231 Episode / Step: 346499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "232 Episode / Step: 347999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "233 Episode / Step: 349499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0003 / RND loss: 0.0429\n",
      "234 Episode / Step: 350999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "235 Episode / Step: 352499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9916 / RND loss: 0.0423\n",
      "236 Episode / Step: 353999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "237 Episode / Step: 355499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "238 Episode / Step: 356999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9908 / RND loss: 0.0436\n",
      "239 Episode / Step: 358499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "240 Episode / Step: 359999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "241 Episode / Step: 361499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9825 / RND loss: 0.0420\n",
      "242 Episode / Step: 362999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "243 Episode / Step: 364499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "244 Episode / Step: 365999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0124 / RND loss: 0.0401\n",
      "245 Episode / Step: 367499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "246 Episode / Step: 368999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0608 / RND loss: 0.0416\n",
      "247 Episode / Step: 370499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "248 Episode / Step: 371999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "249 Episode / Step: 373499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.8376 / RND loss: 0.0383\n",
      "250 Episode / Step: 374999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "251 Episode / Step: 376499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "252 Episode / Step: 377999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0245 / RND loss: 0.0397\n",
      "253 Episode / Step: 379499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "254 Episode / Step: 380999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9416 / RND loss: 0.0390\n",
      "255 Episode / Step: 382499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "256 Episode / Step: 383999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "257 Episode / Step: 385499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.2146 / RND loss: 0.0391\n",
      "258 Episode / Step: 386999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "259 Episode / Step: 388499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "260 Episode / Step: 389999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9736 / RND loss: 0.0386\n",
      "261 Episode / Step: 391499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "262 Episode / Step: 392999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "263 Episode / Step: 394499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0683 / RND loss: 0.0376\n",
      "264 Episode / Step: 395999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "265 Episode / Step: 397499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9567 / RND loss: 0.0382\n",
      "266 Episode / Step: 398999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "267 Episode / Step: 400499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "268 Episode / Step: 401999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9425 / RND loss: 0.0392\n",
      "269 Episode / Step: 403499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "270 Episode / Step: 404999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "271 Episode / Step: 406499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9965 / RND loss: 0.0308\n",
      "272 Episode / Step: 407999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "273 Episode / Step: 409499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "274 Episode / Step: 410999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.7095 / RND loss: 0.0330\n",
      "275 Episode / Step: 412499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "276 Episode / Step: 413999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9428 / RND loss: 0.0288\n",
      "277 Episode / Step: 415499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "278 Episode / Step: 416999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "279 Episode / Step: 418499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9494 / RND loss: 0.0361\n",
      "280 Episode / Step: 419999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "281 Episode / Step: 421499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "282 Episode / Step: 422999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.1033 / RND loss: 0.0352\n",
      "283 Episode / Step: 424499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "284 Episode / Step: 425999 / Score: 0.00 / Actor loss: -0.01 / Critic loss: 0.9920 / RND loss: 0.0334\n",
      "285 Episode / Step: 427499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "286 Episode / Step: 428999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "287 Episode / Step: 430499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0562 / RND loss: 0.0363\n",
      "288 Episode / Step: 431999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "289 Episode / Step: 433499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "290 Episode / Step: 434999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9436 / RND loss: 0.0335\n",
      "291 Episode / Step: 436499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "292 Episode / Step: 437999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "293 Episode / Step: 439499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0265 / RND loss: 0.0359\n",
      "294 Episode / Step: 440999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "295 Episode / Step: 442499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0934 / RND loss: 0.0364\n",
      "296 Episode / Step: 443999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "297 Episode / Step: 445499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "298 Episode / Step: 446999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0022 / RND loss: 0.0359\n",
      "299 Episode / Step: 448499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "300 Episode / Step: 449999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "301 Episode / Step: 451499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1335 / RND loss: 0.0349\n",
      "302 Episode / Step: 452999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "303 Episode / Step: 454499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "304 Episode / Step: 455999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.8819 / RND loss: 0.0346\n",
      "305 Episode / Step: 457499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "306 Episode / Step: 458999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0557 / RND loss: 0.0336\n",
      "307 Episode / Step: 460499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "308 Episode / Step: 461999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "309 Episode / Step: 463499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.8991 / RND loss: 0.0330\n",
      "310 Episode / Step: 464999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "311 Episode / Step: 466499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "312 Episode / Step: 467999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9533 / RND loss: 0.0348\n",
      "313 Episode / Step: 469499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "314 Episode / Step: 470999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "315 Episode / Step: 472499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9718 / RND loss: 0.0348\n",
      "316 Episode / Step: 473999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "317 Episode / Step: 475499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0490 / RND loss: 0.0345\n",
      "318 Episode / Step: 476999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "319 Episode / Step: 478499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "320 Episode / Step: 479999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9936 / RND loss: 0.0349\n",
      "321 Episode / Step: 481499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "322 Episode / Step: 482999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "323 Episode / Step: 484499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.2213 / RND loss: 0.0339\n",
      "324 Episode / Step: 485999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "325 Episode / Step: 487499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9730 / RND loss: 0.0335\n",
      "326 Episode / Step: 488999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "327 Episode / Step: 490499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "328 Episode / Step: 491999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0401 / RND loss: 0.0326\n",
      "329 Episode / Step: 493499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "330 Episode / Step: 494999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "331 Episode / Step: 496499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0016 / RND loss: 0.0329\n",
      "332 Episode / Step: 497999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "333 Episode / Step: 499499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "334 Episode / Step: 500999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9799 / RND loss: 0.0313\n",
      "335 Episode / Step: 502499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "336 Episode / Step: 503999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9837 / RND loss: 0.0329\n",
      "337 Episode / Step: 505499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "338 Episode / Step: 506999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "339 Episode / Step: 508499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0470 / RND loss: 0.0325\n",
      "340 Episode / Step: 509999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "341 Episode / Step: 511499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "342 Episode / Step: 512999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0019 / RND loss: 0.0325\n",
      "343 Episode / Step: 514499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "344 Episode / Step: 515999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "345 Episode / Step: 517499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9266 / RND loss: 0.0318\n",
      "346 Episode / Step: 518999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "347 Episode / Step: 520499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0237 / RND loss: 0.0340\n",
      "348 Episode / Step: 521999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "349 Episode / Step: 523499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "350 Episode / Step: 524999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9468 / RND loss: 0.0339\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "351 Episode / Step: 526499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "352 Episode / Step: 527999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "353 Episode / Step: 529499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.1180 / RND loss: 0.0332\n",
      "354 Episode / Step: 530999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "355 Episode / Step: 532499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9139 / RND loss: 0.0310\n",
      "356 Episode / Step: 533999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "357 Episode / Step: 535499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "358 Episode / Step: 536999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9603 / RND loss: 0.0322\n",
      "359 Episode / Step: 538499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "360 Episode / Step: 539999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "361 Episode / Step: 541499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9365 / RND loss: 0.0316\n",
      "362 Episode / Step: 542999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "363 Episode / Step: 544499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "364 Episode / Step: 545999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1459 / RND loss: 0.0306\n",
      "365 Episode / Step: 547499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "366 Episode / Step: 548999 / Score: 0.00 / Actor loss: 0.01 / Critic loss: 1.0100 / RND loss: 0.0305\n",
      "367 Episode / Step: 550499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "368 Episode / Step: 551999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "369 Episode / Step: 553499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9653 / RND loss: 0.0299\n",
      "370 Episode / Step: 554999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "371 Episode / Step: 556499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "372 Episode / Step: 557999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9836 / RND loss: 0.0281\n",
      "373 Episode / Step: 559499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "374 Episode / Step: 560999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "375 Episode / Step: 562499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9691 / RND loss: 0.0221\n",
      "376 Episode / Step: 563999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "377 Episode / Step: 565499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9509 / RND loss: 0.0237\n",
      "378 Episode / Step: 566999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "379 Episode / Step: 568499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "380 Episode / Step: 569999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.8693 / RND loss: 0.0174\n",
      "381 Episode / Step: 571499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "382 Episode / Step: 572999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "383 Episode / Step: 574499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1335 / RND loss: 0.0154\n",
      "384 Episode / Step: 575999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "385 Episode / Step: 577499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "386 Episode / Step: 578999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0490 / RND loss: 0.0213\n",
      "387 Episode / Step: 580499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "388 Episode / Step: 581999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1120 / RND loss: 0.0258\n",
      "389 Episode / Step: 583499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "390 Episode / Step: 584999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "391 Episode / Step: 586499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0565 / RND loss: 0.0260\n",
      "392 Episode / Step: 587999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "393 Episode / Step: 589499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "394 Episode / Step: 590999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.1727 / RND loss: 0.0286\n",
      "395 Episode / Step: 592499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "396 Episode / Step: 593999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9607 / RND loss: 0.0307\n",
      "397 Episode / Step: 595499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "398 Episode / Step: 596999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "399 Episode / Step: 598499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9700 / RND loss: 0.0303\n",
      "400 Episode / Step: 599999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "401 Episode / Step: 601499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "402 Episode / Step: 602999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9062 / RND loss: 0.0301\n",
      "403 Episode / Step: 604499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "404 Episode / Step: 605999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "405 Episode / Step: 607499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9661 / RND loss: 0.0297\n",
      "406 Episode / Step: 608999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "407 Episode / Step: 610499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9927 / RND loss: 0.0284\n",
      "408 Episode / Step: 611999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "409 Episode / Step: 613499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "410 Episode / Step: 614999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0392 / RND loss: 0.0285\n",
      "411 Episode / Step: 616499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "412 Episode / Step: 617999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "413 Episode / Step: 619499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0689 / RND loss: 0.0275\n",
      "414 Episode / Step: 620999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "415 Episode / Step: 622499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "416 Episode / Step: 623999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0173 / RND loss: 0.0264\n",
      "417 Episode / Step: 625499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "418 Episode / Step: 626999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1104 / RND loss: 0.0269\n",
      "419 Episode / Step: 628499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "420 Episode / Step: 629999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "421 Episode / Step: 631499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9219 / RND loss: 0.0267\n",
      "422 Episode / Step: 632999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "423 Episode / Step: 634499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "424 Episode / Step: 635999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.1201 / RND loss: 0.0269\n",
      "425 Episode / Step: 637499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "426 Episode / Step: 638999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0634 / RND loss: 0.0263\n",
      "427 Episode / Step: 640499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "428 Episode / Step: 641999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "429 Episode / Step: 643499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0608 / RND loss: 0.0263\n",
      "430 Episode / Step: 644999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "431 Episode / Step: 646499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "432 Episode / Step: 647999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0118 / RND loss: 0.0270\n",
      "433 Episode / Step: 649499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "434 Episode / Step: 650999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "435 Episode / Step: 652499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0771 / RND loss: 0.0266\n",
      "436 Episode / Step: 653999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "437 Episode / Step: 655499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0189 / RND loss: 0.0265\n",
      "438 Episode / Step: 656999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "439 Episode / Step: 658499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "440 Episode / Step: 659999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0656 / RND loss: 0.0251\n",
      "441 Episode / Step: 661499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "442 Episode / Step: 662999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "443 Episode / Step: 664499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0988 / RND loss: 0.0250\n",
      "444 Episode / Step: 665999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "445 Episode / Step: 667499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "446 Episode / Step: 668999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0727 / RND loss: 0.0256\n",
      "447 Episode / Step: 670499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "448 Episode / Step: 671999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0680 / RND loss: 0.0259\n",
      "449 Episode / Step: 673499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "450 Episode / Step: 674999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "451 Episode / Step: 676499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0703 / RND loss: 0.0263\n",
      "452 Episode / Step: 677999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "453 Episode / Step: 679499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "454 Episode / Step: 680999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0115 / RND loss: 0.0252\n",
      "455 Episode / Step: 682499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "456 Episode / Step: 683999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "457 Episode / Step: 685499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0129 / RND loss: 0.0235\n",
      "458 Episode / Step: 686999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "459 Episode / Step: 688499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0357 / RND loss: 0.0260\n",
      "460 Episode / Step: 689999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "461 Episode / Step: 691499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "462 Episode / Step: 692999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0083 / RND loss: 0.0251\n",
      "463 Episode / Step: 694499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "464 Episode / Step: 695999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "465 Episode / Step: 697499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0101 / RND loss: 0.0261\n",
      "466 Episode / Step: 698999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "467 Episode / Step: 700499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.1230 / RND loss: 0.0265\n",
      "468 Episode / Step: 701999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "469 Episode / Step: 703499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "470 Episode / Step: 704999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0565 / RND loss: 0.0264\n",
      "471 Episode / Step: 706499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "472 Episode / Step: 707999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "473 Episode / Step: 709499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.1525 / RND loss: 0.0259\n",
      "474 Episode / Step: 710999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "475 Episode / Step: 712499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "476 Episode / Step: 713999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0638 / RND loss: 0.0251\n",
      "477 Episode / Step: 715499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "478 Episode / Step: 716999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.1700 / RND loss: 0.0254\n",
      "479 Episode / Step: 718499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "480 Episode / Step: 719999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "481 Episode / Step: 721499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0448 / RND loss: 0.0248\n",
      "482 Episode / Step: 722999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "483 Episode / Step: 724499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "484 Episode / Step: 725999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0502 / RND loss: 0.0249\n",
      "485 Episode / Step: 727499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "486 Episode / Step: 728999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "487 Episode / Step: 730499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0059 / RND loss: 0.0241\n",
      "488 Episode / Step: 731999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "489 Episode / Step: 733499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0965 / RND loss: 0.0238\n",
      "490 Episode / Step: 734999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "491 Episode / Step: 736499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "492 Episode / Step: 737999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0166 / RND loss: 0.0247\n",
      "493 Episode / Step: 739499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "494 Episode / Step: 740999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "495 Episode / Step: 742499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9975 / RND loss: 0.0228\n",
      "496 Episode / Step: 743999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "497 Episode / Step: 745499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0013 / RND loss: 0.0230\n",
      "498 Episode / Step: 746999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "499 Episode / Step: 748499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "500 Episode / Step: 749999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9910 / RND loss: 0.0217\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "501 Episode / Step: 751499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "502 Episode / Step: 752999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "503 Episode / Step: 754499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0508 / RND loss: 0.0219\n",
      "504 Episode / Step: 755999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "505 Episode / Step: 757499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "506 Episode / Step: 758999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9523 / RND loss: 0.0252\n",
      "507 Episode / Step: 760499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "508 Episode / Step: 761999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0156 / RND loss: 0.0235\n",
      "509 Episode / Step: 763499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "510 Episode / Step: 764999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "511 Episode / Step: 766499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0672 / RND loss: 0.0223\n",
      "512 Episode / Step: 767999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "513 Episode / Step: 769499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "514 Episode / Step: 770999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0477 / RND loss: 0.0225\n",
      "515 Episode / Step: 772499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "516 Episode / Step: 773999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "517 Episode / Step: 775499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0762 / RND loss: 0.0200\n",
      "518 Episode / Step: 776999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "519 Episode / Step: 778499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0856 / RND loss: 0.0245\n",
      "520 Episode / Step: 779999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "521 Episode / Step: 781499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "522 Episode / Step: 782999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9062 / RND loss: 0.0226\n",
      "523 Episode / Step: 784499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "524 Episode / Step: 785999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "525 Episode / Step: 787499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0789 / RND loss: 0.0220\n",
      "526 Episode / Step: 788999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "527 Episode / Step: 790499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "528 Episode / Step: 791999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0224 / RND loss: 0.0211\n",
      "529 Episode / Step: 793499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "530 Episode / Step: 794999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0240 / RND loss: 0.0213\n",
      "531 Episode / Step: 796499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "532 Episode / Step: 797999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "533 Episode / Step: 799499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0041 / RND loss: 0.0211\n",
      "534 Episode / Step: 800999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "535 Episode / Step: 802499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "536 Episode / Step: 803999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0148 / RND loss: 0.0207\n",
      "537 Episode / Step: 805499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "538 Episode / Step: 806999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9755 / RND loss: 0.0195\n",
      "539 Episode / Step: 808499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "540 Episode / Step: 809999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "541 Episode / Step: 811499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0065 / RND loss: 0.0182\n",
      "542 Episode / Step: 812999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "543 Episode / Step: 814499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "544 Episode / Step: 815999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0032 / RND loss: 0.0191\n",
      "545 Episode / Step: 817499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "546 Episode / Step: 818999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "547 Episode / Step: 820499 / Score: 0.00 / Actor loss: 0.01 / Critic loss: 0.9730 / RND loss: 0.0193\n",
      "548 Episode / Step: 821999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "549 Episode / Step: 823499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0129 / RND loss: 0.0193\n",
      "550 Episode / Step: 824999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "551 Episode / Step: 826499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "552 Episode / Step: 827999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.8545 / RND loss: 0.0202\n",
      "553 Episode / Step: 829499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "554 Episode / Step: 830999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "555 Episode / Step: 832499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0221 / RND loss: 0.0189\n",
      "556 Episode / Step: 833999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "557 Episode / Step: 835499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "558 Episode / Step: 836999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9253 / RND loss: 0.0186\n",
      "559 Episode / Step: 838499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "560 Episode / Step: 839999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0527 / RND loss: 0.0185\n",
      "561 Episode / Step: 841499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "562 Episode / Step: 842999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "563 Episode / Step: 844499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.8683 / RND loss: 0.0187\n",
      "564 Episode / Step: 845999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "565 Episode / Step: 847499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "566 Episode / Step: 848999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0434 / RND loss: 0.0180\n",
      "567 Episode / Step: 850499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "568 Episode / Step: 851999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9419 / RND loss: 0.0172\n",
      "569 Episode / Step: 853499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "570 Episode / Step: 854999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "571 Episode / Step: 856499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9527 / RND loss: 0.0173\n",
      "572 Episode / Step: 857999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "573 Episode / Step: 859499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "574 Episode / Step: 860999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9544 / RND loss: 0.0173\n",
      "575 Episode / Step: 862499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "576 Episode / Step: 863999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "577 Episode / Step: 865499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9792 / RND loss: 0.0167\n",
      "578 Episode / Step: 866999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "579 Episode / Step: 868499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9936 / RND loss: 0.0162\n",
      "580 Episode / Step: 869999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "581 Episode / Step: 871499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "582 Episode / Step: 872999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9897 / RND loss: 0.0164\n",
      "583 Episode / Step: 874499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "584 Episode / Step: 875999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "585 Episode / Step: 877499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9319 / RND loss: 0.0138\n",
      "586 Episode / Step: 878999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "587 Episode / Step: 880499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "588 Episode / Step: 881999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0573 / RND loss: 0.0154\n",
      "589 Episode / Step: 883499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "590 Episode / Step: 884999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9626 / RND loss: 0.0149\n",
      "591 Episode / Step: 886499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "592 Episode / Step: 887999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "593 Episode / Step: 889499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0033 / RND loss: 0.0155\n",
      "594 Episode / Step: 890999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "595 Episode / Step: 892499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "596 Episode / Step: 893999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9431 / RND loss: 0.0149\n",
      "597 Episode / Step: 895499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "598 Episode / Step: 896999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "599 Episode / Step: 898499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9716 / RND loss: 0.0149\n",
      "600 Episode / Step: 899999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "601 Episode / Step: 901499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9774 / RND loss: 0.0160\n",
      "602 Episode / Step: 902999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "603 Episode / Step: 904499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "604 Episode / Step: 905999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9578 / RND loss: 0.0151\n",
      "605 Episode / Step: 907499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "606 Episode / Step: 908999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "607 Episode / Step: 910499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0338 / RND loss: 0.0151\n",
      "608 Episode / Step: 911999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "609 Episode / Step: 913499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9693 / RND loss: 0.0152\n",
      "610 Episode / Step: 914999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "611 Episode / Step: 916499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "612 Episode / Step: 917999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9797 / RND loss: 0.0153\n",
      "613 Episode / Step: 919499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "614 Episode / Step: 920999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "615 Episode / Step: 922499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9140 / RND loss: 0.0146\n",
      "616 Episode / Step: 923999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "617 Episode / Step: 925499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "618 Episode / Step: 926999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9504 / RND loss: 0.0146\n",
      "619 Episode / Step: 928499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "620 Episode / Step: 929999 / Score: 0.00 / Actor loss: 0.01 / Critic loss: 0.9351 / RND loss: 0.0146\n",
      "621 Episode / Step: 931499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "622 Episode / Step: 932999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "623 Episode / Step: 934499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9754 / RND loss: 0.0139\n",
      "624 Episode / Step: 935999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "625 Episode / Step: 937499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "626 Episode / Step: 938999 / Score: 0.00 / Actor loss: 0.01 / Critic loss: 0.9771 / RND loss: 0.0139\n",
      "627 Episode / Step: 940499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "628 Episode / Step: 941999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "629 Episode / Step: 943499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0272 / RND loss: 0.0141\n",
      "630 Episode / Step: 944999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "631 Episode / Step: 946499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9790 / RND loss: 0.0138\n",
      "632 Episode / Step: 947999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "633 Episode / Step: 949499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "634 Episode / Step: 950999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9298 / RND loss: 0.0138\n",
      "635 Episode / Step: 952499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "636 Episode / Step: 953999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "637 Episode / Step: 955499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9442 / RND loss: 0.0137\n",
      "638 Episode / Step: 956999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "639 Episode / Step: 958499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9595 / RND loss: 0.0123\n",
      "640 Episode / Step: 959999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "641 Episode / Step: 961499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "642 Episode / Step: 962999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0195 / RND loss: 0.0132\n",
      "643 Episode / Step: 964499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "644 Episode / Step: 965999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "645 Episode / Step: 967499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9080 / RND loss: 0.0127\n",
      "646 Episode / Step: 968999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "647 Episode / Step: 970499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "648 Episode / Step: 971999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9924 / RND loss: 0.0132\n",
      "649 Episode / Step: 973499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "650 Episode / Step: 974999 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 0.9293 / RND loss: 0.0130\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "651 Episode / Step: 976499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "652 Episode / Step: 977999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "653 Episode / Step: 979499 / Score: 0.00 / Actor loss: -0.00 / Critic loss: 1.0095 / RND loss: 0.0132\n",
      "654 Episode / Step: 980999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "655 Episode / Step: 982499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "656 Episode / Step: 983999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9513 / RND loss: 0.0131\n",
      "657 Episode / Step: 985499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "658 Episode / Step: 986999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "659 Episode / Step: 988499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0407 / RND loss: 0.0126\n",
      "660 Episode / Step: 989999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "661 Episode / Step: 991499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9224 / RND loss: 0.0129\n",
      "662 Episode / Step: 992999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "663 Episode / Step: 994499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "664 Episode / Step: 995999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 1.0744 / RND loss: 0.0131\n",
      "665 Episode / Step: 997499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "666 Episode / Step: 998999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "... Save Model to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt...\n",
      "TEST START\n",
      "667 Episode / Step: 1000499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.9606 / RND loss: 0.0119\n",
      "668 Episode / Step: 1001999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "669 Episode / Step: 1003499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "670 Episode / Step: 1004999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "671 Episode / Step: 1006499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "672 Episode / Step: 1007999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "673 Episode / Step: 1009499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "674 Episode / Step: 1010999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "675 Episode / Step: 1012499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "676 Episode / Step: 1013999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "677 Episode / Step: 1015499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "678 Episode / Step: 1016999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "679 Episode / Step: 1018499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "680 Episode / Step: 1019999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "681 Episode / Step: 1021499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "682 Episode / Step: 1022999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "683 Episode / Step: 1024499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "684 Episode / Step: 1025999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "685 Episode / Step: 1027499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "686 Episode / Step: 1028999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "687 Episode / Step: 1030499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "688 Episode / Step: 1031999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "689 Episode / Step: 1033499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "690 Episode / Step: 1034999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "691 Episode / Step: 1036499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "692 Episode / Step: 1037999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "693 Episode / Step: 1039499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "694 Episode / Step: 1040999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "695 Episode / Step: 1042499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "696 Episode / Step: 1043999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "697 Episode / Step: 1045499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "698 Episode / Step: 1046999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "699 Episode / Step: 1048499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "700 Episode / Step: 1049999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "engine_configuration_channel = EngineConfigurationChannel()\n",
    "env = UnityEnvironment(file_name=env_name,\n",
    "                       side_channels=[engine_configuration_channel],\n",
    "                       base_port=unity_base_port)\n",
    "env.reset()\n",
    "\n",
    "# Setup Unity Behavior\n",
    "behavior_name = list(env.behavior_specs.keys())[0]\n",
    "spec = env.behavior_specs[behavior_name]\n",
    "engine_configuration_channel.set_configuration_parameters(time_scale=6.0)\n",
    "dec, term = env.get_steps(behavior_name)\n",
    "num_worker = len(dec)\n",
    "\n",
    "# agent\n",
    "agent = RNDPPOAgent()\n",
    "actor_losses, critic_losses, rnd_losses, scores, episode, score = [], [], [], [], 0, 0\n",
    "for step in range(run_step + test_step):\n",
    "    if step == run_step:\n",
    "        if train_mode:\n",
    "            agent.save_model()\n",
    "        print(\"TEST START\")\n",
    "        train_mode = False\n",
    "        engine_configuration_channel.set_configuration_parameters(time_scale=1.0)\n",
    "\n",
    "    state = dec.obs[0]\n",
    "    action = agent.get_action(state, train_mode)\n",
    "    branch_action = action_branches[action.squeeze()]\n",
    "\n",
    "    action_tuple = ActionTuple()\n",
    "    action_tuple.add_discrete(branch_action)\n",
    "    env.set_actions(behavior_name, action_tuple)\n",
    "    env.step()\n",
    "\n",
    "    # infor from env\n",
    "    dec, term = env.get_steps(behavior_name)\n",
    "    done = [False] * num_worker\n",
    "    next_state = dec.obs[0]\n",
    "    reward = dec.reward\n",
    "    for id in term.agent_id:\n",
    "        _id = list(term.agent_id).index(id)\n",
    "        done[id] = True\n",
    "        next_state[id] = term.obs[0][_id]\n",
    "        reward[id] = term.reward[_id]\n",
    "    score += reward[0]\n",
    "\n",
    "    if train_mode:\n",
    "        for id in range(num_worker):\n",
    "            agent.append_sample(state[id], action[id], [reward[id]], next_state[id], [done[id]])\n",
    "\n",
    "            # training\n",
    "            if len(agent.memory) / num_worker == n_step:\n",
    "                actor_loss, critic_loss, rnd_loss = agent.train_model()\n",
    "                actor_losses.append(actor_loss)\n",
    "                critic_losses.append(critic_loss)\n",
    "                rnd_losses.append(rnd_loss)\n",
    "\n",
    "    if done[0]:\n",
    "        episode +=1\n",
    "        scores.append(score)\n",
    "        score = 0\n",
    "\n",
    "        # logging\n",
    "        if episode % print_interval == 0:\n",
    "            mean_score = np.mean(scores)\n",
    "            mean_rnd_loss = np.mean(rnd_losses) if len(rnd_losses) > 0 else 0\n",
    "            mean_actor_loss = np.mean(actor_losses) if len(actor_losses) > 0 else 0\n",
    "            mean_critic_loss = np.mean(critic_losses)  if len(critic_losses) > 0 else 0\n",
    "            agent.write_summary(mean_score, mean_actor_loss, mean_critic_loss, mean_rnd_loss, step)\n",
    "            actor_losses, critic_losses, rnd_losses, scores = [], [], [], []\n",
    "\n",
    "            print(f\"{episode} Episode / Step: {step} / Score: {mean_score:.2f} / \" +\\\n",
    "                f\"Actor loss: {mean_actor_loss:.2f} / Critic loss: {mean_critic_loss:.4f} / RND loss: {mean_rnd_loss:.4f}\" )\n",
    "\n",
    "        # save model\n",
    "        if train_mode and episode % save_interval == 0:\n",
    "            agent.save_model()\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac3f52b",
   "metadata": {},
   "source": [
    "## Test the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bf21572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "... Load Model from /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/pytorch_output/saved_models/Maze/RND_PPO/20250927160658/MAZE_RND_PPO.ckpt ...\n",
      "1 Episode / Step: 1499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "2 Episode / Step: 2999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "3 Episode / Step: 4499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "4 Episode / Step: 5999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "5 Episode / Step: 7499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "6 Episode / Step: 8999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "7 Episode / Step: 10499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "8 Episode / Step: 11999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "9 Episode / Step: 13499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "10 Episode / Step: 14999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "11 Episode / Step: 16499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "12 Episode / Step: 17999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "13 Episode / Step: 19499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "14 Episode / Step: 20999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "15 Episode / Step: 22499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "16 Episode / Step: 23999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "17 Episode / Step: 25499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "18 Episode / Step: 26999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "19 Episode / Step: 28499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "20 Episode / Step: 29999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "21 Episode / Step: 31499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "22 Episode / Step: 32999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "23 Episode / Step: 34499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "24 Episode / Step: 35999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "25 Episode / Step: 37499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "26 Episode / Step: 38999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "27 Episode / Step: 40499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "28 Episode / Step: 41999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "29 Episode / Step: 43499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "30 Episode / Step: 44999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "31 Episode / Step: 46499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "32 Episode / Step: 47999 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n",
      "33 Episode / Step: 49499 / Score: 0.00 / Actor loss: 0.00 / Critic loss: 0.0000 / RND loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "load_model = True\n",
    "train_mode = False\n",
    "\n",
    "load_model_path = save_model_path\n",
    "\n",
    "engine_configuration_channel = EngineConfigurationChannel()\n",
    "env = UnityEnvironment(file_name=env_name,\n",
    "                       side_channels=[engine_configuration_channel],\n",
    "                       base_port=unity_base_port)\n",
    "env.reset()\n",
    "\n",
    "# Setup Unity Behavior\n",
    "behavior_name = list(env.behavior_specs.keys())[0]\n",
    "spec = env.behavior_specs[behavior_name]\n",
    "engine_configuration_channel.set_configuration_parameters(time_scale=1.0)\n",
    "dec, term = env.get_steps(behavior_name)\n",
    "num_worker = len(dec)\n",
    "\n",
    "# agent\n",
    "agent = RNDPPOAgent()\n",
    "actor_losses, critic_losses, rnd_losses, scores, episode, score = [], [], [], [], 0, 0\n",
    "for step in range(test_step):\n",
    "    state = dec.obs[0]\n",
    "    action = agent.get_action(state, train_mode)\n",
    "    branch_action = action_branches[action.squeeze()]\n",
    "\n",
    "    action_tuple = ActionTuple()\n",
    "    action_tuple.add_discrete(branch_action)\n",
    "    env.set_actions(behavior_name, action_tuple)\n",
    "    env.step()\n",
    "\n",
    "    # infor from env\n",
    "    dec, term = env.get_steps(behavior_name)\n",
    "    done = [False] * num_worker\n",
    "    next_state = dec.obs[0]\n",
    "    reward = dec.reward\n",
    "    for id in term.agent_id:\n",
    "        _id = list(term.agent_id).index(id)\n",
    "        done[id] = True\n",
    "        next_state[id] = term.obs[0][_id]\n",
    "        reward[id] = term.reward[_id]\n",
    "    score += reward[0]\n",
    "\n",
    "    if done[0]:\n",
    "        episode +=1\n",
    "        scores.append(score)\n",
    "        score = 0\n",
    "\n",
    "        # logging\n",
    "        if episode % print_interval == 0:\n",
    "            mean_score = np.mean(scores)\n",
    "            mean_rnd_loss = np.mean(rnd_losses) if len(rnd_losses) > 0 else 0\n",
    "            mean_actor_loss = np.mean(actor_losses) if len(actor_losses) > 0 else 0\n",
    "            mean_critic_loss = np.mean(critic_losses)  if len(critic_losses) > 0 else 0\n",
    "            agent.write_summary(mean_score, mean_actor_loss, mean_critic_loss, mean_rnd_loss, step)\n",
    "            actor_losses, critic_losses, rnd_losses, scores = [], [], [], []\n",
    "\n",
    "            print(f\"{episode} Episode / Step: {step} / Score: {mean_score:.2f} / \" +\\\n",
    "                f\"Actor loss: {mean_actor_loss:.2f} / Critic loss: {mean_critic_loss:.4f} / RND loss: {mean_rnd_loss:.4f}\" )\n",
    "\n",
    "env.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
