{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# Maze RND PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c6c95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ba6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "output_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"mlagents_learn_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a62e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Unity6000_Envs/Maze_Darwin.app\n"
     ]
    }
   ],
   "source": [
    "# Unity Enviroment\n",
    "game = \"Maze\"\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")\n",
    "env_fp = os.path.join(env_dir, env_name)\n",
    "print(env_fp)\n",
    "baseport = 1967"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e227b",
   "metadata": {},
   "source": [
    "## Training PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb8ef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Maze_ppo.yaml\n",
      "Maze_PPO\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: My Behavior?team=0\n",
      "[INFO] Hyperparameters for behavior name My Behavior: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t512\n",
      "\t  buffer_size:\t4096\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t512\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.9999\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t5000000\n",
      "\ttime_horizon:\t512\n",
      "\tsummary_freq:\t50000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] My Behavior. Step: 50000. Time Elapsed: 155.723 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 100000. Time Elapsed: 297.910 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 150000. Time Elapsed: 439.462 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 200000. Time Elapsed: 582.378 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 250000. Time Elapsed: 724.380 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 300000. Time Elapsed: 866.112 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 350000. Time Elapsed: 1008.402 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 400000. Time Elapsed: 1150.750 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 450000. Time Elapsed: 1292.169 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 500000. Time Elapsed: 1446.519 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-499500.onnx\n",
      "[INFO] My Behavior. Step: 550000. Time Elapsed: 1591.420 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 600000. Time Elapsed: 1735.436 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 650000. Time Elapsed: 1877.198 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 700000. Time Elapsed: 2020.192 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 750000. Time Elapsed: 2163.083 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 800000. Time Elapsed: 2305.014 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 850000. Time Elapsed: 2448.889 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 900000. Time Elapsed: 2593.094 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 950000. Time Elapsed: 2750.100 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1000000. Time Elapsed: 2895.619 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-999512.onnx\n",
      "[INFO] My Behavior. Step: 1050000. Time Elapsed: 3041.401 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1100000. Time Elapsed: 3185.899 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1150000. Time Elapsed: 3330.968 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1200000. Time Elapsed: 3477.954 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1250000. Time Elapsed: 3625.263 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1300000. Time Elapsed: 3771.774 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1350000. Time Elapsed: 3919.109 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1400000. Time Elapsed: 4080.280 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1450000. Time Elapsed: 4227.712 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1500000. Time Elapsed: 4374.854 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-1499524.onnx\n",
      "[INFO] My Behavior. Step: 1550000. Time Elapsed: 4522.332 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1600000. Time Elapsed: 4669.723 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1650000. Time Elapsed: 4816.855 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1700000. Time Elapsed: 4964.189 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1750000. Time Elapsed: 5111.299 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1800000. Time Elapsed: 5257.688 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1850000. Time Elapsed: 5417.444 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1900000. Time Elapsed: 5564.109 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1950000. Time Elapsed: 5710.744 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2000000. Time Elapsed: 5856.679 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-1999536.onnx\n",
      "[INFO] My Behavior. Step: 2050000. Time Elapsed: 6003.463 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2100000. Time Elapsed: 6149.694 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2150000. Time Elapsed: 6295.873 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2200000. Time Elapsed: 6437.352 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2250000. Time Elapsed: 6579.229 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2300000. Time Elapsed: 6735.043 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2350000. Time Elapsed: 6877.698 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2400000. Time Elapsed: 7021.131 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2450000. Time Elapsed: 7164.622 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2500000. Time Elapsed: 7308.571 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-2499548.onnx\n",
      "[INFO] My Behavior. Step: 2550000. Time Elapsed: 7454.497 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2600000. Time Elapsed: 7599.565 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2650000. Time Elapsed: 7744.602 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2700000. Time Elapsed: 7889.449 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2750000. Time Elapsed: 8048.374 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2800000. Time Elapsed: 8194.525 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2850000. Time Elapsed: 8340.469 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2900000. Time Elapsed: 8487.121 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2950000. Time Elapsed: 8634.064 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3000000. Time Elapsed: 8780.343 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-2999560.onnx\n",
      "[INFO] My Behavior. Step: 3050000. Time Elapsed: 8927.294 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3100000. Time Elapsed: 9074.138 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3150000. Time Elapsed: 9220.880 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3200000. Time Elapsed: 9380.503 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3250000. Time Elapsed: 9527.381 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3300000. Time Elapsed: 9674.180 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3350000. Time Elapsed: 9820.296 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3400000. Time Elapsed: 9966.888 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3450000. Time Elapsed: 10113.707 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3500000. Time Elapsed: 10259.942 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-3499572.onnx\n",
      "[INFO] My Behavior. Step: 3550000. Time Elapsed: 10406.924 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3600000. Time Elapsed: 10553.628 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3650000. Time Elapsed: 10713.383 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3700000. Time Elapsed: 10859.927 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3750000. Time Elapsed: 11006.853 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3800000. Time Elapsed: 11153.513 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3850000. Time Elapsed: 11299.742 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3900000. Time Elapsed: 11447.405 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3950000. Time Elapsed: 11593.927 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4000000. Time Elapsed: 11740.300 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-3999584.onnx\n",
      "[INFO] My Behavior. Step: 4050000. Time Elapsed: 11887.092 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4100000. Time Elapsed: 12046.317 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4150000. Time Elapsed: 12193.253 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4200000. Time Elapsed: 12340.116 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4250000. Time Elapsed: 12487.380 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4300000. Time Elapsed: 12634.227 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4350000. Time Elapsed: 12780.193 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4400000. Time Elapsed: 12926.724 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4450000. Time Elapsed: 13073.306 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4500000. Time Elapsed: 13219.410 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-4499596.onnx\n",
      "[INFO] My Behavior. Step: 4550000. Time Elapsed: 13378.796 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4600000. Time Elapsed: 13525.478 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4650000. Time Elapsed: 13672.510 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4700000. Time Elapsed: 13819.047 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4750000. Time Elapsed: 13966.393 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4800000. Time Elapsed: 14113.210 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4850000. Time Elapsed: 14261.310 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4900000. Time Elapsed: 14408.208 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4950000. Time Elapsed: 14555.435 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 5000000. Time Elapsed: 14714.883 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-4999608.onnx\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-5004216.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior/My Behavior-5004216.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_PPO/My Behavior.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_ppo_fp = os.path.join(cur_dir, \"config\", \"Maze_ppo.yaml\")\n",
    "run_ppo_id = \"Maze_PPO\"\n",
    "print(config_ppo_fp)\n",
    "print(run_ppo_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_ppo_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba56b5a",
   "metadata": {},
   "source": [
    "## Training RND PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f92a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Maze_RND_ppo.yaml\n",
      "Maze_RND_PPO\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: My Behavior?team=0\n",
      "[INFO] Hyperparameters for behavior name My Behavior: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t512\n",
      "\t  buffer_size:\t4096\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.01\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.95\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t512\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.9999\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\t  rnd:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t0.1\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\t    learning_rate:\t0.0001\n",
      "\t    encoding_size:\tNone\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t5000000\n",
      "\ttime_horizon:\t512\n",
      "\tsummary_freq:\t50000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] My Behavior. Step: 50000. Time Elapsed: 211.901 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 100000. Time Elapsed: 409.791 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 150000. Time Elapsed: 607.385 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 200000. Time Elapsed: 805.877 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 250000. Time Elapsed: 1003.787 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 300000. Time Elapsed: 1201.447 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 350000. Time Elapsed: 1400.309 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 400000. Time Elapsed: 1598.845 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 450000. Time Elapsed: 1796.441 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 500000. Time Elapsed: 2011.507 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-499500.onnx\n",
      "[INFO] My Behavior. Step: 550000. Time Elapsed: 2211.048 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 600000. Time Elapsed: 2410.038 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 650000. Time Elapsed: 2606.452 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 700000. Time Elapsed: 2804.336 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 750000. Time Elapsed: 3001.722 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 800000. Time Elapsed: 3198.571 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 850000. Time Elapsed: 3397.163 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 900000. Time Elapsed: 3587.007 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 950000. Time Elapsed: 3791.055 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1000000. Time Elapsed: 3980.376 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-999512.onnx\n",
      "[INFO] My Behavior. Step: 1050000. Time Elapsed: 4169.136 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1100000. Time Elapsed: 4356.843 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1150000. Time Elapsed: 4543.891 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1200000. Time Elapsed: 4732.902 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1250000. Time Elapsed: 4920.657 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1300000. Time Elapsed: 5107.652 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1350000. Time Elapsed: 5295.649 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1400000. Time Elapsed: 5499.346 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1450000. Time Elapsed: 5686.946 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1500000. Time Elapsed: 5874.346 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-1499524.onnx\n",
      "[INFO] My Behavior. Step: 1550000. Time Elapsed: 6062.275 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1600000. Time Elapsed: 6250.276 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1650000. Time Elapsed: 6437.487 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1700000. Time Elapsed: 6625.955 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1750000. Time Elapsed: 6813.304 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1800000. Time Elapsed: 7000.258 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1850000. Time Elapsed: 7203.576 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1900000. Time Elapsed: 7391.827 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1950000. Time Elapsed: 7579.568 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2000000. Time Elapsed: 7767.049 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-1999536.onnx\n",
      "[INFO] My Behavior. Step: 2050000. Time Elapsed: 7956.212 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2100000. Time Elapsed: 8144.645 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2150000. Time Elapsed: 8332.526 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2200000. Time Elapsed: 8521.394 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2250000. Time Elapsed: 8709.968 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2300000. Time Elapsed: 8913.344 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2350000. Time Elapsed: 9101.527 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2400000. Time Elapsed: 9290.540 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2450000. Time Elapsed: 9478.846 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2500000. Time Elapsed: 9666.565 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-2499548.onnx\n",
      "[INFO] My Behavior. Step: 2550000. Time Elapsed: 9855.915 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2600000. Time Elapsed: 10044.070 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2650000. Time Elapsed: 10231.086 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2700000. Time Elapsed: 10419.555 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2750000. Time Elapsed: 10622.756 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2800000. Time Elapsed: 10810.724 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2850000. Time Elapsed: 10998.007 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2900000. Time Elapsed: 11186.283 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2950000. Time Elapsed: 11373.961 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3000000. Time Elapsed: 11561.043 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-2999560.onnx\n",
      "[INFO] My Behavior. Step: 3050000. Time Elapsed: 11749.346 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3100000. Time Elapsed: 11937.368 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3150000. Time Elapsed: 12124.558 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3200000. Time Elapsed: 12328.592 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3250000. Time Elapsed: 12517.291 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3300000. Time Elapsed: 12705.030 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3350000. Time Elapsed: 12892.368 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3400000. Time Elapsed: 13080.930 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3450000. Time Elapsed: 13268.853 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3500000. Time Elapsed: 13456.672 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-3499572.onnx\n",
      "[INFO] My Behavior. Step: 3550000. Time Elapsed: 13645.147 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3600000. Time Elapsed: 13833.159 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3650000. Time Elapsed: 14036.585 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3700000. Time Elapsed: 14224.670 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3750000. Time Elapsed: 14412.994 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3800000. Time Elapsed: 14601.408 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3850000. Time Elapsed: 14789.979 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3900000. Time Elapsed: 14978.803 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 3950000. Time Elapsed: 15167.006 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4000000. Time Elapsed: 15354.413 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-3999584.onnx\n",
      "[INFO] My Behavior. Step: 4050000. Time Elapsed: 15542.941 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4100000. Time Elapsed: 15746.536 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4150000. Time Elapsed: 15934.217 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4200000. Time Elapsed: 16121.843 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4250000. Time Elapsed: 16310.072 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4300000. Time Elapsed: 16498.026 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4350000. Time Elapsed: 16684.881 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4400000. Time Elapsed: 16873.405 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4450000. Time Elapsed: 17061.686 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4500000. Time Elapsed: 17248.829 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-4499596.onnx\n",
      "[INFO] My Behavior. Step: 4550000. Time Elapsed: 17452.289 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4600000. Time Elapsed: 17640.906 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4650000. Time Elapsed: 17829.356 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4700000. Time Elapsed: 18017.906 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4750000. Time Elapsed: 18206.699 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4800000. Time Elapsed: 18395.060 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4850000. Time Elapsed: 18583.461 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4900000. Time Elapsed: 18772.441 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 4950000. Time Elapsed: 18960.513 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 5000000. Time Elapsed: 19163.781 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-4999608.onnx\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-5004216.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior/My Behavior-5004216.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_RND_PPO/My Behavior.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_ppo_fp = os.path.join(cur_dir, \"config\", \"Maze_RND_ppo.yaml\")\n",
    "run_ppo_id = \"Maze_RND_PPO\"\n",
    "print(config_ppo_fp)\n",
    "print(run_ppo_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_ppo_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47b032",
   "metadata": {},
   "source": [
    "## Training SAC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886efe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/Maze_sac.yaml\n",
      "Maze_SAC\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: My Behavior?team=0\n",
      "[INFO] Hyperparameters for behavior name My Behavior: \n",
      "\ttrainer_type:\tsac\n",
      "\thyperparameters:\t\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  batch_size:\t512\n",
      "\t  buffer_size:\t4096\n",
      "\t  buffer_init_steps:\t0\n",
      "\t  tau:\t0.005\n",
      "\t  steps_per_update:\t10.0\n",
      "\t  save_replay_buffer:\tFalse\n",
      "\t  init_entcoef:\t0.5\n",
      "\t  reward_signal_steps_per_update:\t10.0\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t512\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.9999\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t5000000\n",
      "\ttime_horizon:\t512\n",
      "\tsummary_freq:\t50000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/torch_entities/utils.py:289: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:4424.)\n",
      "  torch.nn.functional.one_hot(_act.T, action_size[i]).float()\n",
      "[INFO] My Behavior. Step: 50000. Time Elapsed: 3021.169 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 100000. Time Elapsed: 6020.467 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 150000. Time Elapsed: 9022.334 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 200000. Time Elapsed: 12041.804 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 250000. Time Elapsed: 15044.548 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 300000. Time Elapsed: 18056.928 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 350000. Time Elapsed: 21088.701 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 400000. Time Elapsed: 24096.609 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 450000. Time Elapsed: 27106.249 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 500000. Time Elapsed: 30402.043 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_SAC/My Behavior/My Behavior-499500.onnx\n",
      "[INFO] My Behavior. Step: 550000. Time Elapsed: 33430.285 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 600000. Time Elapsed: 36446.558 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 650000. Time Elapsed: 39468.295 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 700000. Time Elapsed: 42506.513 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 750000. Time Elapsed: 45522.111 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 800000. Time Elapsed: 48542.906 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 850000. Time Elapsed: 51583.720 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 900000. Time Elapsed: 54598.692 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 950000. Time Elapsed: 57897.432 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1000000. Time Elapsed: 60916.747 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_SAC/My Behavior/My Behavior-999512.onnx\n",
      "[INFO] My Behavior. Step: 1050000. Time Elapsed: 63955.400 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1100000. Time Elapsed: 66974.498 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1150000. Time Elapsed: 69992.521 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1200000. Time Elapsed: 73037.920 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1250000. Time Elapsed: 76057.658 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1300000. Time Elapsed: 79080.127 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1350000. Time Elapsed: 82126.156 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1400000. Time Elapsed: 85433.662 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1450000. Time Elapsed: 88462.914 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1500000. Time Elapsed: 91491.093 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_SAC/My Behavior/My Behavior-1499524.onnx\n",
      "[INFO] My Behavior. Step: 1550000. Time Elapsed: 94537.152 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1600000. Time Elapsed: 97566.351 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1650000. Time Elapsed: 100584.833 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1700000. Time Elapsed: 103632.265 s. Mean Reward: 0.000. Std of Reward: 0.000. Training.\n"
     ]
    }
   ],
   "source": [
    "config_sac_fp = os.path.join(cur_dir, \"config\", \"Maze_sac.yaml\")\n",
    "run_sac_id = \"Maze_SAC\"\n",
    "print(config_sac_fp)\n",
    "print(run_sac_id)\n",
    "\n",
    "!mlagents-learn $config_sac_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_sac_id --base-port=$baseport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee68d6",
   "metadata": {},
   "source": [
    "## Training RND SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abe8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_sac_fp = os.path.join(cur_dir, \"config\", \"Maze_RND_sac.yaml\")\n",
    "run_sac_id = \"Maze_RND_SAC\"\n",
    "print(config_sac_fp)\n",
    "print(run_sac_id)\n",
    "\n",
    "!mlagents-learn $config_sac_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_sac_id --base-port=$baseport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea4b5e",
   "metadata": {},
   "source": [
    "## Training POCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47866e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_poca_fp = os.path.join(cur_dir, \"config\", \"Maze_poca.yaml\")\n",
    "run_poca_id = \"Maze_POCA\"\n",
    "print(config_poca_fp)\n",
    "print(run_poca_id)\n",
    "\n",
    "!mlagents-learn $config_poca_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_poca_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990a406",
   "metadata": {},
   "source": [
    "## Training RND POCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_poca_fp = os.path.join(cur_dir, \"config\", \"Maze_RND_poca.yaml\")\n",
    "run_poca_id = \"Maze_RND_POCA\"\n",
    "print(config_poca_fp)\n",
    "print(run_poca_id)\n",
    "\n",
    "!mlagents-learn $config_poca_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_poca_id --base-port=$baseport"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
