{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a95c2c",
   "metadata": {},
   "source": [
    "# TwoMission Hyper ML-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c6c95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8ba6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# Global Setting\n",
    "cur_dir = os.getcwd()\n",
    "env_dir = os.path.abspath(os.path.join(cur_dir, \"..\", \"Unity6000_Envs\"))\n",
    "output_dir = os.path.abspath(os.path.join(cur_dir, \"temp\", \"mlagents_learn_output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a62e191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Unity6000_Envs/TwoMissions_Darwin.app\n"
     ]
    }
   ],
   "source": [
    "# Unity Enviroment\n",
    "game = \"TwoMissions\"\n",
    "os_name = platform.system()\n",
    "\n",
    "if os_name == 'Linux':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.x86_64\")\n",
    "elif os_name == 'Darwin':\n",
    "    env_name = os.path.join(env_dir, f\"{game}_{os_name}.app\")\n",
    "env_fp = os.path.join(env_dir, env_name)\n",
    "print(env_fp)\n",
    "baseport = 1555"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e227b",
   "metadata": {},
   "source": [
    "## Training PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fb8ef05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/TwoMission_hyper_ppo.yaml\n",
      "TwoMissions_Hyper_PPO\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: My Behavior?team=0\n",
      "[INFO] Hyperparameters for behavior name My Behavior: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t12800\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.001\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.99\n",
      "\t  num_epoch:\t3\n",
      "\t  shared_critic:\tFalse\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t2000000\n",
      "\ttime_horizon:\t1000\n",
      "\tsummary_freq:\t10000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] My Behavior. Step: 10000. Time Elapsed: 25.698 s. Mean Reward: -0.500. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 20000. Time Elapsed: 47.401 s. Mean Reward: -0.664. Std of Reward: 0.348. Training.\n",
      "[INFO] My Behavior. Step: 30000. Time Elapsed: 58.617 s. Mean Reward: -0.500. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 40000. Time Elapsed: 79.914 s. Mean Reward: -0.575. Std of Reward: 0.226. Training.\n",
      "[INFO] My Behavior. Step: 50000. Time Elapsed: 90.977 s. Mean Reward: -0.400. Std of Reward: 0.316. Training.\n",
      "[INFO] My Behavior. Step: 60000. Time Elapsed: 111.918 s. Mean Reward: -0.358. Std of Reward: 0.425. Training.\n",
      "[INFO] My Behavior. Step: 70000. Time Elapsed: 130.958 s. Mean Reward: -0.398. Std of Reward: 0.306. Training.\n",
      "[INFO] My Behavior. Step: 80000. Time Elapsed: 155.205 s. Mean Reward: -0.281. Std of Reward: 0.490. Training.\n",
      "[INFO] My Behavior. Step: 90000. Time Elapsed: 166.513 s. Mean Reward: -0.263. Std of Reward: 0.503. Training.\n",
      "[INFO] My Behavior. Step: 100000. Time Elapsed: 188.091 s. Mean Reward: -0.278. Std of Reward: 0.472. Training.\n",
      "[INFO] My Behavior. Step: 110000. Time Elapsed: 207.562 s. Mean Reward: -0.500. Std of Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 120000. Time Elapsed: 218.348 s. Mean Reward: -0.066. Std of Reward: 0.622. Training.\n",
      "[INFO] My Behavior. Step: 130000. Time Elapsed: 237.514 s. Mean Reward: 0.255. Std of Reward: 0.675. Training.\n",
      "[INFO] My Behavior. Step: 140000. Time Elapsed: 258.026 s. Mean Reward: -0.377. Std of Reward: 0.390. Training.\n",
      "[INFO] My Behavior. Step: 150000. Time Elapsed: 279.515 s. Mean Reward: -0.078. Std of Reward: 0.563. Training.\n",
      "[INFO] My Behavior. Step: 160000. Time Elapsed: 299.785 s. Mean Reward: -0.104. Std of Reward: 0.600. Training.\n",
      "[INFO] My Behavior. Step: 170000. Time Elapsed: 311.159 s. Mean Reward: 0.087. Std of Reward: 0.682. Training.\n",
      "[INFO] My Behavior. Step: 180000. Time Elapsed: 333.983 s. Mean Reward: -0.169. Std of Reward: 0.710. Training.\n",
      "[INFO] My Behavior. Step: 190000. Time Elapsed: 353.215 s. Mean Reward: -0.052. Std of Reward: 0.635. Training.\n",
      "[INFO] My Behavior. Step: 200000. Time Elapsed: 372.173 s. Mean Reward: -0.025. Std of Reward: 0.731. Training.\n",
      "[INFO] My Behavior. Step: 210000. Time Elapsed: 384.095 s. Mean Reward: -0.495. Std of Reward: 0.632. Training.\n",
      "[INFO] My Behavior. Step: 220000. Time Elapsed: 405.098 s. Mean Reward: 0.331. Std of Reward: 0.757. Training.\n",
      "[INFO] My Behavior. Step: 230000. Time Elapsed: 426.349 s. Mean Reward: 0.377. Std of Reward: 0.627. Training.\n",
      "[INFO] My Behavior. Step: 240000. Time Elapsed: 445.724 s. Mean Reward: 0.138. Std of Reward: 0.831. Training.\n",
      "[INFO] My Behavior. Step: 250000. Time Elapsed: 455.904 s. Mean Reward: -0.008. Std of Reward: 0.825. Training.\n",
      "[INFO] My Behavior. Step: 260000. Time Elapsed: 477.470 s. Mean Reward: 0.420. Std of Reward: 0.658. Training.\n",
      "[INFO] My Behavior. Step: 270000. Time Elapsed: 497.087 s. Mean Reward: 0.270. Std of Reward: 0.792. Training.\n",
      "[INFO] My Behavior. Step: 280000. Time Elapsed: 520.791 s. Mean Reward: 0.397. Std of Reward: 0.680. Training.\n",
      "[INFO] My Behavior. Step: 290000. Time Elapsed: 537.140 s. Mean Reward: 0.396. Std of Reward: 0.729. Training.\n",
      "[INFO] My Behavior. Step: 300000. Time Elapsed: 548.494 s. Mean Reward: 0.516. Std of Reward: 0.678. Training.\n",
      "[INFO] My Behavior. Step: 310000. Time Elapsed: 569.733 s. Mean Reward: 0.471. Std of Reward: 0.669. Training.\n",
      "[INFO] My Behavior. Step: 320000. Time Elapsed: 591.116 s. Mean Reward: 0.659. Std of Reward: 0.550. Training.\n",
      "[INFO] My Behavior. Step: 330000. Time Elapsed: 611.578 s. Mean Reward: 0.426. Std of Reward: 0.805. Training.\n",
      "[INFO] My Behavior. Step: 340000. Time Elapsed: 625.334 s. Mean Reward: 0.661. Std of Reward: 0.665. Training.\n",
      "[INFO] My Behavior. Step: 350000. Time Elapsed: 646.144 s. Mean Reward: 0.704. Std of Reward: 0.565. Training.\n",
      "[INFO] My Behavior. Step: 360000. Time Elapsed: 665.932 s. Mean Reward: 0.789. Std of Reward: 0.447. Training.\n",
      "[INFO] My Behavior. Step: 370000. Time Elapsed: 687.828 s. Mean Reward: 0.780. Std of Reward: 0.551. Training.\n",
      "[INFO] My Behavior. Step: 380000. Time Elapsed: 700.806 s. Mean Reward: 0.671. Std of Reward: 0.572. Training.\n",
      "[INFO] My Behavior. Step: 390000. Time Elapsed: 721.733 s. Mean Reward: 0.650. Std of Reward: 0.676. Training.\n",
      "[INFO] My Behavior. Step: 400000. Time Elapsed: 742.473 s. Mean Reward: 0.741. Std of Reward: 0.517. Training.\n",
      "[INFO] My Behavior. Step: 410000. Time Elapsed: 762.436 s. Mean Reward: 0.820. Std of Reward: 0.414. Training.\n",
      "[INFO] My Behavior. Step: 420000. Time Elapsed: 777.207 s. Mean Reward: 0.740. Std of Reward: 0.586. Training.\n",
      "[INFO] My Behavior. Step: 430000. Time Elapsed: 797.604 s. Mean Reward: 0.701. Std of Reward: 0.626. Training.\n",
      "[INFO] My Behavior. Step: 440000. Time Elapsed: 817.317 s. Mean Reward: 0.790. Std of Reward: 0.491. Training.\n",
      "[INFO] My Behavior. Step: 450000. Time Elapsed: 837.499 s. Mean Reward: 0.832. Std of Reward: 0.453. Training.\n",
      "[INFO] My Behavior. Step: 460000. Time Elapsed: 861.281 s. Mean Reward: 0.801. Std of Reward: 0.504. Training.\n",
      "[INFO] My Behavior. Step: 470000. Time Elapsed: 871.331 s. Mean Reward: 0.790. Std of Reward: 0.450. Training.\n",
      "[INFO] My Behavior. Step: 480000. Time Elapsed: 893.726 s. Mean Reward: 0.914. Std of Reward: 0.231. Training.\n",
      "[INFO] My Behavior. Step: 490000. Time Elapsed: 915.483 s. Mean Reward: 0.764. Std of Reward: 0.557. Training.\n",
      "[INFO] My Behavior. Step: 500000. Time Elapsed: 935.930 s. Mean Reward: 0.820. Std of Reward: 0.482. Training.\n",
      "/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:1176: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/TwoMissions_Hyper_PPO/My Behavior/My Behavior-499513.onnx\n",
      "[INFO] My Behavior. Step: 510000. Time Elapsed: 947.963 s. Mean Reward: 0.808. Std of Reward: 0.509. Training.\n",
      "[INFO] My Behavior. Step: 520000. Time Elapsed: 969.950 s. Mean Reward: 0.822. Std of Reward: 0.483. Training.\n",
      "[INFO] My Behavior. Step: 530000. Time Elapsed: 990.774 s. Mean Reward: 0.861. Std of Reward: 0.383. Training.\n",
      "[INFO] My Behavior. Step: 540000. Time Elapsed: 1011.259 s. Mean Reward: 0.742. Std of Reward: 0.592. Training.\n",
      "[INFO] My Behavior. Step: 550000. Time Elapsed: 1024.234 s. Mean Reward: 0.848. Std of Reward: 0.406. Training.\n",
      "[INFO] My Behavior. Step: 560000. Time Elapsed: 1045.952 s. Mean Reward: 0.785. Std of Reward: 0.561. Training.\n",
      "[INFO] My Behavior. Step: 570000. Time Elapsed: 1066.547 s. Mean Reward: 0.806. Std of Reward: 0.508. Training.\n",
      "[INFO] My Behavior. Step: 580000. Time Elapsed: 1089.702 s. Mean Reward: 0.659. Std of Reward: 0.723. Training.\n",
      "[INFO] My Behavior. Step: 590000. Time Elapsed: 1110.673 s. Mean Reward: 0.756. Std of Reward: 0.570. Training.\n",
      "[INFO] My Behavior. Step: 600000. Time Elapsed: 1122.552 s. Mean Reward: 0.864. Std of Reward: 0.421. Training.\n",
      "[INFO] My Behavior. Step: 610000. Time Elapsed: 1144.394 s. Mean Reward: 0.882. Std of Reward: 0.345. Training.\n",
      "[INFO] My Behavior. Step: 620000. Time Elapsed: 1166.523 s. Mean Reward: 0.847. Std of Reward: 0.448. Training.\n",
      "[INFO] My Behavior. Step: 630000. Time Elapsed: 1185.067 s. Mean Reward: 0.877. Std of Reward: 0.369. Training.\n",
      "[INFO] My Behavior. Step: 640000. Time Elapsed: 1197.291 s. Mean Reward: 0.920. Std of Reward: 0.253. Training.\n",
      "[INFO] My Behavior. Step: 650000. Time Elapsed: 1218.020 s. Mean Reward: 0.814. Std of Reward: 0.492. Training.\n",
      "[INFO] My Behavior. Step: 660000. Time Elapsed: 1237.011 s. Mean Reward: 0.851. Std of Reward: 0.437. Training.\n",
      "[INFO] My Behavior. Step: 670000. Time Elapsed: 1258.636 s. Mean Reward: 0.881. Std of Reward: 0.383. Training.\n",
      "[INFO] My Behavior. Step: 680000. Time Elapsed: 1279.168 s. Mean Reward: 0.890. Std of Reward: 0.378. Training.\n",
      "[INFO] My Behavior. Step: 690000. Time Elapsed: 1293.092 s. Mean Reward: 0.912. Std of Reward: 0.316. Training.\n",
      "[INFO] My Behavior. Step: 700000. Time Elapsed: 1313.111 s. Mean Reward: 0.829. Std of Reward: 0.492. Training.\n",
      "[INFO] My Behavior. Step: 710000. Time Elapsed: 1335.589 s. Mean Reward: 0.859. Std of Reward: 0.434. Training.\n",
      "[INFO] My Behavior. Step: 720000. Time Elapsed: 1355.325 s. Mean Reward: 0.832. Std of Reward: 0.508. Training.\n",
      "[INFO] My Behavior. Step: 730000. Time Elapsed: 1368.286 s. Mean Reward: 0.887. Std of Reward: 0.377. Training.\n",
      "[INFO] My Behavior. Step: 740000. Time Elapsed: 1387.635 s. Mean Reward: 0.892. Std of Reward: 0.357. Training.\n",
      "[INFO] My Behavior. Step: 750000. Time Elapsed: 1405.809 s. Mean Reward: 0.912. Std of Reward: 0.294. Training.\n",
      "[INFO] My Behavior. Step: 760000. Time Elapsed: 1424.599 s. Mean Reward: 0.867. Std of Reward: 0.429. Training.\n",
      "[INFO] My Behavior. Step: 770000. Time Elapsed: 1445.215 s. Mean Reward: 0.849. Std of Reward: 0.451. Training.\n",
      "[INFO] My Behavior. Step: 780000. Time Elapsed: 1457.493 s. Mean Reward: 0.869. Std of Reward: 0.394. Training.\n",
      "[INFO] My Behavior. Step: 790000. Time Elapsed: 1474.844 s. Mean Reward: 0.825. Std of Reward: 0.469. Training.\n",
      "[INFO] My Behavior. Step: 800000. Time Elapsed: 1494.147 s. Mean Reward: 0.858. Std of Reward: 0.424. Training.\n",
      "[INFO] My Behavior. Step: 810000. Time Elapsed: 1511.753 s. Mean Reward: 0.868. Std of Reward: 0.404. Training.\n",
      "[INFO] My Behavior. Step: 820000. Time Elapsed: 1523.887 s. Mean Reward: 0.754. Std of Reward: 0.614. Training.\n",
      "[INFO] My Behavior. Step: 830000. Time Elapsed: 1542.555 s. Mean Reward: 0.907. Std of Reward: 0.323. Training.\n",
      "[INFO] My Behavior. Step: 840000. Time Elapsed: 1562.665 s. Mean Reward: 0.912. Std of Reward: 0.304. Training.\n",
      "[INFO] My Behavior. Step: 850000. Time Elapsed: 1580.940 s. Mean Reward: 0.870. Std of Reward: 0.404. Training.\n",
      "[INFO] My Behavior. Step: 860000. Time Elapsed: 1592.523 s. Mean Reward: 0.847. Std of Reward: 0.450. Training.\n",
      "[INFO] My Behavior. Step: 870000. Time Elapsed: 1611.530 s. Mean Reward: 0.900. Std of Reward: 0.327. Training.\n",
      "[INFO] My Behavior. Step: 880000. Time Elapsed: 1629.855 s. Mean Reward: 0.883. Std of Reward: 0.392. Training.\n",
      "[INFO] My Behavior. Step: 890000. Time Elapsed: 1648.630 s. Mean Reward: 0.874. Std of Reward: 0.395. Training.\n",
      "[INFO] My Behavior. Step: 900000. Time Elapsed: 1668.127 s. Mean Reward: 0.881. Std of Reward: 0.402. Training.\n",
      "[INFO] My Behavior. Step: 910000. Time Elapsed: 1679.048 s. Mean Reward: 0.907. Std of Reward: 0.333. Training.\n",
      "[INFO] My Behavior. Step: 920000. Time Elapsed: 1698.431 s. Mean Reward: 0.906. Std of Reward: 0.323. Training.\n",
      "[INFO] My Behavior. Step: 930000. Time Elapsed: 1717.927 s. Mean Reward: 0.869. Std of Reward: 0.431. Training.\n",
      "[INFO] My Behavior. Step: 940000. Time Elapsed: 1735.557 s. Mean Reward: 0.900. Std of Reward: 0.350. Training.\n",
      "[INFO] My Behavior. Step: 950000. Time Elapsed: 1747.620 s. Mean Reward: 0.877. Std of Reward: 0.411. Training.\n",
      "[INFO] My Behavior. Step: 960000. Time Elapsed: 1766.711 s. Mean Reward: 0.907. Std of Reward: 0.351. Training.\n",
      "[INFO] My Behavior. Step: 970000. Time Elapsed: 1785.395 s. Mean Reward: 0.897. Std of Reward: 0.368. Training.\n",
      "[INFO] My Behavior. Step: 980000. Time Elapsed: 1803.922 s. Mean Reward: 0.857. Std of Reward: 0.457. Training.\n",
      "[INFO] My Behavior. Step: 990000. Time Elapsed: 1823.513 s. Mean Reward: 0.930. Std of Reward: 0.267. Training.\n",
      "[INFO] My Behavior. Step: 1000000. Time Elapsed: 1836.170 s. Mean Reward: 0.927. Std of Reward: 0.271. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/TwoMissions_Hyper_PPO/My Behavior/My Behavior-999968.onnx\n",
      "[INFO] My Behavior. Step: 1010000. Time Elapsed: 1854.448 s. Mean Reward: 0.929. Std of Reward: 0.254. Training.\n",
      "[INFO] My Behavior. Step: 1020000. Time Elapsed: 1872.405 s. Mean Reward: 0.956. Std of Reward: 0.129. Training.\n",
      "[INFO] My Behavior. Step: 1030000. Time Elapsed: 1892.512 s. Mean Reward: 0.949. Std of Reward: 0.176. Training.\n",
      "[INFO] My Behavior. Step: 1040000. Time Elapsed: 1903.777 s. Mean Reward: 0.885. Std of Reward: 0.399. Training.\n",
      "[INFO] My Behavior. Step: 1050000. Time Elapsed: 1923.807 s. Mean Reward: 0.883. Std of Reward: 0.400. Training.\n",
      "[INFO] My Behavior. Step: 1060000. Time Elapsed: 1943.478 s. Mean Reward: 0.945. Std of Reward: 0.184. Training.\n",
      "[INFO] My Behavior. Step: 1070000. Time Elapsed: 1960.835 s. Mean Reward: 0.887. Std of Reward: 0.376. Training.\n",
      "[INFO] My Behavior. Step: 1080000. Time Elapsed: 1980.795 s. Mean Reward: 0.939. Std of Reward: 0.236. Training.\n",
      "[INFO] My Behavior. Step: 1090000. Time Elapsed: 1992.661 s. Mean Reward: 0.881. Std of Reward: 0.389. Training.\n",
      "[INFO] My Behavior. Step: 1100000. Time Elapsed: 2013.994 s. Mean Reward: 0.924. Std of Reward: 0.290. Training.\n",
      "[INFO] My Behavior. Step: 1110000. Time Elapsed: 2034.182 s. Mean Reward: 0.931. Std of Reward: 0.232. Training.\n",
      "[INFO] My Behavior. Step: 1120000. Time Elapsed: 2054.405 s. Mean Reward: 0.906. Std of Reward: 0.334. Training.\n",
      "[INFO] My Behavior. Step: 1130000. Time Elapsed: 2066.779 s. Mean Reward: 0.884. Std of Reward: 0.394. Training.\n",
      "[INFO] My Behavior. Step: 1140000. Time Elapsed: 2087.976 s. Mean Reward: 0.954. Std of Reward: 0.165. Training.\n",
      "[INFO] My Behavior. Step: 1150000. Time Elapsed: 2109.336 s. Mean Reward: 0.886. Std of Reward: 0.383. Training.\n",
      "[INFO] My Behavior. Step: 1160000. Time Elapsed: 2129.375 s. Mean Reward: 0.935. Std of Reward: 0.228. Training.\n",
      "[INFO] My Behavior. Step: 1170000. Time Elapsed: 2150.366 s. Mean Reward: 0.890. Std of Reward: 0.380. Training.\n",
      "[INFO] My Behavior. Step: 1180000. Time Elapsed: 2163.480 s. Mean Reward: 0.940. Std of Reward: 0.255. Training.\n",
      "[INFO] My Behavior. Step: 1190000. Time Elapsed: 2183.404 s. Mean Reward: 0.877. Std of Reward: 0.424. Training.\n",
      "[INFO] My Behavior. Step: 1200000. Time Elapsed: 2201.667 s. Mean Reward: 0.884. Std of Reward: 0.393. Training.\n",
      "[INFO] My Behavior. Step: 1210000. Time Elapsed: 2220.587 s. Mean Reward: 0.911. Std of Reward: 0.323. Training.\n",
      "[INFO] My Behavior. Step: 1220000. Time Elapsed: 2232.205 s. Mean Reward: 0.913. Std of Reward: 0.321. Training.\n",
      "[INFO] My Behavior. Step: 1230000. Time Elapsed: 2251.875 s. Mean Reward: 0.938. Std of Reward: 0.238. Training.\n",
      "[INFO] My Behavior. Step: 1240000. Time Elapsed: 2272.175 s. Mean Reward: 0.936. Std of Reward: 0.241. Training.\n",
      "[INFO] My Behavior. Step: 1250000. Time Elapsed: 2292.459 s. Mean Reward: 0.905. Std of Reward: 0.348. Training.\n",
      "[INFO] My Behavior. Step: 1260000. Time Elapsed: 2313.428 s. Mean Reward: 0.893. Std of Reward: 0.384. Training.\n",
      "[INFO] My Behavior. Step: 1270000. Time Elapsed: 2326.290 s. Mean Reward: 0.918. Std of Reward: 0.277. Training.\n",
      "[INFO] My Behavior. Step: 1280000. Time Elapsed: 2344.778 s. Mean Reward: 0.914. Std of Reward: 0.297. Training.\n",
      "[INFO] My Behavior. Step: 1290000. Time Elapsed: 2365.152 s. Mean Reward: 0.954. Std of Reward: 0.181. Training.\n",
      "[INFO] My Behavior. Step: 1300000. Time Elapsed: 2386.200 s. Mean Reward: 0.932. Std of Reward: 0.272. Training.\n",
      "[INFO] My Behavior. Step: 1310000. Time Elapsed: 2398.733 s. Mean Reward: 0.939. Std of Reward: 0.222. Training.\n",
      "[INFO] My Behavior. Step: 1320000. Time Elapsed: 2420.650 s. Mean Reward: 0.836. Std of Reward: 0.497. Training.\n",
      "[INFO] My Behavior. Step: 1330000. Time Elapsed: 2440.986 s. Mean Reward: 0.919. Std of Reward: 0.308. Training.\n",
      "[INFO] My Behavior. Step: 1340000. Time Elapsed: 2461.849 s. Mean Reward: 0.934. Std of Reward: 0.232. Training.\n",
      "[INFO] My Behavior. Step: 1350000. Time Elapsed: 2480.228 s. Mean Reward: 0.936. Std of Reward: 0.221. Training.\n",
      "[INFO] My Behavior. Step: 1360000. Time Elapsed: 2492.161 s. Mean Reward: 0.954. Std of Reward: 0.169. Training.\n",
      "[INFO] My Behavior. Step: 1370000. Time Elapsed: 2510.198 s. Mean Reward: 0.886. Std of Reward: 0.397. Training.\n",
      "[INFO] My Behavior. Step: 1380000. Time Elapsed: 2530.065 s. Mean Reward: 0.898. Std of Reward: 0.349. Training.\n",
      "[INFO] My Behavior. Step: 1390000. Time Elapsed: 2551.249 s. Mean Reward: 0.894. Std of Reward: 0.352. Training.\n",
      "[INFO] My Behavior. Step: 1400000. Time Elapsed: 2562.384 s. Mean Reward: 0.960. Std of Reward: 0.123. Training.\n",
      "[INFO] My Behavior. Step: 1410000. Time Elapsed: 2582.402 s. Mean Reward: 0.935. Std of Reward: 0.241. Training.\n",
      "[INFO] My Behavior. Step: 1420000. Time Elapsed: 2602.284 s. Mean Reward: 0.969. Std of Reward: 0.016. Training.\n",
      "[INFO] My Behavior. Step: 1430000. Time Elapsed: 2623.824 s. Mean Reward: 0.956. Std of Reward: 0.127. Training.\n",
      "[INFO] My Behavior. Step: 1440000. Time Elapsed: 2643.322 s. Mean Reward: 0.872. Std of Reward: 0.418. Training.\n",
      "[INFO] My Behavior. Step: 1450000. Time Elapsed: 2656.847 s. Mean Reward: 0.949. Std of Reward: 0.184. Training.\n",
      "[INFO] My Behavior. Step: 1460000. Time Elapsed: 2677.718 s. Mean Reward: 0.921. Std of Reward: 0.288. Training.\n",
      "[INFO] My Behavior. Step: 1470000. Time Elapsed: 2699.506 s. Mean Reward: 0.961. Std of Reward: 0.053. Training.\n",
      "[INFO] My Behavior. Step: 1480000. Time Elapsed: 2719.632 s. Mean Reward: 0.895. Std of Reward: 0.348. Training.\n",
      "[INFO] My Behavior. Step: 1490000. Time Elapsed: 2739.863 s. Mean Reward: 0.924. Std of Reward: 0.281. Training.\n",
      "[INFO] My Behavior. Step: 1500000. Time Elapsed: 2752.893 s. Mean Reward: 0.939. Std of Reward: 0.222. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/TwoMissions_Hyper_PPO/My Behavior/My Behavior-1499601.onnx\n",
      "[INFO] My Behavior. Step: 1510000. Time Elapsed: 2772.386 s. Mean Reward: 0.941. Std of Reward: 0.211. Training.\n",
      "[INFO] My Behavior. Step: 1520000. Time Elapsed: 2791.919 s. Mean Reward: 0.937. Std of Reward: 0.241. Training.\n",
      "[INFO] My Behavior. Step: 1530000. Time Elapsed: 2810.990 s. Mean Reward: 0.903. Std of Reward: 0.333. Training.\n",
      "[INFO] My Behavior. Step: 1540000. Time Elapsed: 2823.037 s. Mean Reward: 0.903. Std of Reward: 0.341. Training.\n",
      "[INFO] My Behavior. Step: 1550000. Time Elapsed: 2842.261 s. Mean Reward: 0.953. Std of Reward: 0.200. Training.\n",
      "[INFO] My Behavior. Step: 1560000. Time Elapsed: 2862.054 s. Mean Reward: 0.945. Std of Reward: 0.205. Training.\n",
      "[INFO] My Behavior. Step: 1570000. Time Elapsed: 2882.920 s. Mean Reward: 0.939. Std of Reward: 0.234. Training.\n",
      "[INFO] My Behavior. Step: 1580000. Time Elapsed: 2894.917 s. Mean Reward: 0.938. Std of Reward: 0.240. Training.\n",
      "[INFO] My Behavior. Step: 1590000. Time Elapsed: 2915.552 s. Mean Reward: 0.922. Std of Reward: 0.292. Training.\n",
      "[INFO] My Behavior. Step: 1600000. Time Elapsed: 2935.354 s. Mean Reward: 0.948. Std of Reward: 0.179. Training.\n",
      "[INFO] My Behavior. Step: 1610000. Time Elapsed: 2955.718 s. Mean Reward: 0.904. Std of Reward: 0.353. Training.\n",
      "[INFO] My Behavior. Step: 1620000. Time Elapsed: 2975.572 s. Mean Reward: 0.895. Std of Reward: 0.358. Training.\n",
      "[INFO] My Behavior. Step: 1630000. Time Elapsed: 2988.317 s. Mean Reward: 0.929. Std of Reward: 0.273. Training.\n",
      "[INFO] My Behavior. Step: 1640000. Time Elapsed: 3009.851 s. Mean Reward: 0.943. Std of Reward: 0.228. Training.\n",
      "[INFO] My Behavior. Step: 1650000. Time Elapsed: 3029.733 s. Mean Reward: 0.951. Std of Reward: 0.137. Training.\n",
      "[INFO] My Behavior. Step: 1660000. Time Elapsed: 3050.196 s. Mean Reward: 0.961. Std of Reward: 0.120. Training.\n",
      "[INFO] My Behavior. Step: 1670000. Time Elapsed: 3062.814 s. Mean Reward: 0.851. Std of Reward: 0.467. Training.\n",
      "[INFO] My Behavior. Step: 1680000. Time Elapsed: 3081.847 s. Mean Reward: 0.931. Std of Reward: 0.276. Training.\n",
      "[INFO] My Behavior. Step: 1690000. Time Elapsed: 3100.697 s. Mean Reward: 0.955. Std of Reward: 0.164. Training.\n",
      "[INFO] My Behavior. Step: 1700000. Time Elapsed: 3121.445 s. Mean Reward: 0.924. Std of Reward: 0.263. Training.\n",
      "[INFO] My Behavior. Step: 1710000. Time Elapsed: 3140.858 s. Mean Reward: 0.940. Std of Reward: 0.232. Training.\n",
      "[INFO] My Behavior. Step: 1720000. Time Elapsed: 3153.105 s. Mean Reward: 0.923. Std of Reward: 0.298. Training.\n",
      "[INFO] My Behavior. Step: 1730000. Time Elapsed: 3173.365 s. Mean Reward: 0.968. Std of Reward: 0.017. Training.\n",
      "[INFO] My Behavior. Step: 1740000. Time Elapsed: 3193.838 s. Mean Reward: 0.921. Std of Reward: 0.299. Training.\n",
      "[INFO] My Behavior. Step: 1750000. Time Elapsed: 3213.557 s. Mean Reward: 0.940. Std of Reward: 0.234. Training.\n",
      "[INFO] My Behavior. Step: 1760000. Time Elapsed: 3226.664 s. Mean Reward: 0.946. Std of Reward: 0.223. Training.\n",
      "[INFO] My Behavior. Step: 1770000. Time Elapsed: 3247.242 s. Mean Reward: 0.969. Std of Reward: 0.020. Training.\n",
      "[INFO] My Behavior. Step: 1780000. Time Elapsed: 3268.495 s. Mean Reward: 0.929. Std of Reward: 0.277. Training.\n",
      "[INFO] My Behavior. Step: 1790000. Time Elapsed: 3288.497 s. Mean Reward: 0.953. Std of Reward: 0.168. Training.\n",
      "[INFO] My Behavior. Step: 1800000. Time Elapsed: 3308.449 s. Mean Reward: 0.936. Std of Reward: 0.242. Training.\n",
      "[INFO] My Behavior. Step: 1810000. Time Elapsed: 3320.333 s. Mean Reward: 0.953. Std of Reward: 0.169. Training.\n",
      "[INFO] My Behavior. Step: 1820000. Time Elapsed: 3342.451 s. Mean Reward: 0.922. Std of Reward: 0.310. Training.\n",
      "[INFO] My Behavior. Step: 1830000. Time Elapsed: 3362.430 s. Mean Reward: 0.921. Std of Reward: 0.306. Training.\n",
      "[INFO] My Behavior. Step: 1840000. Time Elapsed: 3381.694 s. Mean Reward: 0.945. Std of Reward: 0.214. Training.\n",
      "[INFO] My Behavior. Step: 1850000. Time Elapsed: 3393.470 s. Mean Reward: 0.940. Std of Reward: 0.243. Training.\n",
      "[INFO] My Behavior. Step: 1860000. Time Elapsed: 3413.459 s. Mean Reward: 0.915. Std of Reward: 0.323. Training.\n",
      "[INFO] My Behavior. Step: 1870000. Time Elapsed: 3433.578 s. Mean Reward: 0.944. Std of Reward: 0.226. Training.\n",
      "[INFO] My Behavior. Step: 1880000. Time Elapsed: 3454.559 s. Mean Reward: 0.933. Std of Reward: 0.271. Training.\n",
      "[INFO] My Behavior. Step: 1890000. Time Elapsed: 3467.134 s. Mean Reward: 0.937. Std of Reward: 0.223. Training.\n",
      "[INFO] My Behavior. Step: 1900000. Time Elapsed: 3486.521 s. Mean Reward: 0.924. Std of Reward: 0.309. Training.\n",
      "[INFO] My Behavior. Step: 1910000. Time Elapsed: 3506.961 s. Mean Reward: 0.949. Std of Reward: 0.174. Training.\n",
      "[INFO] My Behavior. Step: 1920000. Time Elapsed: 3527.387 s. Mean Reward: 0.933. Std of Reward: 0.270. Training.\n",
      "[INFO] My Behavior. Step: 1930000. Time Elapsed: 3546.846 s. Mean Reward: 0.942. Std of Reward: 0.231. Training.\n",
      "[INFO] My Behavior. Step: 1940000. Time Elapsed: 3559.840 s. Mean Reward: 0.947. Std of Reward: 0.213. Training.\n",
      "[INFO] My Behavior. Step: 1950000. Time Elapsed: 3579.877 s. Mean Reward: 0.967. Std of Reward: 0.035. Training.\n",
      "[INFO] My Behavior. Step: 1960000. Time Elapsed: 3600.588 s. Mean Reward: 0.942. Std of Reward: 0.229. Training.\n",
      "[INFO] My Behavior. Step: 1970000. Time Elapsed: 3620.658 s. Mean Reward: 0.959. Std of Reward: 0.154. Training.\n",
      "[INFO] My Behavior. Step: 1980000. Time Elapsed: 3633.416 s. Mean Reward: 0.945. Std of Reward: 0.226. Training.\n",
      "[INFO] My Behavior. Step: 1990000. Time Elapsed: 3654.224 s. Mean Reward: 0.939. Std of Reward: 0.235. Training.\n",
      "[INFO] My Behavior. Step: 2000000. Time Elapsed: 3673.862 s. Mean Reward: 0.931. Std of Reward: 0.276. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/TwoMissions_Hyper_PPO/My Behavior/My Behavior-1999940.onnx\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/TwoMissions_Hyper_PPO/My Behavior/My Behavior-2000005.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/TwoMissions_Hyper_PPO/My Behavior/My Behavior-2000005.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/TwoMissions_Hyper_PPO/My Behavior.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_ppo_fp = os.path.join(cur_dir, \"config\", \"TwoMission_hyper_ppo.yaml\")\n",
    "run_ppo_id = \"TwoMissions_Hyper_PPO\"\n",
    "print(config_ppo_fp)\n",
    "print(run_ppo_id)\n",
    "\n",
    "!mlagents-learn $config_ppo_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_ppo_id --base-port=$baseport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47b032",
   "metadata": {},
   "source": [
    "## Training SAC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6886efe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/TwoMission_hyper_sac.yaml\n",
      "TwoMissions_Hyper_SAC\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/bin/mlagents-learn\", line 7, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 270, in main\n",
      "    run_cli(parse_command_line())\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 56, in parse_command_line\n",
      "    return RunOptions.from_argparse(args)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/settings.py\", line 946, in from_argparse\n",
      "    final_runoptions = RunOptions.from_dict(configured_dict)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/settings.py\", line 976, in from_dict\n",
      "    return cattr.structure(options_dict, RunOptions)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/cattr/converters.py\", line 222, in structure\n",
      "    return self._structure_func.dispatch(cl)(obj, cl)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/cattr/converters.py\", line 359, in structure_attrs_fromdict\n",
      "    dispatch(type_)(val, type_) if type_ is not None else val\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/settings.py\", line 667, in dict_to_trainerdict\n",
      "    cattr.structure(d, Dict[str, TrainerSettings])\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/cattr/converters.py\", line 222, in structure\n",
      "    return self._structure_func.dispatch(cl)(obj, cl)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/cattr/converters.py\", line 410, in _structure_dict\n",
      "    return {\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/cattr/converters.py\", line 411, in <dictcomp>\n",
      "    key_conv(k, key_type): val_conv(v, val_type)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/settings.py\", line 707, in structure\n",
      "    d_copy[key] = strict_to_cls(\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/settings.py\", line 67, in strict_to_cls\n",
      "    d_copy[key] = check_and_structure(key, val, t)\n",
      "  File \"/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/mlagents/trainers/settings.py\", line 41, in check_and_structure\n",
      "    raise TrainerConfigError(\n",
      "mlagents.trainers.exception.TrainerConfigError: The option buffer_init_steps was specified in your YAML file for PPOSettings, but is invalid.\n"
     ]
    }
   ],
   "source": [
    "config_sac_fp = os.path.join(cur_dir, \"config\", \"TwoMission_hyper_sac.yaml\")\n",
    "run_sac_id = \"TwoMissions_Hyper_SAC\"\n",
    "print(config_sac_fp)\n",
    "print(run_sac_id)\n",
    "\n",
    "!mlagents-learn $config_sac_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_sac_id --base-port=$baseport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea4b5e",
   "metadata": {},
   "source": [
    "## Training POCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47866e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/config/TwoMission_hyper_poca.yaml\n",
      "Maze_TwoMissions_Hyper_POCA\n",
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 1.1.0,\n",
      "  ml-agents-envs: 1.1.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 2.8.0\n",
      "[INFO] Connected to Unity environment with package version 4.0.0 and communication version 1.5.0\n",
      "[INFO] Connected new brain: My Behavior?team=0\n",
      "[INFO] Hyperparameters for behavior name My Behavior: \n",
      "\ttrainer_type:\tpoca\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t128\n",
      "\t  buffer_size:\t12800\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.001\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.99\n",
      "\t  num_epoch:\t3\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tlinear\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tTrue\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t2\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\teven_checkpoints:\tFalse\n",
      "\tmax_steps:\t2000000\n",
      "\ttime_horizon:\t1000\n",
      "\tsummary_freq:\t10000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] My Behavior. Step: 10000. Time Elapsed: 24.624 s. Mean Reward: -0.500. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 20000. Time Elapsed: 43.114 s. Mean Reward: -0.396. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 30000. Time Elapsed: 54.185 s. Mean Reward: -0.396. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 40000. Time Elapsed: 71.801 s. Mean Reward: -0.378. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 50000. Time Elapsed: 82.732 s. Mean Reward: -0.500. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 60000. Time Elapsed: 101.750 s. Mean Reward: -0.553. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 70000. Time Elapsed: 122.045 s. Mean Reward: -0.470. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 80000. Time Elapsed: 135.118 s. Mean Reward: -0.498. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 90000. Time Elapsed: 153.394 s. Mean Reward: -0.500. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 100000. Time Elapsed: 170.911 s. Mean Reward: -0.500. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 110000. Time Elapsed: 189.598 s. Mean Reward: -0.417. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 120000. Time Elapsed: 200.575 s. Mean Reward: -0.500. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 130000. Time Elapsed: 216.550 s. Mean Reward: -0.482. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 140000. Time Elapsed: 235.073 s. Mean Reward: -0.177. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 150000. Time Elapsed: 256.616 s. Mean Reward: -0.451. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 160000. Time Elapsed: 266.455 s. Mean Reward: 0.174. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 170000. Time Elapsed: 285.301 s. Mean Reward: 0.083. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 180000. Time Elapsed: 304.788 s. Mean Reward: -0.082. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 190000. Time Elapsed: 318.317 s. Mean Reward: -0.050. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 200000. Time Elapsed: 332.274 s. Mean Reward: -0.150. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 210000. Time Elapsed: 347.802 s. Mean Reward: 0.226. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 220000. Time Elapsed: 366.020 s. Mean Reward: 0.349. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 230000. Time Elapsed: 383.548 s. Mean Reward: 0.320. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 240000. Time Elapsed: 395.297 s. Mean Reward: 0.327. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 250000. Time Elapsed: 415.523 s. Mean Reward: 0.394. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 260000. Time Elapsed: 430.793 s. Mean Reward: 0.370. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 270000. Time Elapsed: 450.338 s. Mean Reward: 0.159. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 280000. Time Elapsed: 463.461 s. Mean Reward: 0.125. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 290000. Time Elapsed: 479.150 s. Mean Reward: 0.133. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 300000. Time Elapsed: 501.219 s. Mean Reward: 0.217. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 310000. Time Elapsed: 515.842 s. Mean Reward: 0.215. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 320000. Time Elapsed: 528.428 s. Mean Reward: 0.307. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 330000. Time Elapsed: 546.154 s. Mean Reward: 0.531. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 340000. Time Elapsed: 565.450 s. Mean Reward: 0.701. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 350000. Time Elapsed: 582.731 s. Mean Reward: 0.409. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 360000. Time Elapsed: 594.862 s. Mean Reward: 0.403. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 370000. Time Elapsed: 611.937 s. Mean Reward: 0.310. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 380000. Time Elapsed: 629.880 s. Mean Reward: 0.723. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 390000. Time Elapsed: 646.695 s. Mean Reward: 0.429. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 400000. Time Elapsed: 659.438 s. Mean Reward: 0.697. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 410000. Time Elapsed: 676.121 s. Mean Reward: 0.766. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 420000. Time Elapsed: 694.223 s. Mean Reward: 0.679. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 430000. Time Elapsed: 711.425 s. Mean Reward: 0.537. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 440000. Time Elapsed: 732.526 s. Mean Reward: 0.862. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 450000. Time Elapsed: 743.790 s. Mean Reward: 0.782. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 460000. Time Elapsed: 761.344 s. Mean Reward: 0.767. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 470000. Time Elapsed: 780.353 s. Mean Reward: 0.755. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 480000. Time Elapsed: 797.280 s. Mean Reward: 0.674. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 490000. Time Elapsed: 809.499 s. Mean Reward: 0.826. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 500000. Time Elapsed: 825.950 s. Mean Reward: 0.847. Mean Group Reward: 0.000. Training.\n",
      "/Users/hyunjae.k/anaconda3/envs/mlagents/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:1176: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  warnings.warn(\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_TwoMissions_Hyper_POCA/My Behavior/My Behavior-499982.onnx\n",
      "[INFO] My Behavior. Step: 510000. Time Elapsed: 844.781 s. Mean Reward: 0.893. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 520000. Time Elapsed: 863.787 s. Mean Reward: 0.862. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 530000. Time Elapsed: 874.861 s. Mean Reward: 0.817. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 540000. Time Elapsed: 893.782 s. Mean Reward: 0.833. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 550000. Time Elapsed: 912.210 s. Mean Reward: 0.830. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 560000. Time Elapsed: 930.876 s. Mean Reward: 0.887. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 570000. Time Elapsed: 948.712 s. Mean Reward: 0.741. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 580000. Time Elapsed: 961.304 s. Mean Reward: 0.865. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 590000. Time Elapsed: 979.727 s. Mean Reward: 0.934. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 600000. Time Elapsed: 998.184 s. Mean Reward: 0.777. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 610000. Time Elapsed: 1015.198 s. Mean Reward: 0.829. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 620000. Time Elapsed: 1026.873 s. Mean Reward: 0.844. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 630000. Time Elapsed: 1044.057 s. Mean Reward: 0.885. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 640000. Time Elapsed: 1061.721 s. Mean Reward: 0.881. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 650000. Time Elapsed: 1081.319 s. Mean Reward: 0.861. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 660000. Time Elapsed: 1094.251 s. Mean Reward: 0.775. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 670000. Time Elapsed: 1112.843 s. Mean Reward: 0.909. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 680000. Time Elapsed: 1130.008 s. Mean Reward: 0.809. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 690000. Time Elapsed: 1149.444 s. Mean Reward: 0.830. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 700000. Time Elapsed: 1165.955 s. Mean Reward: 0.885. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 710000. Time Elapsed: 1178.582 s. Mean Reward: 0.805. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 720000. Time Elapsed: 1199.158 s. Mean Reward: 0.919. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 730000. Time Elapsed: 1217.026 s. Mean Reward: 0.925. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 740000. Time Elapsed: 1233.856 s. Mean Reward: 0.868. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 750000. Time Elapsed: 1245.795 s. Mean Reward: 0.904. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 760000. Time Elapsed: 1266.064 s. Mean Reward: 0.913. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 770000. Time Elapsed: 1282.151 s. Mean Reward: 0.861. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 780000. Time Elapsed: 1302.049 s. Mean Reward: 0.917. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 790000. Time Elapsed: 1312.823 s. Mean Reward: 0.913. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 800000. Time Elapsed: 1331.072 s. Mean Reward: 0.895. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 810000. Time Elapsed: 1351.986 s. Mean Reward: 0.894. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 820000. Time Elapsed: 1367.803 s. Mean Reward: 0.856. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 830000. Time Elapsed: 1386.961 s. Mean Reward: 0.922. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 840000. Time Elapsed: 1399.961 s. Mean Reward: 0.827. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 850000. Time Elapsed: 1417.449 s. Mean Reward: 0.902. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 860000. Time Elapsed: 1436.287 s. Mean Reward: 0.897. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 870000. Time Elapsed: 1453.833 s. Mean Reward: 0.859. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 880000. Time Elapsed: 1465.488 s. Mean Reward: 0.888. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 890000. Time Elapsed: 1483.161 s. Mean Reward: 0.904. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 900000. Time Elapsed: 1501.762 s. Mean Reward: 0.898. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 910000. Time Elapsed: 1520.944 s. Mean Reward: 0.881. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 920000. Time Elapsed: 1537.777 s. Mean Reward: 0.884. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 930000. Time Elapsed: 1550.759 s. Mean Reward: 0.939. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 940000. Time Elapsed: 1567.958 s. Mean Reward: 0.862. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 950000. Time Elapsed: 1585.129 s. Mean Reward: 0.868. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 960000. Time Elapsed: 1605.807 s. Mean Reward: 0.919. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 970000. Time Elapsed: 1615.958 s. Mean Reward: 0.939. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 980000. Time Elapsed: 1636.116 s. Mean Reward: 0.938. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 990000. Time Elapsed: 1654.655 s. Mean Reward: 0.861. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1000000. Time Elapsed: 1673.029 s. Mean Reward: 0.902. Mean Group Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_TwoMissions_Hyper_POCA/My Behavior/My Behavior-999998.onnx\n",
      "[INFO] My Behavior. Step: 1010000. Time Elapsed: 1691.652 s. Mean Reward: 0.898. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1020000. Time Elapsed: 1704.875 s. Mean Reward: 0.931. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1030000. Time Elapsed: 1725.369 s. Mean Reward: 0.913. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1040000. Time Elapsed: 1743.417 s. Mean Reward: 0.847. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1050000. Time Elapsed: 1761.665 s. Mean Reward: 0.871. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1060000. Time Elapsed: 1773.078 s. Mean Reward: 0.904. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1070000. Time Elapsed: 1790.390 s. Mean Reward: 0.855. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1080000. Time Elapsed: 1807.277 s. Mean Reward: 0.898. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1090000. Time Elapsed: 1823.996 s. Mean Reward: 0.967. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1100000. Time Elapsed: 1838.145 s. Mean Reward: 0.936. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1110000. Time Elapsed: 1854.875 s. Mean Reward: 0.924. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1120000. Time Elapsed: 1872.516 s. Mean Reward: 0.918. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1130000. Time Elapsed: 1891.816 s. Mean Reward: 0.899. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1140000. Time Elapsed: 1910.419 s. Mean Reward: 0.945. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1150000. Time Elapsed: 1925.174 s. Mean Reward: 0.926. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1160000. Time Elapsed: 1943.176 s. Mean Reward: 0.889. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1170000. Time Elapsed: 1959.192 s. Mean Reward: 0.844. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1180000. Time Elapsed: 1978.365 s. Mean Reward: 0.945. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1190000. Time Elapsed: 1991.499 s. Mean Reward: 0.943. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1200000. Time Elapsed: 2010.036 s. Mean Reward: 0.875. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1210000. Time Elapsed: 2029.087 s. Mean Reward: 0.939. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1220000. Time Elapsed: 2047.597 s. Mean Reward: 0.954. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1230000. Time Elapsed: 2059.331 s. Mean Reward: 0.874. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1240000. Time Elapsed: 2077.148 s. Mean Reward: 0.947. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1250000. Time Elapsed: 2095.104 s. Mean Reward: 0.855. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1260000. Time Elapsed: 2112.202 s. Mean Reward: 0.946. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1270000. Time Elapsed: 2130.475 s. Mean Reward: 0.950. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1280000. Time Elapsed: 2143.478 s. Mean Reward: 0.950. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1290000. Time Elapsed: 2162.504 s. Mean Reward: 0.927. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1300000. Time Elapsed: 2182.096 s. Mean Reward: 0.940. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1310000. Time Elapsed: 2201.805 s. Mean Reward: 0.951. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1320000. Time Elapsed: 2212.421 s. Mean Reward: 0.896. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1330000. Time Elapsed: 2231.865 s. Mean Reward: 0.916. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1340000. Time Elapsed: 2249.253 s. Mean Reward: 0.918. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1350000. Time Elapsed: 2268.017 s. Mean Reward: 0.957. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1360000. Time Elapsed: 2286.051 s. Mean Reward: 0.960. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1370000. Time Elapsed: 2298.078 s. Mean Reward: 0.897. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1380000. Time Elapsed: 2316.968 s. Mean Reward: 0.931. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1390000. Time Elapsed: 2335.850 s. Mean Reward: 0.938. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1400000. Time Elapsed: 2356.936 s. Mean Reward: 0.950. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1410000. Time Elapsed: 2367.824 s. Mean Reward: 0.948. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1420000. Time Elapsed: 2386.024 s. Mean Reward: 0.919. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1430000. Time Elapsed: 2405.220 s. Mean Reward: 0.918. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1440000. Time Elapsed: 2422.942 s. Mean Reward: 0.876. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1450000. Time Elapsed: 2441.281 s. Mean Reward: 0.939. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1460000. Time Elapsed: 2453.524 s. Mean Reward: 0.963. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1470000. Time Elapsed: 2472.045 s. Mean Reward: 0.924. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1480000. Time Elapsed: 2490.978 s. Mean Reward: 0.905. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1490000. Time Elapsed: 2510.409 s. Mean Reward: 0.920. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1500000. Time Elapsed: 2523.551 s. Mean Reward: 0.937. Mean Group Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_TwoMissions_Hyper_POCA/My Behavior/My Behavior-1499957.onnx\n",
      "[INFO] My Behavior. Step: 1510000. Time Elapsed: 2541.068 s. Mean Reward: 0.914. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1520000. Time Elapsed: 2560.824 s. Mean Reward: 0.928. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1530000. Time Elapsed: 2578.827 s. Mean Reward: 0.950. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1540000. Time Elapsed: 2596.083 s. Mean Reward: 0.958. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1550000. Time Elapsed: 2609.666 s. Mean Reward: 0.964. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1560000. Time Elapsed: 2627.542 s. Mean Reward: 0.945. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1570000. Time Elapsed: 2646.527 s. Mean Reward: 0.921. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1580000. Time Elapsed: 2664.834 s. Mean Reward: 0.964. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1590000. Time Elapsed: 2677.635 s. Mean Reward: 0.964. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1600000. Time Elapsed: 2697.270 s. Mean Reward: 0.957. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1610000. Time Elapsed: 2715.602 s. Mean Reward: 0.942. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1620000. Time Elapsed: 2734.454 s. Mean Reward: 0.954. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1630000. Time Elapsed: 2752.974 s. Mean Reward: 0.940. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1640000. Time Elapsed: 2764.906 s. Mean Reward: 0.911. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1650000. Time Elapsed: 2783.430 s. Mean Reward: 0.908. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1660000. Time Elapsed: 2803.213 s. Mean Reward: 0.941. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1670000. Time Elapsed: 2821.011 s. Mean Reward: 0.909. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1680000. Time Elapsed: 2833.523 s. Mean Reward: 0.917. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1690000. Time Elapsed: 2853.676 s. Mean Reward: 0.913. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1700000. Time Elapsed: 2871.882 s. Mean Reward: 0.935. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1710000. Time Elapsed: 2890.190 s. Mean Reward: 0.922. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1720000. Time Elapsed: 2908.888 s. Mean Reward: 0.974. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1730000. Time Elapsed: 2920.961 s. Mean Reward: 0.936. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1740000. Time Elapsed: 2939.629 s. Mean Reward: 0.963. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1750000. Time Elapsed: 2957.326 s. Mean Reward: 0.952. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1760000. Time Elapsed: 2975.728 s. Mean Reward: 0.964. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1770000. Time Elapsed: 2987.827 s. Mean Reward: 0.939. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1780000. Time Elapsed: 3007.062 s. Mean Reward: 0.965. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1790000. Time Elapsed: 3027.082 s. Mean Reward: 0.965. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1800000. Time Elapsed: 3044.721 s. Mean Reward: 0.954. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1810000. Time Elapsed: 3063.276 s. Mean Reward: 0.930. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1820000. Time Elapsed: 3075.921 s. Mean Reward: 0.928. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1830000. Time Elapsed: 3095.595 s. Mean Reward: 0.932. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1840000. Time Elapsed: 3112.736 s. Mean Reward: 0.957. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1850000. Time Elapsed: 3132.007 s. Mean Reward: 0.947. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1860000. Time Elapsed: 3143.997 s. Mean Reward: 0.925. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1870000. Time Elapsed: 3162.189 s. Mean Reward: 0.930. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1880000. Time Elapsed: 3180.659 s. Mean Reward: 0.962. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1890000. Time Elapsed: 3199.542 s. Mean Reward: 0.939. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1900000. Time Elapsed: 3218.032 s. Mean Reward: 0.916. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1910000. Time Elapsed: 3231.165 s. Mean Reward: 0.962. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1920000. Time Elapsed: 3249.921 s. Mean Reward: 0.951. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1930000. Time Elapsed: 3267.515 s. Mean Reward: 0.961. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1940000. Time Elapsed: 3286.331 s. Mean Reward: 0.955. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1950000. Time Elapsed: 3298.943 s. Mean Reward: 0.928. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1960000. Time Elapsed: 3317.742 s. Mean Reward: 0.938. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1970000. Time Elapsed: 3335.774 s. Mean Reward: 0.910. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1980000. Time Elapsed: 3354.538 s. Mean Reward: 0.950. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 1990000. Time Elapsed: 3372.558 s. Mean Reward: 0.956. Mean Group Reward: 0.000. Training.\n",
      "[INFO] My Behavior. Step: 2000000. Time Elapsed: 3385.445 s. Mean Reward: 0.945. Mean Group Reward: 0.000. Training.\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_TwoMissions_Hyper_POCA/My Behavior/My Behavior-1999982.onnx\n",
      "[INFO] Exported /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_TwoMissions_Hyper_POCA/My Behavior/My Behavior-2000027.onnx\n",
      "[INFO] Copied /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_TwoMissions_Hyper_POCA/My Behavior/My Behavior-2000027.onnx to /Users/hyunjae.k/110_HyunJae_Git/2025_Playgrounds/Unity_Robotics_Playgrounds/Agent_Scripts/temp/mlagents_learn_output/Maze_TwoMissions_Hyper_POCA/My Behavior.onnx.\n"
     ]
    }
   ],
   "source": [
    "config_poca_fp = os.path.join(cur_dir, \"config\", \"TwoMission_hyper_poca.yaml\")\n",
    "run_poca_id = \"Maze_TwoMissions_Hyper_POCA\"\n",
    "print(config_poca_fp)\n",
    "print(run_poca_id)\n",
    "\n",
    "!mlagents-learn $config_poca_fp \\\n",
    "               --env=$env_fp \\\n",
    "               --results-dir=$output_dir \\\n",
    "               --run-id=$run_poca_id --base-port=$baseport"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
